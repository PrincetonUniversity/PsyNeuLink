{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 7.1 Conflict Monitoring\n",
    "\n",
    "Humans are motivational omnivorous -- from wanting to catch a fish to wanting to walk on the moon. Accomplishing open-ended goals that can span days to lifetimes requires ... did you just get an email notification? Go ahead, check your phone, this notebook is very patient... now you're back ... requires a cognitive architecture capable of overcoming interruptions, sustaining effort, and controlling attention. These abilities comprise the will of free will.\n",
    "\n",
    "Around the start of the semester, you freely decided to learn about computational modeling of psychological function, and for the most part have willfully followed through. At times it has been effortless -- when you were captivated by fascinating discoveries, theories, and models. At other times it has been effortful -- requiring you to suppress a wide variety of distractions and competing interests. During those effortful moments, when you succeeded in maintaining or regaining focus on the lectures, readings, or lab work, what was happening in your mind? In this lab, we will explore the cognitive processes that monitor for internal conflict and help overcome that conflict. When effort is required to help control attention, mechanisms that monitor conflict can activate effort and control. For a familiar starting point, we will build a conflict monitoring system on top of a Stroop model introduced in the last chapter (see 7).\n",
    "\n",
    "*Setup and Installation:*"
   ],
   "id": "9aadae946fa9a508"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%capture\n",
    "%pip install psyneulink\n",
    "%pip install stroop\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import psyneulink as pnl\n",
    "\n",
    "from stroop.stimulus import get_stimulus_set, TASKS, COLORS, CONDITIONS\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "np.random.seed(0)"
   ],
   "id": "cb8b40c89412ecbb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# constants\n",
    "experiment_info = f\"\"\"\n",
    "stroop experiment info\n",
    "- all colors:\\t {COLORS}\n",
    "- all words:\\t {COLORS}\n",
    "- all tasks:\\t {TASKS}\n",
    "- all conditions:{CONDITIONS}\n",
    "\"\"\"\n",
    "print(experiment_info)\n",
    "\n",
    "# calculate experiment metadata\n",
    "n_conditions = len(CONDITIONS)\n",
    "n_tasks = len(TASKS)\n",
    "n_colors = len(COLORS)\n",
    "\n",
    "# OTHER CONSTANTS\n",
    "N_UNITS = 2"
   ],
   "id": "8c688f2fab6f52f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "\n",
    "### The Stroop Model\n",
    "Here we define a function that creates a model of the Stroop task. This is the same model as we created in the previous tutorial (see, 7.2)"
   ],
   "id": "df3e8e3f1fe8fdc0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_stroop_model(\n",
    "        unit_noise_std=.01,\n",
    "        dec_noise_std=.1,\n",
    "        integration_rate=.2,\n",
    "        leak=0,\n",
    "        competition=1\n",
    "):\n",
    "    # model params\n",
    "    hidden_func = pnl.Logistic(gain=1.0, x_0=4.0)\n",
    "\n",
    "    # input layer, color and word\n",
    "    inp_clr = pnl.TransferMechanism(\n",
    "        default_variable=[0, 0], function=pnl.Linear, name='COLOR INPUT'\n",
    "    )\n",
    "    inp_wrd = pnl.TransferMechanism(\n",
    "        default_variable=[0, 0], function=pnl.Linear, name='WORD INPUT'\n",
    "    )\n",
    "    # task layer, represent the task instruction; color naming / word reading\n",
    "    inp_task = pnl.TransferMechanism(\n",
    "        default_variable=[0, 0], function=pnl.Linear, name='TASK'\n",
    "    )\n",
    "    # hidden layer for color and word\n",
    "    hid_clr = pnl.TransferMechanism(\n",
    "        default_variable=[0, 0],\n",
    "        function=hidden_func,\n",
    "        integrator_mode=True,\n",
    "        integration_rate=integration_rate,\n",
    "        noise=pnl.NormalDist(standard_deviation=unit_noise_std).function,\n",
    "        name='COLORS HIDDEN'\n",
    "    )\n",
    "    hid_wrd = pnl.TransferMechanism(\n",
    "        default_variable=[0, 0],\n",
    "        function=hidden_func,\n",
    "        integrator_mode=True,\n",
    "        integration_rate=integration_rate,\n",
    "        noise=pnl.NormalDist(standard_deviation=unit_noise_std).function,\n",
    "        name='WORDS HIDDEN'\n",
    "    )\n",
    "    # output layer\n",
    "    output = pnl.TransferMechanism(\n",
    "        default_variable=[0, 0],\n",
    "        function=pnl.Logistic,\n",
    "        integrator_mode=True,\n",
    "        integration_rate=integration_rate,\n",
    "        noise=pnl.NormalDist(standard_deviation=unit_noise_std).function,\n",
    "        name='OUTPUT'\n",
    "    )\n",
    "    # decision layer, some accumulator\n",
    "    decision = pnl.LCAMechanism(\n",
    "        default_variable=[0, 0],\n",
    "        leak=leak, competition=competition,\n",
    "        noise=pnl.UniformToNormalDist(\n",
    "            standard_deviation=dec_noise_std).function,\n",
    "        name='DECISION'\n",
    "    )\n",
    "    # PROJECTIONS, weights copied from cohen et al (1990)\n",
    "    wts_clr_ih = pnl.MappingProjection(\n",
    "        matrix=[[2.2, -2.2], [-2.2, 2.2]], name='COLOR INPUT TO HIDDEN')\n",
    "    wts_wrd_ih = pnl.MappingProjection(\n",
    "        matrix=[[2.6, -2.6], [-2.6, 2.6]], name='WORD INPUT TO HIDDEN')\n",
    "    wts_clr_ho = pnl.MappingProjection(\n",
    "        matrix=[[1.3, -1.3], [-1.3, 1.3]], name='COLOR HIDDEN TO OUTPUT')\n",
    "    wts_wrd_ho = pnl.MappingProjection(\n",
    "        matrix=[[2.5, -2.5], [-2.5, 2.5]], name='WORD HIDDEN TO OUTPUT')\n",
    "    wts_tc = pnl.MappingProjection(\n",
    "        matrix=[[4.0, 4.0], [0, 0]], name='COLOR NAMING')\n",
    "    wts_tw = pnl.MappingProjection(\n",
    "        matrix=[[0, 0], [4.0, 4.0]], name='WORD READING')\n",
    "    # build the model\n",
    "    model = pnl.Composition(name='STROOP model')\n",
    "    model.add_linear_processing_pathway([inp_clr, wts_clr_ih, hid_clr])\n",
    "    model.add_linear_processing_pathway([inp_wrd, wts_wrd_ih, hid_wrd])\n",
    "    model.add_linear_processing_pathway([hid_clr, wts_clr_ho, output])\n",
    "    model.add_linear_processing_pathway([hid_wrd, wts_wrd_ho, output])\n",
    "    model.add_linear_processing_pathway([inp_task, wts_tc, hid_clr])\n",
    "    model.add_linear_processing_pathway([inp_task, wts_tw, hid_wrd])\n",
    "    model.add_linear_processing_pathway([output, pnl.IDENTITY_MATRIX, decision])\n",
    "    # collect the node handles\n",
    "    nodes = [inp_clr, inp_wrd, inp_task, hid_clr, hid_wrd, output, decision]\n",
    "    metadata = [integration_rate, dec_noise_std, unit_noise_std]\n",
    "    return model, nodes, metadata"
   ],
   "id": "6cb51433005f182"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's create a model with no noise and plot the model graph.",
   "id": "1c132b2a0cb025e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# turn off noise\n",
    "unit_noise_std = 0\n",
    "dec_noise_std = 0\n",
    "\n",
    "# define the model\n",
    "model, nodes, model_params = get_stroop_model(unit_noise_std, dec_noise_std)\n",
    "\n",
    "# fetch the params\n",
    "[integration_rate, dec_noise_std, unit_noise_std] = model_params\n",
    "[inp_color, inp_word, inp_task, hid_color, hid_word, output, decision] = nodes"
   ],
   "id": "5a9749f0fd5f6611"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Show the graph:",
   "id": "a0d2bdcba319cfc7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model.show_graph(output_fmt = 'jupyter')",
   "id": "138768805d893867"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### The Task Stimuli\n",
    "\n",
    "Again, we have two tasks:\n",
    "- color naming\n",
    "- word reading\n",
    "\n",
    "... and three conditions:\n",
    "\n",
    "- control\n",
    "- conflict\n",
    "- congruent"
   ],
   "id": "a5c0dcf3ba3c78c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# the length of the stimulus sequence\n",
    "n_time_steps = 120\n",
    "input_set = get_stimulus_set(inp_color, inp_word, inp_task, n_time_steps)\n",
    "\n",
    "# show what's in the dictionary\n",
    "for task in TASKS:\n",
    "    print(f'{task}: {input_set[task].keys()}')"
   ],
   "id": "6ce9c460e81a7a62"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# show one stimuli sequence\n",
    "task = 'color naming'\n",
    "cond = 'conflict'\n",
    "print(input_set[task][cond][inp_color].T)"
   ],
   "id": "98dcef1899e979ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Run he model on all Task - Condition Combinations\n",
    "\n",
    "test the model on all CONDITIONS x TASKS combinations"
   ],
   "id": "2b931532a628c222"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# log the activities\n",
    "hid_color.set_log_conditions('value')\n",
    "hid_word.set_log_conditions('value')\n",
    "output.set_log_conditions('value')\n",
    "\n",
    "# run the model\n",
    "execution_id = 0\n",
    "for task in TASKS:\n",
    "    for cond in CONDITIONS:\n",
    "        print(f'Running {task} - {cond} ... ')\n",
    "        model.run(\n",
    "            context=execution_id,\n",
    "            inputs=input_set[task][cond],\n",
    "            num_trials=n_time_steps,\n",
    "        )\n",
    "        execution_id += 1"
   ],
   "id": "cf9f71b43d6c3811"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here, we define a function that collects the logged activity for all trials ...",
   "id": "6c65a44530daa890"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_log_values(execution_ids_):\n",
    "    \"\"\"\n",
    "    get logged activity, given a list/array of execution ids\n",
    "    \"\"\"\n",
    "    # word hidden layer\n",
    "    hw_acts = np.array([\n",
    "        np.squeeze(hid_word.log.nparray_dictionary()[ei]['value'])\n",
    "        for ei in execution_ids_\n",
    "    ])\n",
    "    # color hidden layer\n",
    "    hc_acts = np.array([\n",
    "        np.squeeze(hid_color.log.nparray_dictionary()[ei]['value'])\n",
    "        for ei in execution_ids_\n",
    "    ])\n",
    "    out_acts = np.array([\n",
    "        np.squeeze(hid_color.log.nparray_dictionary()[ei]['value'])\n",
    "        for ei in execution_ids_\n",
    "    ])\n",
    "    dec_acts = np.array([\n",
    "        np.squeeze(model.parameters.results.get(ei))\n",
    "        for ei in execution_ids_\n",
    "    ])\n",
    "    return hw_acts, hc_acts, out_acts, dec_acts"
   ],
   "id": "967bd1b54f5a4b61"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "... and collect the activity for all tasks x conditions",
   "id": "69898fd96e435687"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# collect the activity\n",
    "ids = [ei for ei in range(execution_id)]\n",
    "hw_acts, hc_acts, out_acts, dec_acts = get_log_values(ids)\n",
    "\n",
    "print('activities: trial_id x n_time_steps x n_units')\n",
    "print(f'word hidden: \\t{np.shape(hw_acts)}')\n",
    "print(f'color hidden: \\t{np.shape(hc_acts)}')\n",
    "print(f'output: \\t{np.shape(out_acts)}')\n",
    "print(f'decision acts: \\t{np.shape(dec_acts)}')"
   ],
   "id": "c23b318161acaf6f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Visualize Decision Activity\n",
    "\n",
    "In this section, we will visualize the activity of the two decision units. For simplicity, the stimuli were intentionally chosen so that the correct response is always red (e.g. in a word naming - conflict trial, the word is red). Therefore, the activity for the red decision unit is always higher than the green decision unit. However, the difference between these two units depends on both task and condition."
   ],
   "id": "d95ad4e88fda1c9a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Exercise 1: Setting Expectations{exercise}\n",
    "\n",
    "Before looking at the results, predict which task-condition combination will evoke the biggest differences between the two decision units? Explain your reasoning.  Write your answer below."
   ],
   "id": "6b7c499062606a19"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Solution{solution}\n",
    "\n",
    "You can think about this as \"easy\" vs \"hard\" decisions. As further appart the activations are (the higher the difference), the easier the decision is. If --- on the contrary --- activity levels are more similar (the difference is low), the decision is harder.\n",
    "\n",
    "For the word naming task, the activity is high for the red unit, since the word is red. The color unit is not very important here, since both the task demand unit \"surpresses\" the color unit and the weights from the color unit are lower anyways. So the word naming task doesn't lead to conflict (the difference of activity will be high no matter what condition)\n",
    "\n",
    "For the color naming task, the activity difference, the activity difference depends more on the condition:\n",
    "\n",
    "congruent > control > conflict"
   ],
   "id": "489f3123282a3c08"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here, for *more visually appealing* plots,we are using seaborn for a colorpalette, so let's install this here:",
   "id": "34dda7d9edae169e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%capture\n",
    "%pip install seaborn\n",
    "import seaborn as sns"
   ],
   "id": "6e3be1250b2147ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We define a legend:",
   "id": "f930d0dd6f97810"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# define the set of colors\n",
    "col_pal = sns.color_palette('colorblind', n_colors=3)\n",
    "# define the set of line style\n",
    "lsty_plt = ['-', '--']\n",
    "# line width\n",
    "lw_plt = 3\n",
    "\n",
    "lgd_elements = []\n",
    "# legend for all conditions\n",
    "for i, cond in enumerate(CONDITIONS):\n",
    "    lgd_elements.append(\n",
    "        Line2D([0], [0], color=col_pal[i], lw=lw_plt, label=cond))\n",
    "\n",
    "# legend for all tasks\n",
    "for i, task in enumerate(TASKS):\n",
    "    lgd_elements.append(\n",
    "        Line2D([0], [0], color='black', lw=lw_plt, label=task,\n",
    "               linestyle=lsty_plt[i])\n",
    "    )\n",
    "\n",
    "# show the legend\n",
    "plt.legend(handles=lgd_elements, frameon=False)"
   ],
   "id": "49aaacfb18a733cd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Plotting Response Unit Activity by Condition\n",
    "\n",
    "The cell below creates a plot of decision unit activity over time for 3 different trial types.  For all trials, the ink color is red and the task is to respond to the ink color.  Control trials have no word.  Congruent trials display the word Red.  And Incongruent trials display the word Green.   In this figure, the top 3 lines show the Red Response Unit Activity, and these are higher because the stimulus is red ink and the task is to respond to the color of the ink.  The bottom 3 lines show the Green Response Unit Activity.\n",
    "\n",
    "For the incongruent color naming trial, the Red Response Unit is more active because the ink is red and the task is to respond to the ink color. However, the Green Response Unit (light blue line) is also somewhat active because the word is Green.  The relatively small (smaller than any other task-condition) difference between these two units suggests that the Decision Energy should be higher for this trial."
   ],
   "id": "46163ebaed4aae4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"plot the activity\n",
    "\"\"\"\n",
    "\n",
    "f, axes = plt.subplots(2, 1, figsize=(8, 8))\n",
    "for j, task in enumerate(TASKS):\n",
    "    for i, cond in enumerate(CONDITIONS):\n",
    "        axes[0].plot(\n",
    "            dec_acts[i + j*n_conditions][:, 0],\n",
    "            color=col_pal[i], label=CONDITIONS[i], linestyle=lsty_plt[j],\n",
    "        )\n",
    "        axes[1].plot(\n",
    "            dec_acts[i + j*n_conditions][:, 1],\n",
    "            color=col_pal[i], linestyle=lsty_plt[j],\n",
    "        )\n",
    "\n",
    "title_text = \"\"\"\n",
    "Decision activity, red trial\n",
    "\"\"\"\n",
    "axes[0].set_title(title_text)\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.set_ylabel(f'Activity, {COLORS[i]} unit')\n",
    "axes[-1].set_xlabel('Time')\n",
    "# add legend\n",
    "axes[0].legend(\n",
    "    handles=lgd_elements, frameon=False, bbox_to_anchor=(.7, .75)\n",
    ")\n",
    "f.tight_layout()\n",
    "sns.despine()"
   ],
   "id": "1f0b3c02d3a73336"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Exercise 2. Visualize the activity time course for the hidden layers on a green trial{exercise}\n",
    "\n",
    "2a. Plot the activity for the **color** hidden layer unit, for all tasks (color naming, word reading) x conditions (congruent, control, conflict).  Interpret the results.\n",
    "\n",
    "2b. Plot the activity for the **word** hidden layer unit, for all tasks x conditions.  Interpret the results."
   ],
   "id": "ed0b191c521a12b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Visualize Decision Energy\n",
    "\n",
    "<a href=\"https://en.wikipedia.org/wiki/Hopfield_network#Energy\">Energy</a>\n",
    "is essentially the product of the two activation values.  For example, if the activations are at 0.6 and 0.4, the energy would be 0.24; in comparison to 0.1 and 0.9 computing an energy of 0.09.  This function is sensitive both to the total level of activation, and the differences between the units' activations.\n",
    "- This is also implemented in psyneulink as <a href=\"https://princetonuniversity.github.io/PsyNeuLink/Keywords.html?highlight=energy#psyneulink.core.globals.keywords.DistanceMetrics.ENERGY\">pnl.ENERGY</a>.\n",
    "\n",
    "### Plotting Decision Energy\n",
    "The following cell creates a plot of the decision energy for 3 types of trials: Control, Congruent, and Incongruent.  When the levels of activity for the two response units (Red & Green) are close, the decision energy is higher.  This makes sense because it is harder to decide when both responses are similarly active.  The decision is easiest (and energy is lowest) when the there is a big difference between the two response units."
   ],
   "id": "fa18496aefc155e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "plot dec energy\n",
    "\"\"\"\n",
    "data_plt = dec_acts\n",
    "f, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "col_pal = sns.color_palette('colorblind', n_colors=3)\n",
    "counter = 0\n",
    "for tid, task in enumerate(TASKS):\n",
    "    for cid, cond in enumerate(CONDITIONS):\n",
    "        ax.plot(\n",
    "            np.prod(data_plt[counter], axis=1),\n",
    "            color=col_pal[np.mod(counter, n_conditions)],\n",
    "            linestyle=lsty_plt[tid]\n",
    "        )\n",
    "        counter += 1\n",
    "\n",
    "ax.set_title(f'Decision energy')\n",
    "ax.set_ylabel('Energy')\n",
    "ax.set_xlabel('Time')\n",
    "ax.legend(handles=lgd_elements, frameon=False, bbox_to_anchor=(.7, .95))\n",
    "f.tight_layout()\n",
    "sns.despine()"
   ],
   "id": "3338a943488630c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Exercise 3: Energy, the initial state{exercise}\n",
    "\n",
    "Unpack what is being plotted by finding the equation used (e.g. in PNL documentation) and the input values to this calculation at the first time step.  What is the initial value of decision energy? Comment on why this is an interesting quantity for this situation. (Hint: What happens to the energy if one of the activation values is 1? What about if they are both equal?)"
   ],
   "id": "5df3cd1354d8a344"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Examine the effect of task demand\n",
    "\n",
    "#### Decision Energy as a Signal for Effort & Control\n",
    "\n",
    "The simple model we have built so far shows one type of signal that could be monitored and used as input to a mechanism of effort and control.  For example, if Decision Energy is high, that could provide useful information that the task requires additional attention and/or effort.\n",
    "\n",
    "In order to better understand the effects of modulating attention and/or effort in our models, it is helpful to explore exactly how these factors influence performance.\n"
   ],
   "id": "6ac2cebc5cdc8298"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# re-initialize the model\n",
    "model, nodes, model_params = get_stroop_model(unit_noise_std, dec_noise_std)\n",
    "[inp_color, inp_word, inp_task, hid_color, hid_word, output, decision] = nodes\n",
    "\n",
    "# the length of the stimulus sequence\n",
    "n_time_steps = 120\n",
    "demand_levels = np.round(np.linspace(0, 1, 6), decimals=1)\n",
    "n_demand_levels = len(demand_levels)\n",
    "input_sets = [\n",
    "    get_stimulus_set(inp_color, inp_word, inp_task, n_time_steps, demand=d)\n",
    "    for d in demand_levels\n",
    "]\n",
    "\n",
    "print(f'demand levels: {demand_levels}')"
   ],
   "id": "77adb7f5db93f0c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# run the model for all demand levels\n",
    "execution_id = 0\n",
    "for did, demand in enumerate(demand_levels):\n",
    "    for task in TASKS:\n",
    "        time_start = time.time() #records start time, to estimate our progress\n",
    "        print(f'\\nWith demand = {demand}, running {task}: ', end='')\n",
    "        for cond in CONDITIONS:\n",
    "            print(f'{cond} ', end='')\n",
    "            model.run(\n",
    "                context=execution_id,\n",
    "                inputs=input_sets[did][task][cond],\n",
    "                num_trials=n_time_steps,\n",
    "            )\n",
    "            execution_id += 1\n",
    "        print(f'| Time = %.2f'%(time.time()-time_start), end='')"
   ],
   "id": "d434e755cb551054"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# collect the activity\n",
    "ids = [ei for ei in range(execution_id)]\n",
    "\n",
    "# get decision activities for all trials\n",
    "dec_acts = np.array([\n",
    "    np.squeeze(model.parameters.results.get(ei))\n",
    "    for ei in ids\n",
    "])"
   ],
   "id": "ef627e2d5b8953ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def compute_rt(act, threshold=.9):\n",
    "    \"\"\"compute reaction time\n",
    "    take the activity of the decision layer...\n",
    "    RT := the earliest time point when activity > threshold...\n",
    "    \"\"\"\n",
    "    n_time_steps_, N_UNITS_ = np.shape(act)\n",
    "    tps_pass_threshold = np.where(act[:, 0] > threshold)[0]\n",
    "    if len(tps_pass_threshold) > 0:\n",
    "        return tps_pass_threshold[0]\n",
    "    return n_time_steps_"
   ],
   "id": "a9384d9f2ecfcef5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# re-organize RT data\n",
    "threshold = .9\n",
    "rts = np.zeros((n_demand_levels, n_tasks, n_conditions))\n",
    "counter = 0\n",
    "for did, demand in enumerate(demand_levels):\n",
    "    for tid, task in enumerate(TASKS):\n",
    "        for cid, cond in enumerate(CONDITIONS):\n",
    "            rts[did, tid, cid] = compute_rt(\n",
    "                dec_acts[counter], threshold=threshold\n",
    "            )\n",
    "            counter += 1"
   ],
   "id": "af39d9abb950ccbc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Plotting Task Demand & RT\n",
    "\n",
    "The two figures created by the following cell qualitatively replicate Fig 13A (left) and Fig 13B (right) from <a href=\"https://www.ncbi.nlm.nih.gov/pubmed/2200075\">Cohen et al. (1990)</a>.  The Y axis displays response time, and the X axis progresses upward in task demand unit activity.  (*Note that the key is consistent with previous figures in this notebook, but not all the conditions in the key are plotted.*)\n",
    "\n",
    "In the left panel we can see that Word reading (dashed black line) is generally faster than ink Color Naming (solid black line). The other prominent pattern is that increased activity in the task demand units leads to faster (lower) reaction times.\n",
    "\n",
    "The right panel compares Word reading under conflict (green dashed) to control (blue dashed).  It also displays part of the Color Naming plot under conflict (green solid).  These figures are truncated at the top to zoom in on key comparisons, and the full data extend well above the top of the Y-axis.\n",
    "\n",
    "These reaction times are in different units than human performance, but the overall trends make sense.  We can potentially use Task Demand as a way to model Attention/Effort. Increasing attention to the task improves performance yielding faster reaction times."
   ],
   "id": "7f7c23607641d4cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# plot prep\n",
    "col_pal = sns.color_palette('colorblind', n_colors=3)\n",
    "xticklabels = ['%.1f' % (d) for d in demand_levels]\n",
    "\n",
    "f, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "# left panel\n",
    "axes[0].plot(np.mean(rts[:, 0, :], axis=1), color='black', linestyle='-')\n",
    "axes[0].plot(np.mean(rts[:, 1, :], axis=1), color='black', linestyle='--')\n",
    "axes[0].set_title('RT as a function of task demand')\n",
    "# axes[0].legend(TASKS, frameon=False, bbox_to_anchor=(.4, 1))\n",
    "axes[0].legend(handles=lgd_elements, frameon=False, bbox_to_anchor=(.7, .95))\n",
    "# right panel\n",
    "clf_id = 1\n",
    "n_skips = 2\n",
    "axes[1].plot(np.arange(n_skips, n_demand_levels, 1),\n",
    "             rts[n_skips:, 0, clf_id], color=col_pal[clf_id],\n",
    "             label='conflicting word')\n",
    "axes[1].plot(rts[:, 1, clf_id], color=col_pal[clf_id],\n",
    "             linestyle='--', label='conflicting color')\n",
    "axes[1].plot(rts[:, 1, 0], color=col_pal[0], linestyle='--', label='control')\n",
    "axes[1].set_title('Compared the two conflict conditions')\n",
    "# axes[1].legend(frameon=False, bbox_to_anchor=(.55, 1))\n",
    "# common\n",
    "axes[0].set_ylabel('Reaction time (RT)')\n",
    "axes[1].set_ylim(axes[0].get_ylim())\n",
    "for ax in axes:\n",
    "    ax.set_xticks(range(n_demand_levels))\n",
    "    ax.set_xticklabels(xticklabels)\n",
    "    ax.set_xlabel('Demand')\n",
    "f.tight_layout()\n",
    "sns.despine()\n"
   ],
   "id": "a8906c44df83b94e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Exercise 4. Interpret the task demand results above{exercise}\n",
    "- Compare the results above with human performance in <a href=\"https://www.ncbi.nlm.nih.gov/pubmed/2200075\">Cohen et al. (1990)</a> Figures 13A & 13B, and comment on a few interesting similarities and differences.\n",
    "\n"
   ],
   "id": "b1c4f7a78ee52f94"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Exercise 5: Putting it all together{exercise}\n",
    "\n",
    "Note: Answers to this exercise can be qualitative and schematic -- you do not need to build the models (although you can if you like!), just describe how you would initially reason and plan to build them.\n",
    "\n",
    "5a.  How should task demand unit activity impact accuracy?\n",
    "\n",
    "5b.  Concisely describe key elements of a model mimicking human performance that exhibits the appropriate influence of task demand activity on accuracy.\n",
    "\n",
    "5c.  Describe steps that you could take, based on the models provided in this notebook, to build a model that monitors for conflict within trials and increases attention when conflict is present.\n",
    "\n",
    "5d.  Describe steps that you could take to build a model that monitors for errors after trials and increases attention on the subsequent trial.\n",
    "\n",
    "\n"
   ],
   "id": "6221789b85c68738"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
