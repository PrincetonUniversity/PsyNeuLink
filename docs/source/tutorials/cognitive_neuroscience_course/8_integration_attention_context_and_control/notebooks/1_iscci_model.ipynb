{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 8.1 ISC-CI Model\n",
    "\n",
    "The ISC-CI model introducing a mechanism for context inference, based on the key assumption that temporal co-occurrence provides a useful basis for inferring shared context. Specifically, it assumes that (1) objects occurring together in a given context tend to share the properties elicited by that context; (2) these co-occurrence statistics are learned over the course of development; and (3) this implicit knowledge provides a basis for inferring, from a few examples of objects encountered in a new context, both which features are relevant in that context and what other objects are likely to occur in that context.\n",
    "\n",
    "To make these ideas clear, consider the contexts in which you might encounter different kinds of birds: a bird-watching field trip in science class, a visit to the bird section of the zoo, and a picture book about birds. Each situation involves multiple types of birds (e.g., robins, crows, and ravens) and exposure to multiple bird-related properties (e.g., can-fly, eats-worms, is-bird) in various combinations. After these experiences, encountering a new context in which birds are relevant (e.g., learning that crows and ravens have hollow bones in the bird section of the Natural History museum) is likely to be interpreted as relating specifically to birds and their\n",
    "properties, implying that other birds like robins may also occur in this new context, and that\n",
    "they will share similar properties (e.g., robins also have hollow bones).\n",
    "\n",
    "Conversely, contexts such as a science lesson on aerodynamics, a visit to a flight exhibit at a science museum, and\n",
    "a film on the history of flight are likely to involve multiple types of flying things (e.g., crows,\n",
    "airplanes, and butterflies) and flight-related properties (e.g., can-fly, has-wings, seen-in-the-sky). This suggests that a new context involving flying objects such as crows and airplanes (e.g., learning that crows and airplanes are associated with Bernoulli’s principle) likely relates to all things that can fly, implying that other flying things like butterflies may also occur in this new context and, again, share similar properties (e.g., butterflies are also associated with Bernoulli’s principle).\n",
    "\n",
    "Thus, the properties shared by items encountered in a situation can provide a clue about what the current context is, what properties are currently important, and what other items are likely or unlikely also to be observed. The central hypothesis embodied by the ISC-CI model is that learning such environmental structure can support future inferences about which features might be relevant in novel contexts, based on the distribution of items that co-occur in those contexts. That is, observing that a new context involves a certain set of objects (e.g., both robins and airplanes) provides evidence that certain features will be context-relevant (e.g., can-fly and has-wings), but not\n",
    "others (e.g., lays-eggs), based on past experience.\n",
    "\n",
    "Importantly, this process is graded and probabilistic rather than absolute, as any given set of objects can co-occur in different contexts at different frequencies. In particular, features that are broadly true of many objects are less likely to be relevant in a new context than features that are true of the more limited set of objects seen in that context (Griffiths et al., 2010; Xu & Tenenbaum, 2007). This is because there is a low likelihood of observing any particular set of objects in a broad context: there are many animals, but few Corvidae, so it is more likely that a context involving both crows and ravens relates to Corvidae specifically than it is that this context relates to animals in general. This is because the probability of observing both crows and ravens in the context of animals is lower than the probability of oberseving both crows and ravens in the context of Corvidae.\n",
    "\n",
    "*Setup and Installation:*"
   ],
   "id": "c6e4259d77450a29"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:33:54.247350Z",
     "start_time": "2025-04-16T07:33:50.933748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "%pip install psyneulink\n",
    "\n",
    "import psyneulink as pnl\n",
    "import pandas as pd\n",
    "import random"
   ],
   "id": "eaf667865bc6d83c",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Generating the Training Data\n",
    "\n",
    "### Feature Co-occurrences\n",
    "\n",
    "We design a training environment that simulates experiencing object co-occurrences throughout learning under the key assumption noted just above. The environment consisted of a series of episodes corresponding to different contexts. Each context involved a set of objects that share a common semantic feature (e.g., things that are birds, things that can fly, things that are found in the zoo, etc.), with each feature represented by a single output unit as implemented by the feature labels in the ISC-CI model.\n",
    "\n",
    "We generate the episodes using the objects and features in the Leuven Concepts Database (De Deyne & Storms, 2008; Storms, 2001; Ruts et al., 2004). That database contains a matrix of binary judgments provided by human raters indicating, for each object-feature pairing, whether the object possess the feature (e.g., does a bear weigh more than 100lbs? Are kangaroos found in zoos?).\n",
    "\n",
    "Let's explore the dataset\n"
   ],
   "id": "6a688057f30acb6b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:33:54.456478Z",
     "start_time": "2025-04-16T07:33:54.257813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "FEATURE_PATH = 'https://raw.githubusercontent.com/PrincetonUniversity/NEU-PSY-502/refs/heads/main/data/isc_ci/features.csv'\n",
    "\n",
    "feature_df = pd.read_csv(FEATURE_PATH, index_col=0)\n",
    "\n",
    "feature_df.head()"
   ],
   "id": "d1f51e538a1d952d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           is small  is a bird  is an animal  is big  can fly  is an insect  \\\n",
       "monkey            0          0             1       0        0             0   \n",
       "beaver            0          0             1       0        0             0   \n",
       "bison             0          0             1       1        0             0   \n",
       "dromedary         0          0             1       1        0             0   \n",
       "squirrel          1          0             1       0        0             0   \n",
       "\n",
       "           mammal  is a fish  lays eggs  is brown  ...  is for all ages  \\\n",
       "monkey          1          0          0         0  ...                0   \n",
       "beaver          1          0          0         1  ...                0   \n",
       "bison           1          0          0         0  ...                0   \n",
       "dromedary       1          0          0         1  ...                0   \n",
       "squirrel        1          0          0         1  ...                0   \n",
       "\n",
       "           you can play different notes whit it  \\\n",
       "monkey                                        0   \n",
       "beaver                                        0   \n",
       "bison                                         0   \n",
       "dromedary                                     0   \n",
       "squirrel                                      0   \n",
       "\n",
       "           can be used to put something in  can be bought in sports store  \\\n",
       "monkey                                   0                              0   \n",
       "beaver                                   0                              0   \n",
       "bison                                    0                              0   \n",
       "dromedary                                0                              0   \n",
       "squirrel                                 0                              0   \n",
       "\n",
       "           costs a lot of money  drives above the ground  driven by 1 person  \\\n",
       "monkey                        0                        0                   0   \n",
       "beaver                        0                        0                   0   \n",
       "bison                         0                        0                   0   \n",
       "dromedary                     0                        0                   0   \n",
       "squirrel                      0                        0                   0   \n",
       "\n",
       "           used in water  used in the house  worn often  \n",
       "monkey                 0                  0           0  \n",
       "beaver                 0                  0           0  \n",
       "bison                  0                  0           0  \n",
       "dromedary              0                  0           0  \n",
       "squirrel               0                  0           0  \n",
       "\n",
       "[5 rows x 385 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is small</th>\n",
       "      <th>is a bird</th>\n",
       "      <th>is an animal</th>\n",
       "      <th>is big</th>\n",
       "      <th>can fly</th>\n",
       "      <th>is an insect</th>\n",
       "      <th>mammal</th>\n",
       "      <th>is a fish</th>\n",
       "      <th>lays eggs</th>\n",
       "      <th>is brown</th>\n",
       "      <th>...</th>\n",
       "      <th>is for all ages</th>\n",
       "      <th>you can play different notes whit it</th>\n",
       "      <th>can be used to put something in</th>\n",
       "      <th>can be bought in sports store</th>\n",
       "      <th>costs a lot of money</th>\n",
       "      <th>drives above the ground</th>\n",
       "      <th>driven by 1 person</th>\n",
       "      <th>used in water</th>\n",
       "      <th>used in the house</th>\n",
       "      <th>worn often</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>monkey</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beaver</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bison</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dromedary</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>squirrel</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 385 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Exercise 1a{exercise}\n",
    "\n",
    "As stated above, a context is defined by the common feature shared by the objects in that context. For this dataset, which objects might occur in the \"eats mice\" context?"
   ],
   "id": "dd8d12db58e86c54"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Solution{solution}\n",
    "\n",
    "We can find the objects that might occur in the \"eats mice\" context by filtering the dataset for the feature \"eats mice\" and extracting the corresponding object names:\n",
    "\n",
    "```python\n",
    "eats_mice = feature_df[feature_df['eats mice'] == 1].index.tolist()\n",
    "```"
   ],
   "id": "85c67edf83b07e48"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Exercise 1b{exercise}\n",
    "\n",
    "As stated above, encountering different objects in the same episode provides evidence to the agent that they are in a specific context. For this dataset, which context might be defined by the object \"owl\" (and which by \"falcon\")?"
   ],
   "id": "e9afaa3aa334c711"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Solution{solution}\n",
    "\n",
    "The contexts are defined by the features of the objects:\n",
    "\n",
    "```python\n",
    "contexts_owl = feature_df.columns[feature_df.loc['owl'] == 1]\n",
    "contexts_falcon = feature_df.columns[feature_df.loc['falcon'] == 1]\n",
    "\n",
    "print('Contexts defined by \"owl\":', contexts_owl)\n",
    "print('Contexts defined by \"falcon\":', contexts_falcon)\n",
    "```\n",
    "\n"
   ],
   "id": "6795c9a1ef2c6693"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Exercise 1c{exercise}\n",
    "\n",
    "Objects can appear in various contexts. So for two given objects, they might define multiple contexts. What possible contexts are defined by \"owl\" and \"falcon\" together?"
   ],
   "id": "992fb7206de7971c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Solution{solution}\n",
    "\n",
    "The possible contexts are defined by the features that are shared by \"owl\" and \"falcon\":\n",
    "\n",
    "```python\n",
    "contexts_both = feature_df.columns[(feature_df.loc['owl'] == 1) & (feature_df.loc['falcon'] == 1)]\n",
    "print(contexts_both)\n",
    "```\n"
   ],
   "id": "27ff7c8fef795e3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Exercise 1d{exercise}\n",
    "\n",
    "Now (using the theory from above), try to answer the following question: Given an agent experiences an episode with \"owl\" and \"falcon\" defining the context. Would the agent be more surprised by encountering a \"cat\" in this context or \"penguin\"?\n",
    "\n",
    "(This is not a straight forward question, and you are not supposed to give a definite answer. Think about different (probabilistic/statistical) features of the world influencing the agent's prediction).\n",
    "\n",
    "Tip: Here we make the (unreasonable) assumption that contexts are uniformly distributed. In other words that any episode (being on a bird-watching tour or being in a science lesson) has occurred equally often in the past."
   ],
   "id": "61a2e5b61a281648"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Hint a{hint}\n",
    "\n",
    "In the exercise above, we've seen that \"owl\" and \"falcon\" can elicit different contexts. But is there a way to \"quantify\" which of these contexts is more likely to be elicited?\n",
    "\n",
    "Tip: This depends on how likely it is to encounter both an \"owl\" and a \"falcon\" in any of the given contexts."
   ],
   "id": "96c3ed3492bc16d5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Hint b{hint}\n",
    "\n",
    "We calculate the probabilities from above:\n",
    "\n",
    "```python\n",
    "contexts_both = feature_df.columns[(feature_df.loc['owl'] == 1) & (feature_df.loc['falcon'] == 1)]\n",
    "\n",
    "context_probabilities = {}\n",
    "\n",
    "for c in contexts_both:\n",
    "    objects = feature_df[feature_df[c] == 1].index.tolist()\n",
    "    nr_objects = len(objects)\n",
    "    # Simplification (objects are equally likely):\n",
    "    # The probability for encountering any object is 1 / nr_objects\n",
    "    # => the probability of 'drawing' two objects is 1 / nr_objects^2\n",
    "    probability = 1 / nr_objects**2\n",
    "    context_probabilities[c] = probability\n",
    "\n",
    "print(context_probabilities)\n",
    "print()\n",
    "most_probabl_context = max(context_probabilities, key=context_probabilities.get)\n",
    "print(most_probabl_context)\n",
    "```"
   ],
   "id": "9279807bc394709d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Hint c{hint}\n",
    "\n",
    "The code above shows that the most probable context is \"eats mice\". But \"penguins\" don't eat mice while \"cats\" do (You can convince yourself by querying the database :). So if the agent encounters a \"cat\" it should be less surprised than if it encounters a \"penguin\".\n",
    "\n",
    "However, this is just the most probable context. Although \"penguin\" doesn't appear in the most probable context of \"owl\" and \"falcon\", this might be offset by \"penguin\" appearing in more probable contexts than \"cat\"."
   ],
   "id": "66c0810d92d38a4a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Solution{solution}\n",
    "\n",
    "First, we calculate the probabilities of encountering \"owl\" and \"falcon\" in any given context. We normalize these probabilties and use them as weights:\n",
    "We add all the probabilities of contexts where \"penguin\" also appears vs \"cat\":\n",
    "\n",
    "```python\n",
    "contexts_both = feature_df.columns[(feature_df.loc['owl'] == 1) & (feature_df.loc['falcon'] == 1)]\n",
    "\n",
    "context_probabilities = {}\n",
    "\n",
    "for c in contexts_both:\n",
    "    objects = feature_df[feature_df[c] == 1].index.tolist()\n",
    "    nr_objects = len(objects)\n",
    "    probability = 1 / nr_objects**2\n",
    "    context_probabilities[c] = probability\n",
    "\n",
    "# normalize the to get the probabilty of a certain context beeing evoked\n",
    "sum_probs = sum(context_probabilities.values())\n",
    "normalized = {c: p / sum_probs for c, p in context_probabilities.items()}\n",
    "\n",
    "penguin_weight = 0\n",
    "penguin_nr = 0\n",
    "cat_weight = 0\n",
    "cat_nr = 0\n",
    "\n",
    "\n",
    "for c, v in normalized.items():\n",
    "    objects = feature_df[feature_df[c] == 1].index.tolist()\n",
    "    # the context evokes penguin\n",
    "    if 'penguin' in objects:\n",
    "        penguin_weight += v\n",
    "        penguin_nr += 1\n",
    "    # the context evokes cat\n",
    "    if 'cat' in objects:\n",
    "        cat_weight += v\n",
    "        cat_nr += 1\n",
    "\n",
    "print(f'penguins({penguin_nr}): {penguin_weight}')\n",
    "print(f'cats({cat_nr}): {cat_weight}')\n",
    "```"
   ],
   "id": "a90797584936b1ec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Embedding\n",
    "\n",
    "The ISC-CI model uses as input a word embedding (not a one-hot encoding). This embedding can be interpreted as \"context independent\" representation. Here, we load the embeddings:"
   ],
   "id": "771322d4c9ba3ec0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:33:59.233286Z",
     "start_time": "2025-04-16T07:33:59.049460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EMBEDDING_PATH = 'https://raw.githubusercontent.com/PrincetonUniversity/NEU-PSY-502/refs/heads/main/data/isc_ci/embeddings.csv'\n",
    "\n",
    "embeddings_df = pd.read_csv(EMBEDDING_PATH, index_col=0)\n",
    "\n",
    "chicken_embedding = embeddings_df.loc['chicken']\n",
    "chicken_embedding"
   ],
   "id": "6127ce8f52c66f5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.119731\n",
       "1     0.987248\n",
       "2     0.982023\n",
       "3     0.410961\n",
       "4     0.451753\n",
       "        ...   \n",
       "59    0.022675\n",
       "60    0.326714\n",
       "61    0.014851\n",
       "62    0.035483\n",
       "63    0.982558\n",
       "Name: chicken, Length: 64, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Exercise 2{exercise}\n",
    "\n",
    "We can ask the same question as above: Can you think about a way of using the embeddings of \"owl\", \"falcon\", \"cat\" and \"penguin\" to quantify weather the agent would be more surprised by encountering a \"cat\" or a \"penguin\" in the context of \"owl\" and \"falcon\"?"
   ],
   "id": "71f3d7f2b8673d93"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Hint{hint}\n",
    "\n",
    "With word embeddings, we can calculate similarities between words by using the distance."
   ],
   "id": "7c42dd3a791ab1aa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Solution{solution}\n",
    "\n",
    "We calculate the distance between the embeddings of \"owl\" and \"falcon\" to the embeddings of \"cat\" and \"penguin\":\n",
    "\n",
    "```python\n",
    "owl_emb = embeddings_df.loc['owl']\n",
    "falcon_emb = embeddings_df.loc['falcon']\n",
    "cat_emb = embeddings_df.loc['cat']\n",
    "penguin_emb = embeddings_df.loc['penguin']\n",
    "\n",
    "owl_falcon_emb = (owl_emb + falcon_emb) / 2\n",
    "\n",
    "cat_distance = ((owl_falcon_emb - cat_emb)**2).sum()\n",
    "penguin_distance = ((owl_falcon_emb - penguin_emb)**2).sum()\n",
    "\n",
    "print('cat distance ', cat_distance)\n",
    "print('penguin distance ', penguin_distance)\n",
    "```"
   ],
   "id": "bdb3cbc4c168be77"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Note, the \"context\"-calculations and \"embedding\"-calculations lead to different predictions:\n",
    "\n",
    "- context -> \"cat\" is less surprising in \"owl\", \"falcon\" context\n",
    "- embedding  -> \"penguin\" is less surprising in \"owl\", \"falcon\" context"
   ],
   "id": "159bc2b8be4e160c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Training Data\n",
    "\n",
    "Now, we construct a set of episodes by uniformly sampling from the set of features with replacement, so that each episode involved one shared semantic feature that defined the associated context. Given this feature, we generated a support set by uniformly sampling two items sharing the feature, and a query set by uniformly sampling one additional item sharing the feature (positive) and one that is not sharing the feature (negative). Note, that as above-mentioned, any given set of objects can co-occur in multiple contexts (in other words can share multiple features), however, for features tha are broadly true of many objects, it is less likely for each specific pair of objects to be sampled. For example, if the feature is \"eats mice\", the likelihood of sampling exactly {\"owl\", \"falcon\"} is higher than if the feature is \"is a bird\" (since there are many more birds than mice eaters)."
   ],
   "id": "a5415284fe124dc3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:34:03.073997Z",
     "start_time": "2025-04-16T07:34:03.069627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_random_episode():\n",
    "    # randomly pick a context (feature)\n",
    "    feature = random.choice(feature_df.columns)\n",
    "\n",
    "    # one hot encoded feature vector is our context:\n",
    "    context_label = [0] * len(feature_df.columns)\n",
    "    context_label[feature_df.columns.get_loc(feature)] = 1\n",
    "\n",
    "    # get objects that have this feature by name\n",
    "    objects_included = feature_df[feature_df[feature] == 1].index.tolist()\n",
    "\n",
    "    # get objects that don't have this feature\n",
    "    objects_excluded = feature_df[feature_df[feature] == 0].index.tolist()\n",
    "\n",
    "    # randomly pick two supports (can be the same twice)\n",
    "    support = random.choices(objects_included, k=2)\n",
    "\n",
    "    # the support vector is the embedding of the two supports\n",
    "    support_vector_1 = embeddings_df.loc[support[0]]\n",
    "    support_vector_2 = embeddings_df.loc[support[1]]\n",
    "\n",
    "    # decide weather to pick an object that is in the context or not\n",
    "    choice = random.choice([0, 1])\n",
    "\n",
    "    if choice == 0:\n",
    "        # pick an object that is not in the context\n",
    "        query = random.choice(objects_excluded)\n",
    "    else:\n",
    "        # pick an object that is not in the context\n",
    "        query = random.choice(objects_included)\n",
    "\n",
    "    # the query vector is the embedding of the query\n",
    "    query_vector = embeddings_df.loc[query]\n",
    "\n",
    "    return {\n",
    "        'context_label': context_label,\n",
    "        'support_1': support_vector_1,\n",
    "        'support_2': support_vector_2,\n",
    "        'query': query_vector,\n",
    "        'response': [1, 0] if choice > .5 else [0, 1]\n",
    "    }"
   ],
   "id": "94d3b2680592c4aa",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## PsyNeuLink Model\n",
    "\n",
    "![ISC-CI](https://princetonuniversity.github.io/NEU-PSY-502/_static/images/502B/computation/iscci/iscci.png)\n",
    "\n",
    "We design the model to infer the context from the objects in the support set and use this to make predictions about objects in the query set. The model’s architecture contains a context independent layer that encodes cross-context information, a context layer that encodes information about which features are relevant in the given context, and a context-dependent layer which selectively encodes context-relevant information. The ISC-CI model processes the items in the support set and uses this both to generate an internal representation of context and provide a predicted context-specific shared semantic feature label as output.\n",
    "\n",
    "The ISC-CI model makes inferences about the current context using objects in the support set by sequentially observing each object in the support set, encoding each in the context independent layer, and integrating these representations by taking their average. This can be viewed as a very simple form of recurrence that accumulates (by linearly integrating and normalizing) activity across the items in the support set in the context independent layer.\n",
    "\n",
    "The ISC-CI model makes predictions about which items in the query set occur in the current context. It does so by forming a context dependent representation that takes into account the context inferred from the support set together with the context-independent representation of the query set item. The model then uses this context dependent representation to activate the binary yes/no output unit indicating the likelihood that the query set item occurs in the current context.\n"
   ],
   "id": "92a12e4942b18fa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Exercise 3a{exercise}\n",
    "\n",
    "Convince yourself that as context independent layer, we can use the embeddings of the support and query labels. In our PsyNeuLink implementation, we will \"skip\" the one-hot encoded labels and use the embeddings loaded earlier as input directly."
   ],
   "id": "3b661a179235481e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Solution{solution}\n",
    "\n",
    "The context independent layer captures context independent statistical properties of the objects (words). Word embeddings are a good representation of these properties and in many cases specifically trained to capture these properties (compare, for example, word2vec)."
   ],
   "id": "559a9c02cd109a7a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Exercise 3b{exercise}\n",
    "\n",
    "Explain -in your own words - why calculating the mean of the support embeddings a form of integration. Could you think about a different way of integrating the support embeddings?"
   ],
   "id": "b8a6cc63c51f5db5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Hint{hint}\n",
    "\n",
    "The mean of the support embeddings combines the information of multiple support vectors into one representation. However, does the order of the support vectors matter? Could you think about a way of integrating the support embeddings in a way that most recent support vectors have more weight than older ones?"
   ],
   "id": "e971100d576f90e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Solution{solution}\n",
    "\n",
    "The mean of the support embeddings is a form of integration because it combines the information from multiple support embeddings into a single representation. This allows the model to capture the shared properties of the objects. Other ways of integrating the support embeddings could include using a weighted sum or recurrent neural networks (RNNs or other forms of temporal integration like LSTM or GRU). These methods would allow to integrate the support vectors \"over time\" and take into account the order of the support embeddings."
   ],
   "id": "a1e6d9f03aed1e20"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Exercise 3c{exercise}\n",
    "\n",
    "Before implementing the model, think about the dimensions of the different layers:\n",
    "\n",
    "context independent, mean, context, context label, context dependent, and response"
   ],
   "id": "ccfd939c6fed27b9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Solution{solution}\n",
    "\n",
    "The dimensions of the different layers are as follows:\n",
    "- context independent: embedding dimension\n",
    "- mean: embedding dimension\n",
    "- context: arbitrary dimension (128 in the paper)\n",
    "- context label: number of features in the feature set\n",
    "- context dependent: arbitrary but the same as the context dimension\n",
    "- response: 2 (yes/no)"
   ],
   "id": "f7611866af43beaf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:47:52.976789Z",
     "start_time": "2025-04-16T07:47:52.967198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "N_EMBEDDING = embeddings_df.shape[1]\n",
    "HIDDEN_CONTEXT = 128\n",
    "N_CONTEXT = feature_df.shape[1]\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "\n",
    "def create_model(\n",
    "):\n",
    "    ## Mechanisms\n",
    "    # Here, we use 2 support vectors (but we could use more)\n",
    "    support_1 = pnl.TransferMechanism(\n",
    "        name='support_1',\n",
    "        input_shapes=N_EMBEDDING\n",
    "    )\n",
    "\n",
    "    support_2 = pnl.TransferMechanism(\n",
    "        name='support_2',\n",
    "        input_shapes=N_EMBEDDING\n",
    "    )\n",
    "\n",
    "    # The mean of the support vectors is calculated by adding them\n",
    "    # and multiplying by .5\n",
    "    mean = pnl.TransferMechanism(\n",
    "        name='mean',\n",
    "        input_shapes=N_EMBEDDING,\n",
    "        function=pnl.Linear(slope=.5),\n",
    "\n",
    "    )\n",
    "    context = pnl.TransferMechanism(\n",
    "        name='context',\n",
    "        input_shapes=HIDDEN_CONTEXT,\n",
    "        function=pnl.ReLU()\n",
    "    )\n",
    "\n",
    "    context_label = pnl.TransferMechanism(\n",
    "        name='context_label',\n",
    "        input_shapes=N_CONTEXT,\n",
    "        function=pnl.SoftMax()\n",
    "    )\n",
    "\n",
    "    query = pnl.TransferMechanism(\n",
    "        name='query',\n",
    "        input_shapes=N_EMBEDDING\n",
    "    )\n",
    "\n",
    "    context_dependent = pnl.TransferMechanism(\n",
    "        name='context_dependent',\n",
    "        input_shapes=HIDDEN_CONTEXT,\n",
    "        function=pnl.ReLU()\n",
    "    )\n",
    "\n",
    "    response = pnl.TransferMechanism(\n",
    "        name='response',\n",
    "        input_shapes=2,\n",
    "        function=pnl.SoftMax(),\n",
    "    )\n",
    "\n",
    "    ## Projections\n",
    "\n",
    "    projection_mean_to_context = pnl.MappingProjection(\n",
    "        name='projection_mean_to_context',\n",
    "        matrix=pnl.RandomMatrix(0, .01),\n",
    "        learnable=True\n",
    "    )\n",
    "\n",
    "    projection_query_to_context_dependent = pnl.MappingProjection(\n",
    "        name='projection_query_to_context_dependent',\n",
    "        matrix=pnl.RandomMatrix(0, .01),\n",
    "        learnable=True\n",
    "    )\n",
    "\n",
    "    projection_context_to_context_label = pnl.MappingProjection(\n",
    "        name='projection_context_dependent_to_context_out',\n",
    "        matrix=pnl.RandomMatrix(0, .01),\n",
    "        learnable=True\n",
    "    )\n",
    "\n",
    "    projection_context_dependent_to_response = pnl.MappingProjection(\n",
    "        name='projection_query_dependent_to_response',\n",
    "        matrix=pnl.RandomMatrix(0, .01),\n",
    "        learnable=True\n",
    "    )\n",
    "\n",
    "    ## Pathways\n",
    "\n",
    "    model = pnl.AutodiffComposition(\n",
    "        name='embedding',\n",
    "        pathways=[\n",
    "            [support_1, pnl.IDENTITY_MATRIX, mean],\n",
    "            [support_2, pnl.IDENTITY_MATRIX, mean],\n",
    "            [query, projection_query_to_context_dependent, context_dependent],\n",
    "            [mean, projection_mean_to_context, context],\n",
    "            [context, pnl.IDENTITY_MATRIX, context_dependent],\n",
    "            [context, projection_context_to_context_label, context_label],\n",
    "            [context_dependent, projection_context_dependent_to_response, response]\n",
    "        ],\n",
    "        learning_rate=LEARNING_RATE\n",
    "    )\n",
    "    return (model, query, support_1, support_2,\n",
    "            context_label, response)"
   ],
   "id": "2f99151912e33bd8",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:47:55.733223Z",
     "start_time": "2025-04-16T07:47:53.360017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "isc_ci_model, query, support_1, support_2, context_label, response = create_model()\n",
    "isc_ci_model.show_graph(output_fmt='jupyter')"
   ],
   "id": "574b134edaa07232",
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 12.1.0 (20240811.2233)\n -->\n<!-- Title: embedding&#45;1 Pages: 1 -->\n<svg width=\"318pt\" height=\"357pt\"\n viewBox=\"0.00 0.00 318.45 356.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 352.5)\">\n<title>embedding&#45;1</title>\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-352.5 314.45,-352.5 314.45,4 -4,4\"/>\n<text text-anchor=\"middle\" x=\"155.23\" y=\"-7.2\" font-family=\"Times,serif\" font-size=\"14.00\">embedding&#45;1</text>\n<!-- query -->\n<g id=\"node1\" class=\"node\">\n<title>query</title>\n<ellipse fill=\"none\" stroke=\"green\" stroke-width=\"3\" cx=\"81.73\" cy=\"-186.5\" rx=\"29.26\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"81.73\" y=\"-182.22\" font-family=\"arial\" font-size=\"12.00\">query</text>\n</g>\n<!-- context_dependent&#45;1 -->\n<g id=\"node5\" class=\"node\">\n<title>context_dependent&#45;1</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"81.73\" cy=\"-258.5\" rx=\"81.73\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"81.73\" y=\"-254.22\" font-family=\"arial\" font-size=\"12.00\">context_dependent&#45;1</text>\n</g>\n<!-- query&#45;&gt;context_dependent&#45;1 -->\n<g id=\"edge4\" class=\"edge\">\n<title>query&#45;&gt;context_dependent&#45;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M81.73,-205.89C81.73,-212.99 81.73,-221.28 81.73,-229.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"78.23,-228.92 81.73,-238.92 85.23,-228.92 78.23,-228.92\"/>\n</g>\n<!-- support_2&#45;1 -->\n<g id=\"node2\" class=\"node\">\n<title>support_2&#45;1</title>\n<ellipse fill=\"none\" stroke=\"green\" stroke-width=\"3\" cx=\"140.73\" cy=\"-42.5\" rx=\"50.72\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"140.73\" y=\"-38.23\" font-family=\"arial\" font-size=\"12.00\">support_2&#45;1</text>\n</g>\n<!-- mean -->\n<g id=\"node4\" class=\"node\">\n<title>mean</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"199.73\" cy=\"-114.5\" rx=\"29.26\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"199.73\" y=\"-110.22\" font-family=\"arial\" font-size=\"12.00\">mean</text>\n</g>\n<!-- support_2&#45;1&#45;&gt;mean -->\n<g id=\"edge2\" class=\"edge\">\n<title>support_2&#45;1&#45;&gt;mean</title>\n<path fill=\"none\" stroke=\"black\" d=\"M155.62,-61.16C162.79,-69.67 171.5,-80 179.27,-89.23\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"176.56,-91.44 185.68,-96.83 181.91,-86.93 176.56,-91.44\"/>\n</g>\n<!-- support_1&#45;1 -->\n<g id=\"node3\" class=\"node\">\n<title>support_1&#45;1</title>\n<ellipse fill=\"none\" stroke=\"green\" stroke-width=\"3\" cx=\"259.73\" cy=\"-42.5\" rx=\"50.72\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"259.73\" y=\"-38.23\" font-family=\"arial\" font-size=\"12.00\">support_1&#45;1</text>\n</g>\n<!-- support_1&#45;1&#45;&gt;mean -->\n<g id=\"edge1\" class=\"edge\">\n<title>support_1&#45;1&#45;&gt;mean</title>\n<path fill=\"none\" stroke=\"black\" d=\"M244.9,-60.8C237.43,-69.52 228.26,-80.22 220.14,-89.69\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"217.6,-87.28 213.74,-97.15 222.91,-91.83 217.6,-87.28\"/>\n</g>\n<!-- context -->\n<g id=\"node6\" class=\"node\">\n<title>context</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"199.73\" cy=\"-186.5\" rx=\"34.5\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"199.73\" y=\"-182.22\" font-family=\"arial\" font-size=\"12.00\">context</text>\n</g>\n<!-- mean&#45;&gt;context -->\n<g id=\"edge5\" class=\"edge\">\n<title>mean&#45;&gt;context</title>\n<path fill=\"none\" stroke=\"black\" d=\"M199.73,-132.8C199.73,-140.09 199.73,-148.77 199.73,-156.96\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"196.23,-156.88 199.73,-166.88 203.23,-156.88 196.23,-156.88\"/>\n</g>\n<!-- response&#45;1 -->\n<g id=\"node8\" class=\"node\">\n<title>response&#45;1</title>\n<ellipse fill=\"none\" stroke=\"red\" stroke-width=\"3\" cx=\"81.73\" cy=\"-330.5\" rx=\"48.34\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"81.73\" y=\"-326.23\" font-family=\"arial\" font-size=\"12.00\">response&#45;1</text>\n</g>\n<!-- context_dependent&#45;1&#45;&gt;response&#45;1 -->\n<g id=\"edge7\" class=\"edge\">\n<title>context_dependent&#45;1&#45;&gt;response&#45;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M81.73,-276.8C81.73,-283.79 81.73,-292.06 81.73,-299.95\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"78.23,-299.91 81.73,-309.91 85.23,-299.91 78.23,-299.91\"/>\n</g>\n<!-- context&#45;&gt;context_dependent&#45;1 -->\n<g id=\"edge3\" class=\"edge\">\n<title>context&#45;&gt;context_dependent&#45;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M177.53,-200.67C161.05,-210.45 138.18,-224.01 118.92,-235.44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"117.34,-232.3 110.53,-240.42 120.91,-238.32 117.34,-232.3\"/>\n</g>\n<!-- context_label -->\n<g id=\"node7\" class=\"node\">\n<title>context_label</title>\n<ellipse fill=\"none\" stroke=\"red\" stroke-width=\"3\" cx=\"236.73\" cy=\"-258.5\" rx=\"55.49\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"236.73\" y=\"-254.22\" font-family=\"arial\" font-size=\"12.00\">context_label</text>\n</g>\n<!-- context&#45;&gt;context_label -->\n<g id=\"edge6\" class=\"edge\">\n<title>context&#45;&gt;context_label</title>\n<path fill=\"none\" stroke=\"black\" d=\"M208.5,-204.09C212.51,-211.68 217.37,-220.88 221.93,-229.49\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"218.77,-231.02 226.54,-238.22 224.96,-227.74 218.77,-231.02\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x2c254d910>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Exercise 4{exercise}\n",
    "\n",
    "The activation function of the `context label` and the `response` is SoftMax. Do you think these are reasonable activation functions? If so, why?"
   ],
   "id": "998df58f042209d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Solution{solution}\n",
    "\n",
    "The SoftMax activation function is reasonable for the context label because it outputs a probability distribution over the features. In the section above (generating the training data), we discussed that a context is exactly defined by one feature (a feature that is shared by all support items).\n",
    "\n",
    "The SoftMax activation function is also reasonable for the response for the same reason. The response is a binary classification task (yes/no) and the SoftMax activation function captures this."
   ],
   "id": "bb968e95d210099f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Training Loop\n",
    "\n",
    "The model is now trained on 20,000 episodes.\n",
    "\n",
    "***Note, that this is not enough for the model to converge and just illustrates how a training loop would look like. We don't expect reasonable predictions after training.***"
   ],
   "id": "9e011cb639f0ecc5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:35:19.071664Z",
     "start_time": "2025-04-16T07:34:11.051248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tot_reps = 1\n",
    "examples_per_rep = 20_000\n",
    "n_epochs = 1\n",
    "\n",
    "for reps in range(tot_reps):\n",
    "\n",
    "    inputs_dict = {\n",
    "        query: [],\n",
    "        support_1: [],\n",
    "        support_2: [],\n",
    "    }\n",
    "\n",
    "    targets_dict = {\n",
    "        context_label: [],\n",
    "        response: [],\n",
    "    }\n",
    "\n",
    "    # Get Trainign\n",
    "    i = 0\n",
    "    while i < examples_per_rep:\n",
    "        example = get_random_episode()\n",
    "        # Append the input to the dictionary\n",
    "        inputs_dict[query].append(example['query'])\n",
    "        inputs_dict[support_1].append(example['support_1'])\n",
    "        inputs_dict[support_2].append(example['support_2'])\n",
    "\n",
    "        # Append the targets to the dictionary\n",
    "        targets_dict[context_label].append(example['context_label'])\n",
    "        targets_dict[response].append(example['response'])\n",
    "        i += 1\n",
    "\n",
    "    # Train the network for `n_epochs`\n",
    "    result = isc_ci_model.learn(\n",
    "        inputs={\n",
    "            'inputs': inputs_dict,\n",
    "            'targets': targets_dict,\n",
    "            'epochs': n_epochs\n",
    "        },\n",
    "        execution_mode=pnl.ExecutionMode.PyTorch\n",
    "    )\n",
    "    # Print a dot for each repetition to track progress\n",
    "    print('.', end='')\n",
    "    # Print a new line every 10 repetitions\n",
    "    if (reps + 1) % 10 == 0:\n",
    "        print()\n",
    "\n"
   ],
   "id": "f8d1823097a1354e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Testing",
   "id": "ffc90fad94580dfa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:35:19.125255Z",
     "start_time": "2025-04-16T07:35:19.122840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedding_falcon = embeddings_df.loc['falcon']\n",
    "embedding_owl = embeddings_df.loc['owl']\n",
    "\n",
    "embedding_cat = embeddings_df.loc['cat']\n",
    "embedding_penguin = embeddings_df.loc['penguin']\n"
   ],
   "id": "2435cf42858b7219",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:35:21.021877Z",
     "start_time": "2025-04-16T07:35:19.151657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res_cat = isc_ci_model.run(\n",
    "    {\n",
    "        query: embedding_cat,\n",
    "        support_1: embedding_falcon,\n",
    "        support_2: embedding_owl,\n",
    "    })\n",
    "response.value"
   ],
   "id": "47fd94378e67b63f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4971299 , 0.50272648]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:35:22.471009Z",
     "start_time": "2025-04-16T07:35:21.035033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res_penguin = isc_ci_model.run(\n",
    "    {\n",
    "        query: embedding_penguin,\n",
    "        support_1: embedding_falcon,\n",
    "        support_2: embedding_owl,\n",
    "    })\n",
    "response.value"
   ],
   "id": "ca2202a5a2d4aaf6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47386775, 0.52613219]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Exercise 5{exercise}\n",
    "\n",
    "Since the training was not sufficient, the model will not be able to predict the correct response. However, can you explain what the expected outcome for the above support and query items would be?"
   ],
   "id": "4f1058fcc804dd95"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Solution{solution}\n",
    "\n",
    "The expected outcome for the above support and query items would be:\n",
    "\n",
    "Higher split between yes and no for the query cat than for the query penguin."
   ],
   "id": "720ac1d848c96339"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Exercise 6{exercise}\n",
    "\n",
    "Even with a larger training set, the model is unlikely to \"see\" each combination of support and query items for each possible context. How can it still learn contexts for unseen combinations?\n"
   ],
   "id": "73b137fd5fbe2b5a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Hint{hint}\n",
    "\n",
    "Why are we using context independent layers in the first place? What would happen if we just use one-hot encodings and skip these independent layer?"
   ],
   "id": "76ae21123c9864ea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Solution{solution}\n",
    "\n",
    "The embeddings make it so that the model generalizes to unseen combinations since they might be \"similar\" to seen combinations. For example, birds share features in embedding space. So even if the model hasn't seen specific bird combinations it still learns the context that is elicited by these combinations.\n",
    "\n",
    "If we just use one-hot encodings and skip the context independent layer, the model would not be able to generalize to unseen combinations since they don't share any activations (everything is orthogonal). This would mean that with enough training, the model would maybe still learn to make correct predictions but never on unseen combinations."
   ],
   "id": "bd6abedb1e4c5b81"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
