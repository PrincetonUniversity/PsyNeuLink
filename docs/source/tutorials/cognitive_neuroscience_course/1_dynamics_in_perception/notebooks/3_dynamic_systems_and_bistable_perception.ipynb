{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1.3 Dynamic Systems and Bistable Perception\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In the next section we are going to explore some **dynamics** of running a model, including how information flows and is modified over time.  We will be building up to a simple model of bistable perception for a figure that people can readily interpret in two different ways.\n",
    "\n",
    "![necker cube](necker-cube.png)\n",
    "\n",
    "Two classic examples of bistable figures are the \"Duck Rabbit\" seen as either of two animals (but not usually both simultaneously), and the Necker Cube, where the face of the cube that you initially see as closest to you can alternatively be interpreted as farthest away from you.  We are going to work toward a Model of settling on one interpretation of the Necker Cube, after first exploring some simple dynamic models."
   ],
   "id": "16bc7d2df40f9730"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Installation and Setup**",
   "id": "83df81d6112c78c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "%pip install psyneulink\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import psyneulink as pnl"
   ],
   "id": "d8e9d0b0171403d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Dynamics 1: Attractor State\n",
    "\n",
    "The following code creates a composition with two mechanisms that are mutually connected by weights of -1. The output of one mechanism is multiplied by -1 and given as the input to the next mechanism, in a repeating cycle. We can specify initial input values for each mechanism and watch it evolve over time.  \n",
    "\n",
    "This particular mechanism will evolve toward stable values of 1 and -1. The values 1 and -1 are determined by the difference between the initial inputs. If the inputs are X and Y, this system will always evolve to $+/-abs[X-Y]/4$ (plus & minus the absolute value of the difference between the two inputs, divided by 4).  Whichever mechanism receives the larger initial input evolves to the positive value, while the smaller initial input evolves to the negative value.     "
   ],
   "id": "73b16dcfb0d08e94"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a PsyNeuLink Composition\n",
    "comp_attract = pnl.Composition()\n",
    "\n",
    "# Create the first Transfer Mechanism (node)\n",
    "node_attract1 = pnl.TransferMechanism(\n",
    "    name='node_attract1',  # Name of the mechanism for identification in graphs and outputs.\n",
    "    function=pnl.Linear(slope=1, intercept=0),  # Linear function with a slope of 1 and no intercept.\n",
    "    integrator_mode=True,  # Enables integration of inputs over time (temporal smoothing).\n",
    "    integration_rate=.5,  # Smoothing factor for integration: balance between current and previous input.\n",
    "    default_variable=np.zeros((1,)),  # Default input format: a single scalar (vector of size 1).\n",
    ")\n",
    "\n",
    "# Create the second Transfer Mechanism (node)\n",
    "node_attract2 = pnl.TransferMechanism(\n",
    "    name='node_attract2',\n",
    "    function=pnl.Linear(slope=1, intercept=0),  # Linear transfer function (identity mapping here).\n",
    "    integrator_mode=True,  # Temporal smoothing enabled.\n",
    "    integration_rate=.5,  # Same integration rate as the first node.\n",
    "    default_variable=np.zeros((1,)),  # Default input format.\n",
    ")\n",
    "\n",
    "# Explanation of integration:\n",
    "# With integrator_mode=True, the current activation is calculated as:\n",
    "# (1 - integration_rate) * previous_value + integration_rate * current_input\n",
    "# The mechanism's function is applied to this smoothed value.\n",
    "\n",
    "# Define the connection weight from node 1 to node 2\n",
    "connect_a1_a2 = ([-1])  # Weight matrix for mapping from node_attract1 to node_attract2.\n",
    "\n",
    "# Define the connection weight from node 2 to node 1\n",
    "connect_a2_a1 = ([-1])  # Weight matrix for mapping from node_attract2 to node_attract1.\n",
    "\n",
    "# Create a MappingProjection from node_attract1 to node_attract2\n",
    "weights_a1_a2 = pnl.MappingProjection(\n",
    "    name='connect_a1_a2',  # Name of the projection for identification.\n",
    "    matrix=connect_a1_a2,  # Weight matrix for the connection.\n",
    ")\n",
    "\n",
    "# Create a MappingProjection from node_attract2 to node_attract1\n",
    "weights_a2_a1 = pnl.MappingProjection(\n",
    "    name='connect_a2_a1',  # Name of the projection for identification.\n",
    "    matrix=connect_a2_a1,  # Weight matrix for the connection.\n",
    ")\n",
    "\n",
    "# Add the nodes and projections to the composition as a circular pathway\n",
    "# This defines a loop where the output of each node influences the other\n",
    "comp_attract.add_linear_processing_pathway(\n",
    "    pathway=(node_attract1, weights_a1_a2, node_attract2, weights_a2_a1, node_attract1)\n",
    ")\n",
    "\n",
    "# Enable detailed reporting of output for both nodes\n",
    "node_attract1.reportOutputPref = True  # Output values will be reported during execution.\n",
    "node_attract2.reportOutputPref = True\n",
    "\n",
    "# Define inputs for each node over multiple trials\n",
    "# The inputs will influence the activation and learning behavior of the system\n",
    "input_a1 = 2  # Initial input to node_attract1.\n",
    "input_a2 = 6  # Initial input to node_attract2.\n",
    "\n",
    "input_dict = {\n",
    "    node_attract1: [input_a1] + [0] * 9,  # Input sequence for node_attract1.\n",
    "    node_attract2: [input_a2] + [0] * 9   # Input sequence for node_attract2.\n",
    "}\n",
    "\n",
    "# Execute the composition for a specified number of trials\n",
    "comp_attract.run(\n",
    "    inputs=input_dict,  # Provide the input sequences.\n",
    "    num_trials=10  # Number of trials to run.\n",
    ")\n",
    "\n",
    "# Visualize the graph of the composition\n",
    "comp_attract.show_graph(output_fmt='jupyter')  # This generates a graph showing the structure of the composition."
   ],
   "id": "4ac0299a55b7d4bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can plot the results over successive time steps to get a clearer sense of how the system evolves over time.  Compare the plot below to your understanding of how the system evolves.",
   "id": "6f4f9d94abb36cdf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(np.shape(np.squeeze(comp_attract.results)))\n",
    "print(np.squeeze(comp_attract.results))\n",
    "plt.plot(np.squeeze(comp_attract.results))"
   ],
   "id": "778dc2df99055393",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "How did the system evolve over time?\n",
    "\n",
    "To get a better, we can calculate the activations in each step by hand:\n",
    "\n",
    "Remember that the activation of each node is calculated as:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "act_{1}(t) &= (1 - integration\\_rate) * act_{1}(t-1) + integration\\_rate * input_{1} \\\\\n",
    "&= (1 - integration\\_rate) * act_{1}(t-1) + integration\\_rate * (input_{i, external} - act_{2}(t-1))\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "act_{1}(t) &= (1 - integration\\_rate) * act_{1}(t-1) + integration\\_rate * input_{1} \\\\\n",
    "&= (1 - integration\\_rate) * act_{1}(t-1) + integration\\_rate * (input_{i, external} - act_{2}(t-1))\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "***Step 1***\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "act_{1}(1) &= (1 - integration\\_rate) * act_{1}(0) + integration\\_rate * (input_{i, external} - act_{2}(0)) \\\\\n",
    "&= (1 - 0.5) * 0 + 0.5 * (2 - 0) \\\\\n",
    "&= 1\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "act_{2}(1) &= (1 - integration\\_rate) * act_{2}(0) + integration\\_rate * (input_{i, external} - act_{1}(0)) \\\\\n",
    "&= (1 - 0.5) * 0 + 0.5 * (6 - 0) \\\\\n",
    "&= 3\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "***Step 2***\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "act_{1}(2) &= (1 - integration\\_rate) * act_{1}(1) + integration\\_rate * (input_{i, external} - act_{2}(1)) \\\\\n",
    "&= (1 - 0.5) * 1 + 0.5 * (0 - 3) \\\\\n",
    "&= -1\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "act_{2}(2) &= (1 - integration\\_rate) * act_{2}(1) + integration\\_rate * (input_{i, external} - act_{1}(1)) \\\\\n",
    "&= (1 - 0.5) * 3 + 0.5 * (0 - 1) \\\\\n",
    "&= 1\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "***Step 3***\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "act_{1}(3) &= (1 - integration\\_rate) * act_{1}(2) + integration\\_rate * (input_{i, external} - act_{2}(2)) \\\\\n",
    "&= (1 - 0.5) * -1 + 0.5 * (0 - 1) \\\\\n",
    "&= -1\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "act_{2}(2) &= (1 - integration\\_rate) * act_{2}(1) + integration\\_rate * (input_{i, external} - act_{1}(1)) \\\\\n",
    "&= (1 - 0.5) * 1 + 0.5 * (0 - (-1)) \\\\\n",
    "&= 1\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "So the system has stabilized at $act_{1} = -1$ and $act_{2} = 1$."
   ],
   "id": "b0db7d78dd2d470f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "Try to predict what happens if we change the input values of `node_attract1` and `node_attract2`.\n",
    "\n",
    "In the previous cell, we executed the system 10 times (`num_trials = 10`), with initial input values specified as `input_a1 = 6` and `input_a2 = 2`, and all subsequent input values set equal to `0` in the input_dict. What happens if you set all the subsequent input values to `1` instead of `0`?"
   ],
   "id": "e271200d7d3e714b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Reset the composition ensuring that the results are cleared.\n",
    "comp_attract.reset(clear_results=True)\n",
    "\n",
    "input_dict = {\n",
    "    node_attract1: [input_a1] + [1] * 9,  # Input sequence for node_attract1.\n",
    "    node_attract2: [input_a2] + [1] * 9,  # Input sequence for node_attract2.\n",
    "}\n",
    "\n",
    "comp_attract.run(\n",
    "    inputs=input_dict,\n",
    "    num_trials=10\n",
    ")\n",
    "\n",
    "print(np.shape(np.squeeze(comp_attract.results)))\n",
    "print(np.squeeze(comp_attract.results))\n",
    "plt.plot(np.squeeze(comp_attract.results))"
   ],
   "id": "869dee3c55028637",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Exercise 1{exercise}\n",
    "\n",
    "Explain the behavior of the system when the subsequent input values are set to `1` instead of `0`."
   ],
   "id": "1059e8b49252202f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Solution 1{solution}\n",
    "\n",
    "When the subsequent input values are set to `1` instead of `0` for both attractors, the system will evolve to a stable state where the output of `node_attract1` is `-0.5` and the output of `node_attract2` is `1.5`. With a constant input of `1` for both nodes, the stable state shifts `integration_rate` * `constant_input`. The relative difference between the two nodes remains the same, but the absolute values of the outputs are shifted by the constant input value."
   ],
   "id": "521032e232b18939"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "Try to predict what happens if we change the functions in the `TransferMechanisms` from Linear to Logistic (with default parameters, `gain = 1`, `bias = 0`, `offset = 0)`?"
   ],
   "id": "2ba8ac32cc90d81b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a PsyNeuLink Composition\n",
    "comp_attract_logistic = pnl.Composition()\n",
    "\n",
    "# Create the first Transfer Mechanism with Logistic function\n",
    "node_attract_logistic_1 = pnl.TransferMechanism(\n",
    "    name='node_attract1',  \n",
    "    function=pnl.Logistic(gain=1, bias=0, offset=0),  # Logistic function with a gain of 1 and no bias and offset.\n",
    "    integrator_mode=True,\n",
    "    integration_rate=.5,\n",
    "    default_variable=np.zeros((1,)),\n",
    ")\n",
    "\n",
    "# Create the second Transfer Mechanism with Logistic function\n",
    "node_attract_logistic_2 = pnl.TransferMechanism(\n",
    "    name='node_attract2',\n",
    "    function=pnl.Logistic(gain=1, bias=0, offset=0),  # Logistic function with a gain of 1 and no bias and offset.\n",
    "    integrator_mode=True,\n",
    "    integration_rate=.5,\n",
    "    default_variable=np.zeros((1,)),\n",
    ")\n",
    "\n",
    "# Create the Connection Weights\n",
    "connect_a1_a2 = ([-1])\n",
    "connect_a2_a1 = ([-1]) \n",
    "\n",
    "# Create the Mapping Projections\n",
    "weights_logistic_a1_a2 = pnl.MappingProjection(\n",
    "    name='connect_a1_a2',\n",
    "    matrix=connect_a1_a2,\n",
    ")\n",
    "weights_logistic_a2_a1 = pnl.MappingProjection(\n",
    "    name='connect_a2_a1',\n",
    "    matrix=connect_a2_a1,\n",
    ")\n",
    "\n",
    "# Add the nodes and projections to the composition\n",
    "comp_attract_logistic.add_linear_processing_pathway(\n",
    "    pathway=(node_attract_logistic_1, weights_logistic_a1_a2, node_attract_logistic_2, weights_logistic_a2_a1, node_attract_logistic_1)\n",
    ")\n",
    "\n",
    "# Enable detailed reporting of output for both nodes\n",
    "node_attract_logistic_1.reportOutputPref = True\n",
    "node_attract_logistic_2.reportOutputPref = True\n",
    "\n",
    "# Define inputs for each node over multiple trials\n",
    "input_a1 = 2  # Initial input to node_attract1.\n",
    "input_a2 = 6  # Initial input to node_attract2.\n",
    "\n",
    "input_dict = {\n",
    "    node_attract_logistic_1: [input_a1] + [0] * 9,  # Input sequence for node_attract1.\n",
    "    node_attract_logistic_2: [input_a2] + [0] * 9,  # Input sequence for node_attract2.\n",
    "}\n",
    "\n",
    "# Execute the composition for a specified number of trials\n",
    "comp_attract_logistic.run(\n",
    "    inputs=input_dict,\n",
    "    num_trials=len(input_dict[node_attract_logistic_1])\n",
    ")\n",
    "\n",
    "# Plot the output\n",
    "print(np.shape(np.squeeze(comp_attract_logistic.results)))\n",
    "print(np.squeeze(comp_attract_logistic.results))\n",
    "plt.plot(np.squeeze(comp_attract_logistic.results))"
   ],
   "id": "bd96840b98eff51",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Exercise 2{exercise}\n",
    "\n",
    "Write down the equation for activation of the node `node_attract1` with the Logistic function."
   ],
   "id": "11cdc993fab66ae2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Solution 2{solution}\n",
    "\n",
    "The activation of `node_attract1` with the Logistic function is calculated as:\n",
    "\n",
    "with the logistic function:\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{1}{1 + e^{-gain * (x - bias)}} + offset\n",
    "$$\n",
    "\n",
    "the activation of `node_attract1` is:\n",
    "\n",
    "$$\n",
    "act_{1}(t) = (1 - integration\\_rate) * act_{1}(t-1) + integration\\_rate * f(input_{1} - act_{2}(t-1))\n",
    "$$\n",
    "\n",
    "with gain = 1, bias = 0, and offset = 0:\n",
    "\n",
    "$$\n",
    "act_{1}(t) = (1 - integration\\_rate) * act_{1}(t-1) + integration\\_rate * \\frac{1}{1 + e^{-(input_{1} - act_{2}(t-1))}}\n",
    "$$\n",
    "\n",
    "</details>"
   ],
   "id": "b5f1c3c20f59670e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Dynamics 2: Unstable Feedback Loops\n",
    "\n",
    "While some systems evolve to fixed attractor states, others will evolve in a runaway cycle that goes continuously up or continuously down. Still others behave chaotically.  If you give the previous system input values that are consistently different the outputs will continuously diverge.\n",
    " For example if instead of both inputs being 0 or both being 1 (at each time step after the first one), the inputs are consistently different -- all 0s to node1 and all 1s to node2.  Try running the system with the following input:   "
   ],
   "id": "5d0c201fd88f59c2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Exercise 3{exercise}\n",
    "\n",
    "You can change the behavior of a system by changing the input values. Think of a way to change the input values so the output will continuously diverge. "
   ],
   "id": "42db896612f735ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Reset the composition ensuring that the results are cleared.\n",
    "comp_attract.reset(clear_results=True)\n",
    "\n",
    "\n",
    "input_dict = {\n",
    "    node_attract1: # TODO: Your code here\n",
    "    node_attract2: # TODO: Your code here\n",
    "}\n",
    "\n",
    "# Execute the composition for a specified number of trials\n",
    "comp_attract.run(\n",
    "    inputs=input_dict,\n",
    "    num_trials=len(input_dict[node_attract1])\n",
    ")\n",
    "\n",
    "# Plot the output\n",
    "print(np.shape(np.squeeze(comp_attract.results)))\n",
    "print(np.squeeze(comp_attract.results))\n",
    "plt.plot(np.squeeze(comp_attract.results))"
   ],
   "id": "5eaa6f78f333fa0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Solution 3{solution}\n",
    "\n",
    "In this case, inputs that are consistently different will cause the outputs to continuously diverge. For example, if we set the input values to `0` for `node_attract1` and `1` for `node_attract2`, the outputs will diverge over time. This is because the system is designed to evolve toward stable states based on the difference between the inputs. If the inputs are consistently different, the outputs will continue to diverge as the system tries to reach a stable state based on the input values.\n",
    "\n",
    "```python\n",
    "# Reset the composition ensuring that the results are cleared.\n",
    "comp_attract.reset(clear_results=True)\n",
    "\n",
    "\n",
    "input_dict = {\n",
    "    node_attract1: [0] * 10,  # Input sequence for node_attract1.\n",
    "    node_attract2: [1] * 10   # Input sequence for node_attract2.\n",
    "}\n",
    "\n",
    "# Execute the composition for a specified number of trials\n",
    "comp_attract.run(\n",
    "    inputs=input_dict,\n",
    "    num_trials=len(input_dict[node_attract1])\n",
    ")\n",
    "\n",
    "# Plot the output\n",
    "print(np.shape(np.squeeze(comp_attract.results)))\n",
    "print(np.squeeze(comp_attract.results))\n",
    "plt.plot(np.squeeze(comp_attract.results))\n",
    "```"
   ],
   "id": "d3a7be9062bd0f29"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Exercise 4{exercise}\n",
    "\n",
    "Is there a way to make the outputs diverge for if we use standard Logistic functions (`gain=1, bias=0, offset=0`). Try different weights and inputs to see if you can make the outputs diverge.\n"
   ],
   "id": "de5e8402291f53d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a PsyNeuLink Composition\n",
    "comp_divergent = pnl.Composition()\n",
    "\n",
    "# Create the first Transfer Mechanism (node)\n",
    "node_divergent_1 = pnl.TransferMechanism(\n",
    "    name='node_attract1',\n",
    "    function=pnl.Logistic(gain=1, offset=0),  # Logistic function with a slope of 1 and no intercept.\n",
    "    integrator_mode=True,\n",
    "    integration_rate=.5,\n",
    "    default_variable=np.zeros((1,)),\n",
    ")\n",
    "\n",
    "# Create the second Transfer Mechanism (node)\n",
    "node_divergent_2 = pnl.TransferMechanism(\n",
    "    name='node_attract2',\n",
    "    function=pnl.Logistic(gain=1, offset=0),\n",
    "    integrator_mode=True,\n",
    "    integration_rate=.5,\n",
    "    default_variable=np.zeros((1,)),\n",
    ")\n",
    "\n",
    "# Define the connection weight\n",
    "connect_divergent_a1_a2 =  # TODO: Your code here\n",
    "\n",
    "# Define the connection weight from node 2 to node 1\n",
    "connect_divergent_a2_a1 =  # TODO: Your code here\n",
    "\n",
    "# Create a MappingProjection from node_attract1 to node_attract2\n",
    "weights_divergent_a1_a2 = pnl.MappingProjection(\n",
    "    name='connect_a1_a2',  # Name of the projection for identification.\n",
    "    matrix=connect_divergent_a1_a2,  # Weight matrix for the connection.\n",
    ")\n",
    "\n",
    "# Create a MappingProjection from node_attract2 to node_attract1\n",
    "weights_divergent_a2_a1 = pnl.MappingProjection(\n",
    "    name='connect_a2_a1',  # Name of the projection for identification.\n",
    "    matrix=connect_divergent_a2_a1,  # Weight matrix for the connection.\n",
    ")\n",
    "\n",
    "# Add the nodes and projections to the composition as a circular pathway\n",
    "# This defines a loop where the output of each node influences the other\n",
    "comp_divergent.add_linear_processing_pathway(\n",
    "    pathway=(node_divergent_1, weights_divergent_a1_a2, node_divergent_2, weights_divergent_a2_a1, node_divergent_1)\n",
    ")\n",
    "\n",
    "# Enable detailed reporting of output for both nodes\n",
    "node_divergent_1.reportOutputPref = True  # Output values will be reported during execution.\n",
    "node_divergent_2.reportOutputPref = True\n",
    "\n",
    "# Define inputs for each node over multiple trials\n",
    "input_dict = {\n",
    "    node_divergent_1:  # TODO: Add code here\n",
    "    node_divergent_2:  # TODO: Add code here\n",
    "}\n",
    "\n",
    "# Execute the composition for a specified number of trials\n",
    "comp_divergent.run(\n",
    "    inputs=input_dict,  # Provide the input sequences.\n",
    "    num_trials=10  # Number of trials to run.\n",
    ")\n",
    "\n",
    "# Visualize the graph of the composition\n",
    "print(np.shape(np.squeeze(comp_divergent.results)))\n",
    "print(np.squeeze(comp_divergent.results))\n",
    "plt.plot(np.squeeze(comp_divergent.results))"
   ],
   "id": "180317fbbf771a86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Solution 4{solution}\n",
    "\n",
    "It is not possible to make the system diverge since the output of the nodes is bounded by the logistic function. The logistic function has a range between 0 and 1, so the outputs of the nodes will always be within this range. Even if you change the weights and inputs, the outputs will not diverge beyond this range."
   ],
   "id": "70307f0e3cb20b49"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Necker Cube Model\n",
    "\n",
    "The Necker Cube is a 2D drawing with two common 3D interpretations: the faces of the cube that you see in the \"front\" and \"back\" can be reversed - this also corresponds to seeing the 3D cube from \"above\" or \"below.\" With a little practice most people can alternate between seeing these two interpretations. However, almost nobody looks at the figure and spontaneously sees a tangled 3D object with vertices at arbitrary depths, or a 3D \"X\" or any one of a vast number of other possibilities. How you interpret the vertices seems to be a holistic (Gestalt) process where the local positions of vertices and 3D angles are fixed by a more global interpretation. Could a network of merely local connections give rise to two distinct globally stable interpretations? Put another way, could vertices represented with weights connecting only to a few local neighboring vertices spontaneously move toward either of two global attractor states corresponding to the two interpretations we actually see?\n",
    "\n",
    "\n",
    "\n",
    "![necker cube connections](necker-cube-connections.png)\n",
    "\n",
    "You can get a sense from these two figures how we might label and organize a Necker cube model [Note: FUL stands for Front Upper Left, and the other abbreviations are similar.]  Take a few moments to infer as much as you can from the two figures. \n",
    "\n",
    "The following figure depicts how we will represent the vertices in our Necker Cube perception model. Think of the red sides as the interpreted \"front\" of the cube.    \n",
    "\n",
    "![necker cube fronts](necker-cube-fronts.png)\n",
    "\n",
    "We'll use 16 nodes, numbered 0 to 15 [because Python indexes arrays starting with 0]. The figure shows that we want activations of these 16 nodes to cluster into two groups, 0-7 and 8-15, and we want these clusters to mutually inhibit each other so that only one cluster is active together at a time, corresponding to one interpretation of the Necker Cube at a time. \n",
    "\n",
    "Remember, a connection matrix will have the dimensions 16x16. The entry on [row, column] will be the weight of the connection from the node in the row to the node in the column. For example if the entry on [0, 1] is 1, this means that node 0 has an excitatory connection to node 1. If the entry on [3, 11] is -2, this means that node 3 has an inhibitory connection to node 11.\n",
    "\n",
    "In the following code, we will build the matrix by specifying the exitatory and inhibitory connections for each vertex in a `build_matrix`. From that, we will generate the necker_matrix with the connection weights. For example, in the line `build_matrix[0,:] = [0, 1, 3, 4, 8]`, you can think of the numbers [0, 1, 3, 4, 8] like this: the first number [0] is a vertex (more specifically, it is a particular 3D interpretation of the spatial position of that vertex), the next three numbers [1, 3, 4] are vertex interpretations that will have excitatory connections to [0], and the last number [8] will have an inhibitory connection to [0]. Now look back at the figure above to fully understand this schematic.  In the left cube 0 is connected by an edge to three other vertices [1, 3, 4]. In the right cube, vertex 8 is in the same position as 0 but has the opposite depth interpretation: 0 and 8 are mutually exclusive interpretations, and their activations should be inversely related using mutual inhibition."
   ],
   "id": "131c687f5964f9a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# First, we create the build matrix with the excitatory and inhibitory connections for each vertex in index form\n",
    "build_matrix = np.zeros((16,5))\n",
    "build_matrix[0,:] = [0, 1, 3, 4, 8]\n",
    "build_matrix[1,:] = [1, 0, 2, 5, 9]\n",
    "build_matrix[2,:] = [2, 1, 3, 6, 10]\n",
    "build_matrix[3,:] = [3, 0, 2, 7, 11]\n",
    "build_matrix[4,:] = [4, 5, 7, 0, 12]\n",
    "build_matrix[5,:] = [5, 4, 6, 1, 13]\n",
    "build_matrix[6,:] = [6, 5, 7, 2, 14]\n",
    "build_matrix[7,:] = [7, 4, 6, 3, 15]\n",
    "build_matrix[8,:] = [8, 9, 11, 12, 0]\n",
    "build_matrix[9,:] = [9, 8, 10, 13, 1]\n",
    "build_matrix[10,:] = [10, 9, 11, 14, 2]\n",
    "build_matrix[11,:] = [11, 8, 10, 15, 3]\n",
    "build_matrix[12,:] = [12, 13, 15, 8, 4]\n",
    "build_matrix[13,:] = [13, 12, 14, 9, 5]\n",
    "build_matrix[14,:] = [14, 13, 15, 10, 6]\n",
    "build_matrix[15,:] = [15, 12, 14, 11, 7]\n",
    "\n",
    "# Ensure the matrix is of integer type since we use them as indices\n",
    "build_matrix = build_matrix.astype(int)\n",
    "build_matrix"
   ],
   "id": "89ecff8dfab8081f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Now we create the necker_matrix with the connection weights using the build_matrix\n",
    "necker_matrix = np.zeros((16,16))\n",
    "necker_matrix = necker_matrix.astype(int)\n",
    "\n",
    "# Set the excitatory and inhibitory connection weights\n",
    "excite = 1\n",
    "inhibit = -2\n",
    "\n",
    "# Fill the necker_matrix with the connection weights\n",
    "for x in range(0,16):\n",
    "    necker_matrix[build_matrix[x,0], build_matrix[x,1]] = excite\n",
    "    necker_matrix[build_matrix[x,0], build_matrix[x,2]] = excite\n",
    "    necker_matrix[build_matrix[x,0], build_matrix[x,3]] = excite\n",
    "    necker_matrix[build_matrix[x,0], build_matrix[x,4]] = inhibit\n",
    "   \n",
    "    \n",
    "necker_matrix"
   ],
   "id": "905ec0470ecf11ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can also visualize the matrix similar to the figures in the [Hebbian Learning section]({{ base_url }}/content/Dynamics%20in%20erception/1%20Hebbian%20learning.ipynb).\n",
    "\n",
    "def plot_correlation_matrix(matrix, mask=None, title=\"Correlation Matrix\", lb=lb, ub=ub):\n",
    "    \"\"\"\n",
    "    Function to plot a correlation matrix with optional masking\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    \n",
    "    if mask is not None:\n",
    "        matrix = np.ma.array(matrix, mask=mask)\n",
    "    plt.imshow(matrix, cmap='RdBu_r', vmin=lb, vmax=ub)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ],
   "id": "a6c5e6702617415a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ub=np.max(np.abs(necker_matrix))\n",
    "lb=-ub\n",
    "\n",
    "plt.xticks(range(16))  # Rotate labels for better visibility\n",
    "plt.yticks(range(16))\n",
    "\n",
    "plt.imshow(necker_matrix, cmap='RdBu_r',vmax=ub)\n",
    "plt.colorbar()"
   ],
   "id": "24f50a2cbade6881",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a composition\n",
    "necker_cube = pnl.Composition()\n",
    "\n",
    "# Set up the TransferMechanisms with Linear functions\n",
    "necker_node_a = pnl.TransferMechanism(\n",
    "    name='necker_node_a',\n",
    "    input_shapes=16,\n",
    "    function=pnl.Linear(),\n",
    "    integrator_mode = True,\n",
    "    integration_rate = .5,\n",
    ")\n",
    "\n",
    "necker_node_b = pnl.TransferMechanism(\n",
    "    name='necker_node_b',\n",
    "    input_shapes=16,\n",
    "    function=pnl.Linear(),\n",
    "    integrator_mode = True,\n",
    "    integration_rate = .5,\n",
    ")\n",
    "\n",
    "# Set up the connections\n",
    "weights_A_B = necker_matrix\n",
    "weights_B_A = necker_matrix\n",
    "\n",
    "connect_A_B = pnl.MappingProjection(\n",
    "    name='connect_A_B',\n",
    "    matrix=weights_A_B,\n",
    ")\n",
    "\n",
    "connect_B_A = pnl.MappingProjection(\n",
    "    name='connect_B_A',\n",
    "    matrix=weights_B_A,\n",
    ")\n",
    "\n",
    "# Add the pathways\n",
    "necker_cube.add_linear_processing_pathway(pathway = (necker_node_a, connect_A_B, necker_node_b, connect_B_A, necker_node_a))\n",
    "\n",
    "necker_node_a.reportOutputPref = True\n",
    "necker_node_b.reportOutputPref = True\n",
    "\n",
    "# Show the model graph\n",
    "necker_cube.show_graph(output_fmt = 'jupyter')"
   ],
   "id": "8686c59ca465a3cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trial_length = 10\n",
    "zero_input = np.zeros([trial_length, 16]) \n",
    "necker_input1 = zero_input\n",
    "necker_input1[0] = np.random.random((1,16))\n",
    "necker_input2 = zero_input\n",
    "# necker_input2[0] = np.random.random((1,16))\n",
    "\n",
    "\n",
    "input_dict = {necker_node_a: necker_input1,\n",
    "             necker_node_b: necker_input2,\n",
    "             }\n",
    "\n",
    "necker_cube.run(input_dict, num_trials = trial_length)"
   ],
   "id": "cef47b93c258be7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "necker_cube.reset(clear_results=True)\n",
    "\n",
    "np.random.seed(0)  # TODO: Try changing the seed to see different results\n",
    "\n",
    "trial_length = 100\n",
    "zero_input = np.zeros([trial_length, 16])\n",
    "necker_input1 = zero_input\n",
    "necker_input1[0] = np.random.random((1, 16))\n",
    "necker_input2 = zero_input\n",
    "necker_input2[0] = np.random.random((1, 16))\n",
    "\n",
    "input_dict = {necker_node_a: necker_input1,\n",
    "              necker_node_b: necker_input2,\n",
    "              }\n",
    "\n",
    "necker_cube.run(inputs=input_dict, num_trials=trial_length)\n",
    "\n",
    "acts = np.squeeze(np.array(necker_cube.results))\n",
    "\n",
    "f, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "# Plot activation of necker_node_a (input 1-8 in red, input 9-16 in blue)    \n",
    "axes[0].plot(acts[:, 0, :8], color='red')\n",
    "axes[0].plot(acts[:, 0, 8:], color='blue')\n",
    "# Plot activation of necker_node_a (input 1-8 in red, input 9-16 in blue)  \n",
    "axes[1].plot(acts[:, 1, :8], color='red')\n",
    "axes[1].plot(acts[:, 1, 8:], color='blue')"
   ],
   "id": "45682a1be40dbdd1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Exercise 5{exercise}\n",
    "\n",
    "The Necker Cube perception models presented here are very simple and have lots of room for improvement. You can modify these models to make them better.  For example, over multiple trials the activations run away to very high and very low values. This is unrealistic - How might you fix this problem?"
   ],
   "id": "fd7503bb2473bb6b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Solution 5{solution}\n",
    "\n",
    "Instead of linear functions, we can use logistic functions that have a bounded output range. This will prevent the activations from running away to very high and very low values. We can also adjust the integration rate to control the rate at which the activations change over time. By tuning the parameters of the logistic functions and the integration rate, we can create a more stable and realistic model of the Necker Cube perception.\n",
    "\n",
    "```python\n",
    "necker_cube_logistic = pnl.Composition()\n",
    "\n",
    "# Set up the TransferMechanisms with Logistic functions\n",
    "necker_node_logistic_a = pnl.TransferMechanism(\n",
    "    name='necker_node_logistic_a',\n",
    "    input_shapes=16,\n",
    "    function=pnl.Logistic(),\n",
    "    integrator_mode = True,\n",
    "    integration_rate = .5,\n",
    ")\n",
    "\n",
    "necker_node_logistic_b = pnl.TransferMechanism(\n",
    "    name='necker_node_logistic_b',\n",
    "    input_shapes=16,\n",
    "    function=pnl.Logistic(),\n",
    "    integrator_mode = True,\n",
    "    integration_rate = .5,\n",
    ")\n",
    "\n",
    "weights_A_B = necker_matrix\n",
    "weights_B_A = necker_matrix\n",
    "\n",
    "connect_A_B = pnl.MappingProjection(\n",
    "    name='connect_A_B',\n",
    "    matrix=weights_A_B,\n",
    ")\n",
    "\n",
    "connect_B_A = pnl.MappingProjection(\n",
    "    name='connect_B_A',\n",
    "    matrix=weights_B_A,\n",
    ")\n",
    "\n",
    "necker_cube_logistic.add_linear_processing_pathway(\n",
    "    pathway = (necker_node_logistic_a, connect_A_B, necker_node_logistic_b, connect_B_A, necker_node_logistic_a)\n",
    ")\n",
    "\n",
    "\n",
    "trial_length = 100\n",
    "zero_input = np.zeros([trial_length, 16])\n",
    "necker_input1 = zero_input\n",
    "necker_input1[0] = np.random.random((1, 16))\n",
    "necker_input2 = zero_input\n",
    "necker_input2[0] = np.random.random((1, 16))\n",
    "\n",
    "input_dict = {necker_node_logistic_a: necker_input1,\n",
    "              necker_node_logistic_b: necker_input2,\n",
    "              }\n",
    "\n",
    "necker_cube_logistic.run(inputs=input_dict, num_trials=trial_length)\n",
    "\n",
    "acts = np.squeeze(np.array(necker_cube_logistic.results))\n",
    "\n",
    "# Plot the activations of the nodes over time\n",
    "f, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "axes[0].plot(acts[:, 0, :8], color='red')\n",
    "axes[0].plot(acts[:, 0, 8:], color='blue')\n",
    "axes[1].plot(acts[:, 1, :8], color='red')\n",
    "axes[1].plot(acts[:, 1, 8:], color='blue')\n",
    "```\n"
   ],
   "id": "fba314751266c260"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Exercise 6{exercise}\n",
    "\n",
    "![duck_rabbit](../duckrabbit.jpeg)\n",
    "\n",
    "Create your own models of bistable perception for the Duck/Rabbit figure. \n",
    "\n",
    "*Requirements*: Your models must include the following 6 features. Ears, Bill, LeftFront, LeftBack, RightFront, RightBack.\n",
    "\n",
    "Follow (6a - 6b) to create your models."
   ],
   "id": "b7e6c9c977315f5b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Exercise 6a**\n",
    "\n",
    "Create a matrix for the Duck/Rabbit model."
   ],
   "id": "61cacd70bd7cddc6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "duck_rabbit_matrix =  # TODO: Your code here\n",
    "\n",
    "ub = np.max(np.abs(duck_rabbit_matrix))\n",
    "lb = -ub\n",
    "\n",
    "plt.xticks(range(16))  # Rotate labels for better visibility\n",
    "plt.yticks(range(16))\n",
    "\n",
    "plt.imshow(duck_rabbit_matrix, cmap='RdBu_r', vmax=ub)\n",
    "plt.colorbar()"
   ],
   "id": "9124143f64c46a71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Hint 6a{hint}\n",
    "\n",
    "Think about a good feature mapping first. Clustering the features into two groups might be a good start."
   ],
   "id": "fbc39b32ce92dc8d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Solution 6a{solution}\n",
    "\n",
    "```python\n",
    "\n",
    "features = ['ears', 'left_front', 'right_back', 'bill', 'left_back', 'right_front']\n",
    "\n",
    "\n",
    "# Here, we create the matrix for the Duck/Rabbit model with connections (without the build_matrix)\n",
    "duck_rabbit_matrix = np.array([\n",
    "    [ 0,  1,  1, -2,  0,  0],  # Ears(0) exibitory to LeftFront(1) and RightBack(2), inhibitory to Bill(3)\n",
    "    [ 1,  0,  1,  0, -2,  0],  # LeftFront(1) exibitory to Ears(0) and RightBack(2), inhibitory to LeftBack(4)\n",
    "    [ 1,  1,  0,  0,  0, -2],  # RightBack(2) exibitory to Ears(0) and LeftFront(1), inhibitory to RightFront(5)\n",
    "    [-2,  0,  0,  0,  1,  1],  # Bill(3) inhibitory to Ears(0), exibitory to LeftBack(4) and RightFront(5)\n",
    "    [ 0, -2,  0,  1,  0,  1],  # LeftBack(4) inhibotry to LeftFront(3), exhibitory to Bill(3) and RightFront(5)\n",
    "    [ 0,  0, -2,  1,  1,  0]   # RightFront(5) inhibitory to RightBack(2), exhibitory to Bill(3) and LeftBack(4)\n",
    "])                      \n",
    "```\n",
    "\n",
    "*Note:* This is just one of multiple possible solutions. The connections can be arranged differently based on the features and their relationships."
   ],
   "id": "f1ef58c5bc695e1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Exercise 6b**\n",
    "\n",
    "Create a model that always arrives one interpretation (depending on a random input)."
   ],
   "id": "cc05631283c422b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a composition\n",
    "duck_rabbit_comp = pnl.Composition()\n",
    "\n",
    "# TODO: Your code here\n",
    "\n",
    "# Show the model graph\n",
    "trial_length = 100\n",
    "zero_input = np.zeros([trial_length, 6])\n",
    "duck_rabbit_input1 = zero_input\n",
    "duck_rabbit_input1[0] = np.random.random((1, 6))\n",
    "duck_rabbit_input2 = zero_input\n",
    "duck_rabbit_input2[0] = np.random.random((1, 6))\n",
    "\n",
    "input_dict =  # TODO: Your code here\n",
    "\n",
    "duck_rabbit_comp.run(inputs=input_dict, num_trials=trial_length)\n",
    "\n",
    "acts = np.squeeze(np.array(duck_rabbit_comp.results))\n",
    "\n",
    "f, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "# Plot activation of necker_node_a (input 1-8 in red, input 9-16 in blue)    \n",
    "axes[0].plot(acts[:, 0, :3], color='red')\n",
    "axes[0].plot(acts[:, 0, 3:], color='blue')\n",
    "# Plot activation of necker_node_a (input 1-8 in red, input 9-16 in blue)  \n",
    "axes[1].plot(acts[:, 1, :3], color='red')\n",
    "axes[1].plot(acts[:, 1, 3:], color='blue')"
   ],
   "id": "dd1b1fdbc95fca4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Solution 6b{solution}       \n",
    "\n",
    "```python\n",
    "# Create a composition\n",
    "duck_rabbit_comp = pnl.Composition()\n",
    "\n",
    "# Set up the TransferMechanisms with Linear functions\n",
    "duck_rabbit_node_a = pnl.TransferMechanism(\n",
    "    name='necker_node_a',\n",
    "    input_shapes=6,\n",
    "    function=pnl.Linear(),\n",
    "    integrator_mode = True,\n",
    "    integration_rate = .5,\n",
    ")\n",
    "\n",
    "duck_rabbit_node_b = pnl.TransferMechanism(\n",
    "    name='duck_rabbit_node_b',\n",
    "    input_shapes=6,\n",
    "    function=pnl.Linear(),\n",
    "    integrator_mode = True,\n",
    "    integration_rate = .5,\n",
    ")\n",
    "\n",
    "# Set up the connections\n",
    "weights_a_b = duck_rabbit_matrix\n",
    "weights_b_a = duck_rabbit_matrix\n",
    "\n",
    "connect_a_b = pnl.MappingProjection(\n",
    "    name='connect_a_b',\n",
    "    matrix=weights_a_b,\n",
    ")\n",
    "\n",
    "connect_b_a = pnl.MappingProjection(\n",
    "    name='connect_b_a',\n",
    "    matrix=weights_b_a,\n",
    ")\n",
    "\n",
    "# Add the pathways\n",
    "duck_rabbit_comp.add_linear_processing_pathway(pathway = (duck_rabbit_node_a, connect_a_b, duck_rabbit_node_b, connect_b_a, duck_rabbit_node_a))\n",
    "\n",
    "\n",
    "# Show the model graph\n",
    "trial_length = 100\n",
    "zero_input = np.zeros([trial_length, 6])\n",
    "duck_rabbit_input1 = zero_input\n",
    "duck_rabbit_input1[0] = np.random.random((1, 6))\n",
    "duck_rabbit_input2 = zero_input\n",
    "duck_rabbit_input2[0] = np.random.random((1, 6))\n",
    "\n",
    "input_dict = {duck_rabbit_node_a: duck_rabbit_input1,\n",
    "              duck_rabbit_node_b: duck_rabbit_input2,\n",
    "              }\n",
    "\n",
    "duck_rabbit_comp.run(inputs=input_dict, num_trials=trial_length)\n",
    "\n",
    "acts = np.squeeze(np.array(duck_rabbit_comp.results))\n",
    "\n",
    "f, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "# Plot activation of necker_node_a (input 1-8 in red, input 9-16 in blue)    \n",
    "axes[0].plot(acts[:, 0, :3], color='red')\n",
    "axes[0].plot(acts[:, 0, 3:], color='blue')\n",
    "# Plot activation of necker_node_a (input 1-8 in red, input 9-16 in blue)  \n",
    "axes[1].plot(acts[:, 1, :3], color='red')\n",
    "axes[1].plot(acts[:, 1, 3:], color='blue')\n",
    "```"
   ],
   "id": "1340170dc9437bf7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Exercise 6c**\n",
    "\n",
    "When looking at some bistable figures, after a certain amount of time your interpretation spontaneously flips to the opposite of what you previously saw.\n",
    "\n",
    "Create a model that oscillates between the two interpretations."
   ],
   "id": "b9e20ddc63ef1d56"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Hint 6c{hint}\n",
    "\n",
    "A simple way to introduce oscillations is to use negative feedback and non-linearity. "
   ],
   "id": "5c179a1b0f3fd5ad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Solution 6c{solution}      \n",
    "\n",
    "```python\n",
    "# Create a composition\n",
    "duck_rabbit_comp = pnl.Composition()\n",
    "\n",
    "# Set up the TransferMechanisms with Linear functions\n",
    "duck_rabbit_node_a = pnl.TransferMechanism(\n",
    "    name='necker_node_a',\n",
    "    input_shapes=6,\n",
    "    function=pnl.Logistic(), # Here, we use the Logistic function to introduce non-linearity\n",
    "    integrator_mode = True,\n",
    "    integration_rate = .5,\n",
    ")\n",
    "\n",
    "duck_rabbit_node_b = pnl.TransferMechanism(\n",
    "    name='duck_rabbit_node_b',\n",
    "    input_shapes=6,\n",
    "    function=pnl.Linear(),\n",
    "    integrator_mode = True,\n",
    "    integration_rate = .5,\n",
    ")\n",
    "\n",
    "# Set up the connections\n",
    "weights_a_b = duck_rabbit_matrix\n",
    "weights_b_a = - 10 * duck_rabbit_matrix # Here we use a negative feedback to create oscillations\n",
    "\n",
    "connect_a_b = pnl.MappingProjection(\n",
    "    name='connect_a_b',\n",
    "    matrix=weights_a_b,\n",
    ")\n",
    "\n",
    "connect_b_a = pnl.MappingProjection(\n",
    "    name='connect_b_a',\n",
    "    matrix=weights_b_a,\n",
    ")\n",
    "\n",
    "# Add the pathways\n",
    "duck_rabbit_comp.add_linear_processing_pathway(pathway = (duck_rabbit_node_a, connect_a_b, duck_rabbit_node_b, connect_b_a, duck_rabbit_node_a))\n",
    "\n",
    "\n",
    "# Show the model graph\n",
    "trial_length = 100\n",
    "zero_input = np.zeros([trial_length, 6])\n",
    "duck_rabbit_input1 = zero_input\n",
    "duck_rabbit_input1[0] = np.random.random((1, 6))\n",
    "duck_rabbit_input2 = zero_input\n",
    "duck_rabbit_input2[0] = np.random.random((1, 6))\n",
    "\n",
    "input_dict = {duck_rabbit_node_a: duck_rabbit_input1,\n",
    "              duck_rabbit_node_b: duck_rabbit_input2,\n",
    "              }\n",
    "\n",
    "duck_rabbit_comp.run(inputs=input_dict, num_trials=trial_length)\n",
    "\n",
    "acts = np.squeeze(np.array(duck_rabbit_comp.results))\n",
    "\n",
    "f, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "# Plot activation of necker_node_a (input 1-8 in red, input 9-16 in blue)    \n",
    "axes[0].plot(acts[:, 0, :3], color='red')\n",
    "axes[0].plot(acts[:, 0, 3:], color='blue')\n",
    "# Plot activation of necker_node_a (input 1-8 in red, input 9-16 in blue)  \n",
    "axes[1].plot(acts[:, 1, :3], color='red')\n",
    "axes[1].plot(acts[:, 1, 3:], color='blue')\n",
    "```\n",
    "\n",
    "*Note:* This is just one out of many solution (with minimal changes from the original code). The oscillations can be created in many different ways, and the model can be improved in many ways. For example, a more plausible way to implement this is by decaying the activations over time. "
   ],
   "id": "c93cffefbb84bd24"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
