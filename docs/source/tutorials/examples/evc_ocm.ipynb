{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Expected Value of Control - OptimizationControlMechanism (EVC - OCM)\n",
    "\n",
    "*Installation and Setup*"
   ],
   "id": "55994abd65189057"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "%pip install psyneulink"
   ],
   "id": "d28639acdf19c150",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "import psyneulink as pnl",
   "id": "d55651f2de90f025",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "First, we model the decision-making process using a Drift Diffusion Model (DDM) with an analytical solution. To model adaptive control, we use reward as input. The reward input can be used to optimize threshold and drift-rate of the DDM.\n",
    "\n",
    "We can think of this as finding the balance between the cost of control, the time it takes to make a decision, and the accuracy of the decision."
   ],
   "id": "ad83149768a123ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "stimulus =  pnl.ProcessingMechanism(name='Stimulus') # Input Stimulus can be seen as SignalToNoise Ratio (SNR) the higher the easier the decision\n",
    "reward = pnl.ProcessingMechanism(name='Reward') # Reward Mechanism\n",
    "\n",
    "decision = pnl.DDM(\n",
    "    name='Decision',\n",
    "    function=pnl.DriftDiffusionAnalytical(\n",
    "        drift_rate=1.0,\n",
    "        threshold=1.0,\n",
    "        noise=0.5,\n",
    "        starting_value=0,\n",
    "        non_decision_time=0.45\n",
    "    ),\n",
    "    output_ports=[pnl.DECISION_VARIABLE,\n",
    "                  pnl.RESPONSE_TIME,\n",
    "                  pnl.PROBABILITY_UPPER_THRESHOLD], # < -- Here, we add the output ports that we want to monitor for optimization of control\n",
    ")"
   ],
   "id": "da4ab064835bddce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's create the composition (first without the control):",
   "id": "6c922e4ba20ab97d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "comp = pnl.Composition(name=\"EVC-OCM\")\n",
    "comp.add_node(reward)\n",
    "comp.add_linear_processing_pathway([stimulus, decision])\n",
    "\n",
    "comp.show_graph(output_fmt='jupyter')"
   ],
   "id": "858f2a1de0698eef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now, we add a controller.\n",
    "\n",
    "First, we create the objective mechanism that will specify the optimization goal. In this case, we want to optimize the reward and probability of being correct, as well as balancing the response time."
   ],
   "id": "33fd08e7f5b74902"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "objective_mechanism = pnl.ObjectiveMechanism(\n",
    "    name='OCM Objective Mechanism',\n",
    "    function=pnl.LinearCombination(operation=pnl.PRODUCT),\n",
    "    monitor=[\n",
    "        reward,  # <-- When a mechanism is monitored, its default output port is monitored\n",
    "        decision.output_ports[pnl.PROBABILITY_UPPER_THRESHOLD], # <-- We monitor the PROBABILITY_UPPER_THRESHOLD output port previously specified as the decision mechanism\n",
    "        (decision.output_ports[pnl.RESPONSE_TIME], -1, 1)] # <-- In addition to an output port, we can also specify a transformation (weight and exponent),here we\n",
    ")"
   ],
   "id": "d05a3baa2c418acc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, we can create the controller and add it to the composition:",
   "id": "11613d0c8217e53e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "controller = pnl.OptimizationControlMechanism(\n",
    "    name = 'OCM',\n",
    "    agent_rep=comp,\n",
    "    state_features=[stimulus.input_port, reward.input_port],\n",
    "    state_feature_function=pnl.AdaptiveIntegrator(rate=0.5), # <- Instead of the current input the input and the last state of the input are integrated via this function (This simulates a \"sliding window over average\" of input and reward)\n",
    "    objective_mechanism=objective_mechanism,\n",
    "    function=pnl.GridSearch(),\n",
    "    control_signals=[\n",
    "        pnl.ControlSignal(modulates=(pnl.DRIFT_RATE, decision), allocation_samples=[0.1, 0.3, 0.5, 0.7, 0.9]),\n",
    "        pnl.ControlSignal(modulates=(pnl.THRESHOLD, decision), allocation_samples=[0.1, 0.3, 0.5, 0.7, 0.9]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "comp.add_controller(controller)"
   ],
   "id": "133c698796fd1447",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's look at the composition again, this time with the controller:",
   "id": "39189c6e43738f03"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "comp.show_graph(show_controller=True)",
   "id": "e1abe72e56d708ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "And run this on some example data:",
   "id": "7f04aa17e975e4f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "stim_list_dict = {\n",
    "    stimulus: [0.5, 0.123],\n",
    "    reward: [10, 20]\n",
    "}\n",
    "\n",
    "comp.run(inputs=stim_list_dict)\n",
    "\n",
    "print(comp.results)"
   ],
   "id": "2b90e5c495adaac3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
