


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>AutodiffComposition &mdash; PsyNeuLink 0.15.2.0+40.gf91e2a1e2 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="CompositionFunctionApproximator" href="CompositionFunctionApproximator.html" />
    <link rel="prev" title="Compositions" href="Compositions.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://princetonuniversity.github.io/PsyNeuLink/"></a>
<!--      <a class="header-logo"></a>-->
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/PrincetonUniversity/PsyNeuLink">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="psyneulink-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="psyneulink-left-menu" id="psyneulink-left-menu">
      <div class="psyneulink-side-scroll">
        <div class="psyneulink-menu psyneulink-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="psyneulink-left-menu-search">
            

            
              
              
                <div class="version">
                  0.15.2.0+40
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="index.html">Welcome to PsyNeuLink </a></li>
<li class="toctree-l1"><a class="reference internal" href="BasicsAndPrimer.html">Basics and Primer</a></li>
<li class="toctree-l1"><a class="reference internal" href="QuickReference.html">Quick Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="Core.html">Core</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="Library.html">Library</a></li>
<li class="toctree-l1"><a class="reference internal" href="ContributorsGuide.html">Contributors Guide</a></li>
</ul>

            
          
          <div class="psyneulink-dev-mode-toggle">
          </div>
        </div>
      </div>
    </nav>
    <div class="psyneulink-container">
      <div class="psyneulink-page-level-bar" id="psyneulink-page-level-bar">
        <div class="psyneulink-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="psyneulink-breadcrumbs">
    
      <li>
        <a href="index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="Library.html">Library</a> &gt;</li>
        
          <li><a href="Compositions.html">Compositions</a> &gt;</li>
        
      <li>AutodiffComposition</li>
    
  </ul>

  
</div>
        </div>

        <div class="psyneulink-shortcuts-wrapper" id="psyneulink-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="psyneulink-content-wrap" class="psyneulink-content-wrap">
        <div class="psyneulink-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="psyneulink-article" class="psyneulink-article">
              
  <section id="autodiffcomposition">
<h1>AutodiffComposition<a class="headerlink" href="#autodiffcomposition" title="Permalink to this headline">¶</a></h1>
<div class="related docutils container">
<p><em>Related</em></p>
<ul class="simple">
<li><p><a class="reference internal" href="Composition.html#composition-learning"><span class="std std-ref">Learning in a Composition</span></a></p></li>
</ul>
</div>
<span class="target" id="module-psyneulink.library.compositions.autodiffcomposition"></span><section id="contents">
<h2>Contents<a class="headerlink" href="#contents" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><ul>
<li><p><a class="reference internal" href="#autodiffcomposition-overview"><span class="std std-ref">Overview</span></a></p></li>
<li><p><a class="reference internal" href="#autodiffcomposition-creation"><span class="std std-ref">Creating an AutodiffComposition</span></a>
- <code class="xref any docutils literal notranslate"><span class="pre">AutodiffComposition_</span></code></p>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference internal" href="#autodiffcomposition-modulatory-mechanisms"><span class="std std-ref">Only one OutputPort per Node</span></a></p></li>
<li><p><a class="reference internal" href="#autodiffcomposition-bias-parameters"><span class="std std-ref">No Bias Parameters</span></a></p></li>
<li><p><a class="reference internal" href="#autodiffcomposition-nesting"><span class="std std-ref">Nesting</span></a></p></li>
<li><p><a class="reference internal" href="#autodiffcomposition-post-construction-modification"><span class="std std-ref">No Post-construction Modification</span></a></p></li>
</ul>
</div></blockquote>
<ul class="simple">
<li><p><a class="reference internal" href="#autodiffcomposition-execution"><span class="std std-ref">Execution</span></a>
- <a class="reference internal" href="#autodiffcomposition-pytorch"><span class="std std-ref">PyTorch mode</span></a>
- <a class="reference internal" href="#autodiffcomposition-llvm"><span class="std std-ref">LLVM mode</span></a>
- <a class="reference internal" href="#autodiffcomposition-python"><span class="std std-ref">Python mode</span></a>
- <a class="reference internal" href="#autodiffcomposition-nested-modulation"><span class="std std-ref">Nested Execution and Modulation</span></a>
- <a class="reference internal" href="#autodiffcomposition-logging"><span class="std std-ref">Logging</span></a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#autodiffcomposition-examples"><span class="std std-ref">Examples</span></a></p></li>
<li><p><a class="reference internal" href="#autodiffcomposition-class-reference"><span class="std std-ref">Class Reference</span></a></p></li>
</ul>
</div></blockquote>
</section>
<section id="overview">
<span id="autodiffcomposition-overview"></span><h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>AutodiffComposition is a subclass of <a class="reference internal" href="Composition.html"><span class="doc">Composition</span></a> for constructing and training feedforward neural network
either, using either direct compilation (to LLVM) or automatic conversion to <a class="reference external" href="https://pytorch.org/">PyTorch</a>,
both of which considerably accelerate training (by as much as three orders of magnitude) compared to the
<a class="reference internal" href="Composition.html#composition-learning-standard"><span class="std std-ref">standard implementation of learning</span></a> in a Composition.  Although an
AutodiffComposition is constructed and executed in much the same way as a standard Composition, it largely restricted
to feedforward neural networks using <a class="reference internal" href="Composition.html#composition-learning-supervised"><span class="std std-ref">supervised learning</span></a>, and in particular the
the <a class="reference external" href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation learning algorithm</a>. although it can be used for
some forms of <a class="reference internal" href="Composition.html#composition-learning-unsupervised"><span class="std std-ref">unsupervised learning</span></a> that are supported in PyTorch (e.g.,
<a class="reference external" href="https://github.com/giannisnik/som">self-organized maps</a>).</p>
</section>
<section id="creating-an-autodiffcomposition">
<span id="autodiffcomposition-creation"></span><h2>Creating an AutodiffComposition<a class="headerlink" href="#creating-an-autodiffcomposition" title="Permalink to this headline">¶</a></h2>
<p>An AutodiffComposition can be created by calling its constructor, and then adding <a class="reference internal" href="Component.html"><span class="doc">Components</span></a> using
the standard <a class="reference internal" href="Composition.html#composition-creation"><span class="std std-ref">Composition methods</span></a> for doing so (e.g., <a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.Composition.add_node" title="psyneulink.core.compositions.composition.Composition.add_node"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">add_node</span></code></a>,
<a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.Composition.add_projections" title="psyneulink.core.compositions.composition.Composition.add_projections"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">add_projection</span></code></a>,  <a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.Composition.add_linear_processing_pathway" title="psyneulink.core.compositions.composition.Composition.add_linear_processing_pathway"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">add_linear_processing_pathway</span></code></a>, etc.). The constructor also includes a number of parameters that are
specific to the AutodiffComposition (see <a class="reference internal" href="#autodiffcomposition-class-reference"><span class="std std-ref">Class Reference</span></a> for a list of these parameters,
and <a class="reference internal" href="#autodiffcomposition-examples"><span class="std std-ref">examples</span></a> below). While an AutodiffComposition can generally be created using the
same methods as a standard Composition, there are a few restrictions that apply to its construction, summarized below.</p>
<section id="only-one-outputport-per-node">
<span id="autodiffcomposition-modulatory-mechanisms"></span><span id="autodiffcomposition-restrictions"></span><h3><em>Only one OutputPort per Node</em><a class="headerlink" href="#only-one-outputport-per-node" title="Permalink to this headline">¶</a></h3>
<p>The <a class="reference internal" href="Composition.html#composition-nodes"><span class="std std-ref">Nodes</span></a> of an AutodiffComposition currently can have only <em>one</em> <a class="reference internal" href="OutputPort.html"><span class="doc">OutputPort</span></a>, though that
can have more than one <a class="reference internal" href="Port.html#psyneulink.core.components.ports.port.Port_Base.efferents" title="psyneulink.core.components.ports.port.Port_Base.efferents"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">efferent</span></code></a> <a class="reference internal" href="MappingProjection.html"><span class="doc">MappingProjection</span></a>.  Nodes can also have more than one
<a class="reference internal" href="InputPort.html"><span class="doc">InputPort</span></a>, that can receive more than one <a class="reference internal" href="Port.html#psyneulink.core.components.ports.port.Port_Base.path_afferents" title="psyneulink.core.components.ports.port.Port_Base.path_afferents"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">afferent</span> <span class="pre">`path_afferent</span></code></a> Projections.</p>
</section>
<section id="no-modulatory-components">
<h3><em>No Modulatory Components</em><a class="headerlink" href="#no-modulatory-components" title="Permalink to this headline">¶</a></h3>
<p>All of the Components in an AutodiffComposition must be able to be subjected to <a class="reference internal" href="Composition.html#composition-learning"><span class="std std-ref">learning</span></a>,
which means that no <a class="reference internal" href="ModulatoryMechanism.html"><span class="doc">ModulatoryMechanisms</span></a> can be included in an AutodiffComposition.
Specifically, this precludes any <a class="reference internal" href="Composition.html#composition-learning-components"><span class="std std-ref">learning components</span></a>, <a class="reference internal" href="ControlMechanism.html"><span class="doc">ControlMechanisms</span></a>, or a <a class="reference internal" href="Composition.html#composition-controller"><span class="std std-ref">controller</span></a>.</p>
<p id="autodiff-learning-components-warning"><em>Learning Components.</em>  An AutodiffComposition <strong>cannot include any</strong> <a class="reference internal" href="Composition.html#composition-learning-components"><span class="std std-ref">learning components</span></a> themselves (i.e., <a class="reference internal" href="LearningMechanism.html"><span class="doc">LearningMechanisms</span></a>, <a class="reference internal" href="LearningSignal.html"><span class="doc">LearningSignals</span></a>, or LearningProjections &lt;LearningProjection&gt;`, nor the <code class="xref any docutils literal notranslate"><span class="pre">ComparatorMechanism</span></code>
or <a class="reference internal" href="Composition.html#objective-mechanism"><span class="std std-ref">ObjectiveMechanism</span></a> used to compute the loss for learning). These are constructed
automatically when learning is executed in <a class="reference internal" href="#autodiffcomposition-python"><span class="std std-ref">Python mode</span></a> or <a class="reference internal" href="#autodiffcomposition-llvm"><span class="std std-ref">LLVM mode</span></a>, and PyTorch-compatible Components are constructed when it is executed in <a class="reference internal" href="#autodiffcomposition-pytorch"><span class="std std-ref">PyTorch mode</span></a>.</p>
<p><em>Control Components.</em>  An AutodiffComposition also cannot include any <a class="reference internal" href="ControlMechanism.html"><span class="doc">ControlMechanisms</span></a> or a
<a class="reference internal" href="Composition.html#composition-controller"><span class="std std-ref">controller</span></a>.  However, it <em>can</em> include Mechanisms that are subject to modulatory control
(see <a class="reference internal" href="ModulatorySignal.html#modulatorysignal-anatomy-figure"><span class="std std-ref">Figure</span></a>, and <a class="reference internal" href="ModulatorySignal.html#modulatorysignal-modulation"><span class="std std-ref">modulation</span></a>) by ControlMechanisms
<em>outside</em> the Composition, including the controller of a Composition within which the AutodiffComposition is nested.
That is, an AutodiffComposition can be <a class="reference internal" href="Composition.html#composition-nested"><span class="std std-ref">nested in a Composition</span></a> that has such other Components
(see <a class="reference internal" href="#autodiffcomposition-nested-modulation"><span class="std std-ref">Nested Execution and Modulation</span></a> below).</p>
</section>
<section id="no-bias-parameters">
<span id="autodiffcomposition-bias-parameters"></span><h3><em>No Bias Parameters</em><a class="headerlink" href="#no-bias-parameters" title="Permalink to this headline">¶</a></h3>
<p>AutodiffComposition does not (currently) support the <em>automatic</em> construction of separate bias parameters.
Thus, when constructing a model using an AutodiffComposition that corresponds to one in PyTorch, the <code class="xref any docutils literal notranslate"><span class="pre">bias</span></code> parameter of PyTorch modules should be set
to <code class="xref any docutils literal notranslate"><span class="pre">False</span></code>.</p>
<blockquote>
<div><p>Trainable biases <em>can</em> be specified explicitly in an AutodiffComposition by including a <a class="reference internal" href="ProcessingMechanism.html"><span class="doc">ProcessingMechanism</span></a>
that projects to the relevant Mechanism (i.e., implementing that layer of the network to receive the biases)
using a <a class="reference internal" href="MappingProjection.html"><span class="doc">MappingProjection</span></a> with a <a class="reference internal" href="MappingProjection.html#psyneulink.core.components.projections.pathway.mappingprojection.MappingProjection.matrix" title="psyneulink.core.components.projections.pathway.mappingprojection.MappingProjection.matrix"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">matrix</span></code></a> parameter that implements a diagnoal
matrix with values corresponding to the initial value of the biases, and setting the <a class="reference internal" href="InputPort.html#psyneulink.core.components.ports.inputport.InputPort.default_input" title="psyneulink.core.components.ports.inputport.InputPort.default_input"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">default_input</span></code></a> Parameter of one of the ProcessingMechanism’s <a class="reference internal" href="Mechanism.html#psyneulink.core.components.mechanisms.mechanism.Mechanism_Base.input_ports" title="psyneulink.core.components.mechanisms.mechanism.Mechanism_Base.input_ports"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">input_ports</span></code></a> to <em>DEFAULT_VARIABLE</em>, and its <code class="xref any docutils literal notranslate"><span class="pre">default_variable</span></code>
equal to 1. ProcessingMechanisms configured in this way are assigned <a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.NodeRole" title="psyneulink.core.compositions.composition.NodeRole"><code class="xref any py py-class docutils literal notranslate"><span class="pre">NodeRole</span></code></a> <a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.NodeRole.BIAS" title="psyneulink.core.compositions.composition.NodeRole.BIAS"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">BIAS</span></code></a>, and the MappingProjection
is subject to learning.</p>
</div></blockquote>
</section>
<section id="nesting">
<span id="autodiffcomposition-nesting"></span><h3><em>Nesting</em><a class="headerlink" href="#nesting" title="Permalink to this headline">¶</a></h3>
<p>An AutodiffComposition can be <a class="reference internal" href="Composition.html#composition-nested"><span class="std std-ref">nested</span></a> inside another Composition for learning, and there can
be any level of such nestings.  However, all of the nested Compositions must be AutodiffCompositions. Furthermore, all
nested Compositions use the <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learning_rate" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learning_rate"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">learning_rate</span></code></a> specified for the outermost Composition,
whether this is specified in the call to its <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learn" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learn"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">learn</span></code></a> method, its constructor, or its
default value is being used (see <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learning_rate" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learning_rate"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">learning_rate</span></code></a> below for additional details).</p>
<div class="technical-note docutils container">
<p>Projections from <a class="reference internal" href="Composition.html#composition-nodes"><span class="std std-ref">Nodes</span></a> in an immediately enclosing outer Composition to the <a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.Composition.input_CIM" title="psyneulink.core.compositions.composition.Composition.input_CIM"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">input_CIM</span></code></a> of a nested Composition, and from its <a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.Composition.output_CIM" title="psyneulink.core.compositions.composition.Composition.output_CIM"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">output_CIM</span></code></a> to Nodes
in the outer Composition are subject to learning;  however those within the nested Composition itself (i.e.,
from its input_CIM to its INPUT Nodes and from its OUTPUT Nodes to its output_CIM) are <em>not</em> subject to learning,
as they serve simply as conduits of information between the outer Composition and the nested one.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Nested Compositions are supported for learning only in <a class="reference internal" href="#autodiffcomposition-pytorch"><span class="std std-ref">PyTorch mode</span></a>, and will
cause an error if the <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learn" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learn"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">learn</span></code></a> method of an AutodiffComposition is executed in
<a class="reference internal" href="#autodiffcomposition-python"><span class="std std-ref">Python mode</span></a> or <a class="reference internal" href="#autodiffcomposition-llvm"><span class="std std-ref">LLVM mode</span></a>.</p>
</div>
</section>
<section id="no-post-construction-modification">
<span id="autodiffcomposition-post-construction-modification"></span><h3><em>No Post-construction Modification</em><a class="headerlink" href="#no-post-construction-modification" title="Permalink to this headline">¶</a></h3>
<p>Mechanisms or Projections should not be added to or deleted from an AutodiffComposition after it has
been executed. Unlike an ordinary Composition, AutodiffComposition does not support this functionality.</p>
</section>
</section>
<section id="execution">
<span id="autodiffcomposition-execution"></span><h2>Execution<a class="headerlink" href="#execution" title="Permalink to this headline">¶</a></h2>
<p>An AutodiffComposition’s <a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.Composition.run" title="psyneulink.core.compositions.composition.Composition.run"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">run</span></code></a>, <a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.Composition.execute" title="psyneulink.core.compositions.composition.Composition.execute"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">execute</span></code></a>, and <a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.Composition.learn" title="psyneulink.core.compositions.composition.Composition.learn"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">learn</span></code></a>
methods are the same as for a <a class="reference internal" href="Composition.html"><span class="doc">Composition</span></a>.  However, the <strong>execution_mode</strong> in the <a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.Composition.learn" title="psyneulink.core.compositions.composition.Composition.learn"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">learn</span></code></a>
method has different effects than for a standard Composition, that determine whether it uses <a class="reference internal" href="#autodiffcomposition-llvm"><span class="std std-ref">LLVM compilation</span></a> or <a class="reference internal" href="#autodiffcomposition-pytorch"><span class="std std-ref">translation to PyTorch</span></a> to execute learning.
These are each described in greater detail below, and summarized in this <a class="reference internal" href="Composition.html#composition-compilation-table"><span class="std std-ref">table</span></a>
which provides a comparison of the different modes of execution for an AutodiffComposition and standard <a class="reference internal" href="Composition.html"><span class="doc">Composition</span></a>.</p>
<section id="pytorch-mode">
<span id="autodiffcomposition-pytorch"></span><h3><em>PyTorch mode</em><a class="headerlink" href="#pytorch-mode" title="Permalink to this headline">¶</a></h3>
<p># 7/10/24 - FIX:
.. _AutodiffComposition_PyTorch_LearningScale:</p>
<blockquote>
<div><dl>
<dt>ADD DESCRIPTION OF HOW LearningScale SPECIFICATIONS MAP TO EXECUTOIN OF pytorch_rep:</dt><dd><p>OPTIMIZATION STEP:
for AutodiffCompositions, this corresponds to a single call to <code class="xref any docutils literal notranslate"><span class="pre">foward()</span></code> and <code class="xref any docutils literal notranslate"><span class="pre">backward()</span></code></p>
<blockquote>
<div><p>methods of the Pytorch model</p>
</div></blockquote>
</dd>
</dl>
</div></blockquote>
<p>This is the default for an AutodiffComposition, but, can be specified explicitly by setting <strong>execution_mode</strong> =
<a class="reference internal" href="LLVM.html#psyneulink.core.llvm.__init__.ExecutionMode.PyTorch" title="psyneulink.core.llvm.__init__.ExecutionMode.PyTorch"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">ExecutionMode.PyTorch</span></code></a> in the <a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.Composition.learn" title="psyneulink.core.compositions.composition.Composition.learn"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">learn</span></code></a> method (see <a class="reference internal" href="BasicsAndPrimer.html#basicsandprimer-rumelhart-model"><span class="std std-ref">example</span></a>
in <a class="reference internal" href="BasicsAndPrimer.html"><span class="doc">Basics and Primer</span></a>).  In this mode, the AutodiffComposition is automatically translated to a <a class="reference external" href="https://pytorch.org">PyTorch</a> model for learning.  This is comparable in speed to <code class="xref any docutils literal notranslate"><span class="pre">LLVM</span> <span class="pre">compilation</span></code>, but provides greater flexiblity, including the ability to include nested
AutoDiffCompositions in learning. Although it is best suited for use with <a class="reference internal" href="Composition.html#composition-learning-supervised"><span class="std std-ref">supervised learning</span></a>, it can also be used for some forms of <a class="reference internal" href="Composition.html#composition-learning-unsupervised"><span class="std std-ref">unsupervised learning</span></a> that are supported in PyTorch (e.g., <a class="reference external" href="https://github.com/giannisnik/som">self-organized maps</a>).</p>
<blockquote>
<div><div class="admonition note" id="autodiffcomposition-pytorch-note">
<p class="admonition-title">Note</p>
<p>While specifying <a class="reference internal" href="LLVM.html#psyneulink.core.llvm.__init__.ExecutionMode.PyTorch" title="psyneulink.core.llvm.__init__.ExecutionMode.PyTorch"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">ExecutionMode.PyTorch</span></code></a> in the <a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.Composition.learn" title="psyneulink.core.compositions.composition.Composition.learn"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">learn</span></code></a>  method of an AutodiffComposition
causes it to use PyTorch for training, specifying this in the <code class="xref any docutils literal notranslate"><span class="pre">run</span></code> method causes it to be
executed using the <em>Python</em> interpreter (and not PyTorch);  this is so that any modulation can take effect
during execution (see <a class="reference internal" href="#autodiffcomposition-nested-modulation"><span class="std std-ref">Nested Execution and Modulation</span></a> below), which is not supported by PyTorch.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><p>Specifying <a class="reference internal" href="LLVM.html#psyneulink.core.llvm.__init__.ExecutionMode.LLVM" title="psyneulink.core.llvm.__init__.ExecutionMode.LLVM"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">ExecutionMode.LLVM</span></code></a> or <a class="reference internal" href="LLVM.html#psyneulink.core.llvm.__init__.ExecutionMode.PyTorch" title="psyneulink.core.llvm.__init__.ExecutionMode.PyTorch"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">ExecutionMode.PyTorch</span></code></a> in the learn() method of a standard
<a class="reference internal" href="Composition.html"><span class="doc">Composition</span></a> causes an error.</p></li>
</ul>
</div>
</div></blockquote>
</section>
<section id="llvm-mode">
<span id="autodiffcomposition-llvm"></span><h3><em>LLVM mode</em><a class="headerlink" href="#llvm-mode" title="Permalink to this headline">¶</a></h3>
<p>This is specified by setting <strong>execution_mode</strong> = <a class="reference internal" href="LLVM.html#psyneulink.core.llvm.__init__.ExecutionMode.LLVMRun" title="psyneulink.core.llvm.__init__.ExecutionMode.LLVMRun"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">ExecutionMode.LLVMRun</span></code></a> in the <a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.Composition.learn" title="psyneulink.core.compositions.composition.Composition.learn"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">learn</span></code></a> method
of an AutodiffCompositon.  This provides the fastest performance, but is limited to <a class="reference internal" href="Composition.html#composition-learning-supervised"><span class="std std-ref">supervised learning</span></a> using the <a class="reference internal" href="LearningFunctions.html#psyneulink.core.components.functions.learningfunctions.BackPropagation" title="psyneulink.core.components.functions.learningfunctions.BackPropagation"><code class="xref any py py-class docutils literal notranslate"><span class="pre">BackPropagation</span></code></a> algorithm. This can be run using standard forms of
loss, including mean squared error (MSE) and cross entropy, by specifying this in the <strong>loss_spec</strong> argument of
the constructor (see <a class="reference internal" href="#autodiffcomposition-class-reference"><span class="std std-ref">AutodiffComposition</span></a> for additional details, and
<a class="reference internal" href="Composition.html#composition-compiled-modes"><span class="std std-ref">Compilation Modes</span></a> for more information about executing a Composition in compiled mode.</p>
<blockquote>
<div><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Specifying <code class="xref any docutils literal notranslate"><span class="pre">ExecutionMode.LLVMRUn</span></code> in either the <a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.Composition.learn" title="psyneulink.core.compositions.composition.Composition.learn"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">learn</span></code></a> and <a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.Composition.run" title="psyneulink.core.compositions.composition.Composition.run"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">run</span></code></a>
methods of an AutodiffComposition causes it to (attempt to) use compiled execution in both cases; this is
because LLVM compilation supports the use of modulation in PsyNeuLink models (as compared to <a class="reference internal" href="#autodiffcomposition-pytorch"><span class="std std-ref">PyTorch mode</span></a>; see <a class="reference internal" href="#autodiffcomposition-pytorch-note"><span class="std std-ref">note</span></a> below).</p>
</div>
</div></blockquote>
</section>
<section id="python-mode">
<span id="autodiffcomposition-python"></span><h3><em>Python mode</em><a class="headerlink" href="#python-mode" title="Permalink to this headline">¶</a></h3>
<p>An AutodiffComposition can also be run using the standard PsyNeuLink learning components.  However, this cannot
be used if the AutodiffComposition has any nested Compositions, irrespective of whether they are ordinary
Compositions or AutodiffCompositions.</p>
</section>
<section id="nested-execution-and-modulation">
<span id="autodiffcomposition-nested-modulation"></span><h3><em>Nested Execution and Modulation</em><a class="headerlink" href="#nested-execution-and-modulation" title="Permalink to this headline">¶</a></h3>
<p># FIX:
Like any other <a class="reference internal" href="Composition.html"><span class="doc">Composition</span></a>, an AutodiffComposition may be <a class="reference internal" href="Composition.html#composition-nested"><span class="std std-ref">nested</span></a> inside another
(see <a class="reference internal" href="#autodiffcomposition-nested-example"><span class="std std-ref">example</span></a> below).  However, during learning, none of the internal
Components of the AutodiffComposition (e.g., intermediate layers of a neural network model) are accessible to the
other Components of the outer Composition, (e.g., as sources of information, or for <a class="reference internal" href="ModulatorySignal.html#modulatorysignal-modulation"><span class="std std-ref">modulation</span></a>).  However, when
it is executed using its <a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.Composition.run" title="psyneulink.core.compositions.composition.Composition.run"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">run</span></code></a> method, then the  AutodiffComposition functions like any other,
and all of its internal Components are accessible to other Components of the outer Composition. Thus, as long as access
to its internal Components is not needed during learning, an <a class="reference internal" href="#"><span class="doc">AutodiffComposition</span></a> can be trained, and then used to
execute the trained Composition like any other.</p>
</section>
<section id="logging">
<span id="autodiffcomposition-logging"></span><h3><em>Logging</em><a class="headerlink" href="#logging" title="Permalink to this headline">¶</a></h3>
<p>Logging in AutodiffCompositions follows the same procedure as <a class="reference internal" href="Log.html"><span class="doc">logging in a Composition</span></a>.
However, since an AutodiffComposition internally converts all of its Mechanisms either to LLVM
or to an equivalent PyTorch model, then its inner components are not actually executed. This means that there is
limited support for logging parameters of components inside an AutodiffComposition; Currently, the only supported
parameters are:</p>
<ol class="arabic simple">
<li><p>the <a class="reference internal" href="KohonenMechanism.html#psyneulink.library.components.mechanisms.processing.transfer.kohonenmechanism.KohonenMechanism.matrix" title="psyneulink.library.components.mechanisms.processing.transfer.kohonenmechanism.KohonenMechanism.matrix"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">matrix</span></code></a> parameter of Projections</p></li>
<li><p>the <a class="reference internal" href="LCControlMechanism.html#psyneulink.library.components.mechanisms.modulatory.control.agt.lccontrolmechanism.LCControlMechanism.value" title="psyneulink.library.components.mechanisms.modulatory.control.agt.lccontrolmechanism.LCControlMechanism.value"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">value</span></code></a> parameter of its inner components</p></li>
</ol>
<p class="rubric" id="autodiffcomposition-examples">Examples</p>
<p id="autodiffcomposition-creation-example">The following is an example showing how to create a simple AutodiffComposition, specify its inputs and targets,
and run it with learning enabled and disabled:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">psyneulink</span> <span class="k">as</span> <span class="nn">pnl</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Set up PsyNeuLink Components</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">my_mech_1</span> <span class="o">=</span> <span class="n">pnl</span><span class="o">.</span><span class="n">TransferMechanism</span><span class="p">(</span><span class="n">function</span><span class="o">=</span><span class="n">pnl</span><span class="o">.</span><span class="n">Linear</span><span class="p">,</span> <span class="n">input_shapes</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">my_mech_2</span> <span class="o">=</span> <span class="n">pnl</span><span class="o">.</span><span class="n">TransferMechanism</span><span class="p">(</span><span class="n">function</span><span class="o">=</span><span class="n">pnl</span><span class="o">.</span><span class="n">Linear</span><span class="p">,</span> <span class="n">input_shapes</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">my_projection</span> <span class="o">=</span> <span class="n">pnl</span><span class="o">.</span><span class="n">MappingProjection</span><span class="p">(</span><span class="n">matrix</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span>
<span class="gp">... </span>                    <span class="n">sender</span><span class="o">=</span><span class="n">my_mech_1</span><span class="p">,</span>
<span class="gp">... </span>                    <span class="n">receiver</span><span class="o">=</span><span class="n">my_mech_2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create AutodiffComposition</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">my_autodiff</span> <span class="o">=</span> <span class="n">pnl</span><span class="o">.</span><span class="n">AutodiffComposition</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">my_autodiff</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">my_mech_1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">my_autodiff</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">my_mech_2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">my_autodiff</span><span class="o">.</span><span class="n">add_projection</span><span class="p">(</span><span class="n">sender</span><span class="o">=</span><span class="n">my_mech_1</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="n">my_projection</span><span class="p">,</span> <span class="n">receiver</span><span class="o">=</span><span class="n">my_mech_2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Specify inputs and targets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">my_inputs</span> <span class="o">=</span> <span class="p">{</span><span class="n">my_mech_1</span><span class="p">:</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">my_targets</span> <span class="o">=</span> <span class="p">{</span><span class="n">my_mech_2</span><span class="p">:</span> <span class="p">[[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="n">my_inputs</span><span class="p">,</span> <span class="s2">&quot;targets&quot;</span><span class="p">:</span> <span class="n">my_targets</span><span class="p">,</span> <span class="s2">&quot;epochs&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Run Composition in learnng mode</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">my_autodiff</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">input_dict</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Run Composition in test mode</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">my_autodiff</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">input_dict</span><span class="p">[</span><span class="s1">&#39;inputs&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p id="autodiffcomposition-nested-example">The following shows how the AutodiffComposition created in the previous example can be nested and run inside another
Composition:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create outer composition</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">my_outer_composition</span> <span class="o">=</span> <span class="n">pnl</span><span class="o">.</span><span class="n">Composition</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">my_outer_composition</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">my_autodiff</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Specify dict containing inputs and targets for nested Composition</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">training_input</span> <span class="o">=</span> <span class="p">{</span><span class="n">my_autodiff</span><span class="p">:</span> <span class="n">input_dict</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Run in learning mode</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result1</span> <span class="o">=</span> <span class="n">my_outer_composition</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">training_input</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="class-reference">
<span id="autodiffcomposition-class-reference"></span><h2>Class Reference<a class="headerlink" href="#class-reference" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">psyneulink.library.compositions.autodiffcomposition.</span></span><span class="sig-name descname"><span class="pre">AutodiffComposition</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pathways</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sgd'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_spec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Loss.MSE</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_decay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disable_learning</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force_no_retain_graph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">refresh_losses</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">synch_projection_matrices_with_torch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'run'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">synch_node_variables_with_torch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">synch_node_values_with_torch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'run'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">synch_results_with_torch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'run'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retain_torch_trained_outputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'minibatch'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retain_torch_targets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'minibatch'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retain_torch_losses</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'minibatch'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disable_cuda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cuda_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'autodiff_composition'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>AutodiffComposition(                                optimizer_type=’sgd’,</dt><dd><p>loss_spec=Loss.MSE,
weight_decay=0,
learning_rate=0.001,
disable_learning=False,
synch_projection_matrices_with_torch=RUN,
synch_node_variables_with_torch=None,
synch_node_values_with_torch=RUN,
synch_results_with_torch=RUN,
retain_torch_trained_outputs=MINIBATCH,
retain_torch_targets=MINIBATCH,
retain_torch_losses=MINIBATCH,
device=CPU
)</p>
</dd>
</dl>
<p>Subclass of <a class="reference internal" href="Composition.html"><span class="doc">Composition</span></a> that trains models using either LLVM compilation or <a class="reference external" href="https://pytorch.org">PyTorch</a>;
see and <a class="reference internal" href="Composition.html#composition-class-reference"><span class="std std-ref">Composition</span></a> for additional arguments and attributes.  See <a class="reference internal" href="Composition.html"><span class="doc">Composition</span></a>
for additional arguments to constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer_type</strong> (<em>str : default 'sgd'</em>) – the kind of optimizer used in training. The current options are ‘sgd’ or ‘adam’.</p></li>
<li><p><strong>loss_spec</strong> (<a class="reference internal" href="Keywords.html#psyneulink.core.globals.keywords.Loss" title="psyneulink.core.globals.keywords.Loss"><em>Loss</em></a><em> or </em><em>PyTorch loss function : default Loss.MSE</em>) – specifies the loss function for training; see <a class="reference internal" href="Keywords.html#psyneulink.core.globals.keywords.Loss" title="psyneulink.core.globals.keywords.Loss"><code class="xref any py py-class docutils literal notranslate"><span class="pre">Loss</span></code></a> for arguments.</p></li>
<li><p><strong>weight_decay</strong> (<em>float : default 0</em>) – specifies the L2 penalty (which discourages large weights) used by the optimizer.</p></li>
<li><p><strong>learning_rate</strong> (<em>float : default 0.001</em>) – specifies the learning rate passed to the optimizer if none is specified in the <code class="xref any docutils literal notranslate"><span class="pre">learn</span></code> method of the AutodiffComposition;
see <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learning_rate" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learning_rate"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">learning_rate</span></code></a> for additional details.</p></li>
<li><p><strong>disable_learning</strong> (<em>bool: default False</em>) – specifies whether the AutodiffComposition should disable learning when run in <a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.Composition.learn" title="psyneulink.core.compositions.composition.Composition.learn"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">learning</span> <span class="pre">mode</span></code></a>.</p></li>
<li><p><strong>synch_projection_matrices_with_torch</strong> (<code class="xref any docutils literal notranslate"><span class="pre">LearningScale</span></code> : default RUN) – specifies the default for the AutodiffComposition for when to copy Pytorch parameters to PsyNeuLink
<a class="reference internal" href="MappingProjection.html#psyneulink.core.components.projections.pathway.mappingprojection.MappingProjection.matrix" title="psyneulink.core.components.projections.pathway.mappingprojection.MappingProjection.matrix"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">Projection</span> <span class="pre">matrices</span></code></a> (connection weights), which can be overridden by specifying
the <strong>synch_projection_matrices_with_torch</strong> argument in the <a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.Composition.learn" title="psyneulink.core.compositions.composition.Composition.learn"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">learn</span></code></a> method;
see <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.synch_projection_matrices_with_torch" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.synch_projection_matrices_with_torch"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">synch_projection_matrices_with_torch</span></code></a>
for additional details.</p></li>
<li><p><strong>synch_node_variables_with_torch</strong> (<code class="xref any docutils literal notranslate"><span class="pre">LearningScale</span></code> : default None) – specifies the default for the AutodiffComposition for when to copy the current input to Pytorch nodes
to the PsyNeuLink <a class="reference internal" href="Mechanism.html#psyneulink.core.components.mechanisms.mechanism.Mechanism_Base.value" title="psyneulink.core.components.mechanisms.mechanism.Mechanism_Base.value"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">variable</span></code></a> attribute of the corresponding PsyNeuLink <code class="xref any docutils literal notranslate"><span class="pre">nodes</span></code>, which can be overridden by specifying the <strong>synch_node_variables_with_torch</strong> argument
in the <a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.Composition.learn" title="psyneulink.core.compositions.composition.Composition.learn"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">learn</span></code></a> method; see <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.synch_node_variables_with_torch" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.synch_node_variables_with_torch"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">synch_node_variables_with_torch</span></code></a> for additional details.</p></li>
<li><p><strong>synch_node_values_with_torch</strong> (<code class="xref any docutils literal notranslate"><span class="pre">LearningScale</span></code> : default RUN) – specifies the default for the AutodiffComposition for when to copy the current output of Pytorch nodes to the
PsyNeuLink <a class="reference internal" href="Mechanism.html#psyneulink.core.components.mechanisms.mechanism.Mechanism_Base.value" title="psyneulink.core.components.mechanisms.mechanism.Mechanism_Base.value"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">value</span></code></a> attribute of the corresponding PsyNeuLink <code class="xref any docutils literal notranslate"><span class="pre">nodes</span></code>,
which can be overridden by specifying the <strong>synch_node_values_with_torch</strong> argument in the <a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.Composition.learn" title="psyneulink.core.compositions.composition.Composition.learn"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">learn</span></code></a> method; see <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.synch_node_values_with_torch" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.synch_node_values_with_torch"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">synch_node_values_with_torch</span></code></a> for additional details.</p></li>
<li><p><strong>synch_results_with_torch</strong> (<code class="xref any docutils literal notranslate"><span class="pre">LearningScale</span></code> : default RUN) – specifies the default for the AutodiffComposition for when to copy the outputs of the Pytorch model
to the AutodiffComposition’s <a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.Composition.results" title="psyneulink.core.compositions.composition.Composition.results"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">results</span></code></a> attribute, which can be overridden by
specifying the <strong>synch_results_with_torch</strong> argument in the <a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.Composition.learn" title="psyneulink.core.compositions.composition.Composition.learn"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">learn</span></code></a> method.
Note that this differs from <strong>retain_torch_trained_outputs</strong>, which specifies the frequency at which
the outputs of the PyTorch model are tracked, all of which are stored in the AutodiffComposition’s
<a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.torch_trained_outputs" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.torch_trained_outputs"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">torch_trained_outputs</span></code></a> attribute at the end of the run;
see <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.synch_results_with_torch" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.synch_results_with_torch"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">synch_results_with_torch</span></code></a> for
additional details.</p></li>
<li><p><strong>retain_torch_trained_outputs</strong> (<code class="xref any docutils literal notranslate"><span class="pre">LearningScale</span></code> : default MINIBATCH) – specifies the default for the AutodiffComposition for scale at which the outputs of the Pytorch
model are tracked, all of which are stored in the AutodiffComposition’s <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.torch_trained_outputs" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.torch_trained_outputs"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">torch_trained_outputs</span></code></a> attribute at the end of the run; this can be overridden
by specifying the <strong>retain_torch_trained_outputs</strong> argument in the <a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.Composition.learn" title="psyneulink.core.compositions.composition.Composition.learn"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">learn</span></code></a> method.
Note that this differs from <strong>synch_results_with_torch</strong>, which specifies the frequency with
which values are called to the AutodiffComposition’s <a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.Composition.results" title="psyneulink.core.compositions.composition.Composition.results"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">results</span></code></a> attribute; see <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.retain_torch_trained_outputs" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.retain_torch_trained_outputs"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">retain_torch_trained_outputs</span></code></a> for additional details.</p></li>
<li><p><strong>retain_torch_targets</strong> (<code class="xref any docutils literal notranslate"><span class="pre">LearningScale</span></code> : default MINIBATCH) – specifies the default for the AutodiffComposition for when to copy the targets used for training the
Pytorch model to the AutodiffComposition’s <code class="xref any docutils literal notranslate"><span class="pre">torch_targets</span></code> attribute, which can be
overridden by specifying the <strong>retain_torch_targets</strong> argument in the <a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.Composition.learn" title="psyneulink.core.compositions.composition.Composition.learn"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">learn</span></code></a> method;
see <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.retain_torch_targets" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.retain_torch_targets"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">retain_torch_targets</span></code></a> for additional details.</p></li>
<li><p><strong>retain_torch_losses</strong> (<code class="xref any docutils literal notranslate"><span class="pre">LearningScale</span></code> : default MINIBATCH) – specifies the default for the AutodiffComposition for the scale at which the losses of the Pytorch model
are tracked, all of which are stored in the AutodiffComposition’s <code class="xref any docutils literal notranslate"><span class="pre">torch_losses</span></code>
attribute at the end of the run; see <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.retain_torch_losses" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.retain_torch_losses"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">retain_torch_losses</span></code></a> for
additional details.</p></li>
<li><p><strong>device</strong> (<em>torch.device : default device-dependent</em>) – specifies the device on which the model is run. If None, the device is set to ‘cuda’ if available,
then ‘mps`, otherwise ‘cpu’.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">pytorch_representation</span> <span class="pre">=</span> <span class="pre">None</span></span></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.optimizer">
<span class="sig-name descname"><span class="pre">optimizer</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>the optimizer used for training. Depends on the <strong>optimizer_type</strong>, <strong>learning_rate</strong>, and <strong>weight_decay</strong>
arguments from initialization.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>PyTorch optimizer function</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.loss">
<span class="sig-name descname"><span class="pre">loss</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.loss" title="Permalink to this definition">¶</a></dt>
<dd><p>the loss function used for training. Depends on the <strong>loss_spec</strong> argument from initialization.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>PyTorch loss function</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learning_rate">
<span class="sig-name descname"><span class="pre">learning_rate</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learning_rate" title="Permalink to this definition">¶</a></dt>
<dd><p>determines the learning_rate passed the optimizer, and is applied to all <a class="reference internal" href="Projection.html"><span class="doc">Projection</span></a>s in the
AutodiffComposition that are <code class="xref any docutils literal notranslate"><span class="pre">learnable</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>At present, the same learning rate is applied to all Components of an AutodiffComposition, irrespective
of the <code class="xref any docutils literal notranslate"><span class="pre">learning_rate</span></code> that may be specified for any
individual Mechanisms or any <a class="reference internal" href="#autodiffcomposition-nesting"><span class="std std-ref">nested Compositions</span></a>; in the case of the
latter, the <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learning_rate" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learning_rate"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">learning_rate</span></code></a> of the outermost AutodiffComposition is
used, whether this is specified in the call to its <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learn" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learn"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">learn</span></code></a> method, its
constructor, or its default value is being used.</p>
</div>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>To disable updating of a particular <a class="reference internal" href="MappingProjection.html"><span class="doc">MappingProjection</span></a> in an AutodiffComposition, specify the
<strong>learnable</strong> parameter of its constructor as <code class="xref any docutils literal notranslate"><span class="pre">False</span></code>; this applies to MappingProjections at any
level of <a class="reference internal" href="#autodiffcomposition-nesting"><span class="std std-ref">nesting</span></a>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.synch_projection_matrices_with_torch">
<span class="sig-name descname"><span class="pre">synch_projection_matrices_with_torch</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.synch_projection_matrices_with_torch" title="Permalink to this definition">¶</a></dt>
<dd><p>determines when to copy PyTorch parameters to PsyNeuLink <a class="reference internal" href="MappingProjection.html#psyneulink.core.components.projections.pathway.mappingprojection.MappingProjection.matrix" title="psyneulink.core.components.projections.pathway.mappingprojection.MappingProjection.matrix"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">Projection</span> <span class="pre">matrices</span></code></a>
(connection weights) if this is not specified in the call to <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learn" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learn"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">learn</span></code></a>. Copying more
frequently keeps the PsyNeuLink representation more closely synchronized with parameter updates in Pytorch,
but slows performance (see <code class="xref any docutils literal notranslate"><span class="pre">AutodiffComposition_PyTorch_LearningScale</span></code> for information about settings).</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>OPTIMIZATION_STEP, MINIBATCH, EPOCH or RUN</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.synch_node_variables_with_torch">
<span class="sig-name descname"><span class="pre">synch_node_variables_with_torch</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.synch_node_variables_with_torch" title="Permalink to this definition">¶</a></dt>
<dd><p>determines when to copy the current input to Pytorch nodes (modules) to the PsyNeuLink <a class="reference internal" href="Mechanism.html#psyneulink.core.components.mechanisms.mechanism.Mechanism_Base.value" title="psyneulink.core.components.mechanisms.mechanism.Mechanism_Base.value"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">variable</span></code></a> attribute of the corresponding PsyNeuLink <code class="xref any docutils literal notranslate"><span class="pre">nodes</span></code>, if this is not
specified in the call to <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learn" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learn"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">learn</span></code></a>.
Copying more frequently keeps the PsyNeuLink
representation more closely copying more frequently keeps them synchronized with parameter updates in Pytorch,
but slows performance (see <code class="xref any docutils literal notranslate"><span class="pre">AutodiffComposition_PyTorch_LearningScale</span></code> for information about settings).</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>OPTIMIZATION_STEP, TRIAL, MINIBATCH, EPOCH, RUN or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.synch_node_values_with_torch">
<span class="sig-name descname"><span class="pre">synch_node_values_with_torch</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.synch_node_values_with_torch" title="Permalink to this definition">¶</a></dt>
<dd><p>determines when to copy the current output of Pytorch nodes (modules) to the PsyNeuLink <a class="reference internal" href="Mechanism.html#psyneulink.core.components.mechanisms.mechanism.Mechanism_Base.value" title="psyneulink.core.components.mechanisms.mechanism.Mechanism_Base.value"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">value</span></code></a> attribute of the corresponding PsyNeuLink <code class="xref any docutils literal notranslate"><span class="pre">nodes</span></code>, if this is not
specified in the call to <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learn" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learn"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">learn</span></code></a>. Copying more frequently keeps the PsyNeuLink
representation more closely copying more frequently keeps them synchronized with parameter updates in Pytorch,
but slows performance (see <code class="xref any docutils literal notranslate"><span class="pre">AutodiffComposition_PyTorch_LearningScale</span></code> for information about settings).</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>OPTIMIZATION_STEP, MINIBATCH, EPOCH or RUN</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.synch_results_with_torch">
<span class="sig-name descname"><span class="pre">synch_results_with_torch</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.synch_results_with_torch" title="Permalink to this definition">¶</a></dt>
<dd><p>determines when to copy the current outputs of Pytorch nodes to the PsyNeuLink <a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.Composition.results" title="psyneulink.core.compositions.composition.Composition.results"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">results</span></code></a> attribute of the AutodiffComposition if this is not specified in
the call to <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learn" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learn"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">learn</span></code></a>. Copying more frequently keeps the PsyNeuLink
representation more closely synchronized with parameter updates in Pytorch, but slows performance
(see <code class="xref any docutils literal notranslate"><span class="pre">AutodiffComposition_PyTorch_LearningScale</span></code> for information about settings).</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>OPTIMIZATION_STEP, TRIAL, MINIBATCH, EPOCH or RUN</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.retain_torch_trained_outputs">
<span class="sig-name descname"><span class="pre">retain_torch_trained_outputs</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.retain_torch_trained_outputs" title="Permalink to this definition">¶</a></dt>
<dd><p>determines the scale at which the outputs of the Pytorch model are tracked, all of which are stored in the
AutodiffComposition’s <a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.Composition.results" title="psyneulink.core.compositions.composition.Composition.results"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">results</span></code></a> attribute at the end of the run if this is not specified
in the call to <code class="xref any docutils literal notranslate"><span class="pre">learn</span> <span class="pre">&lt;AutodiffComposition.learn&gt;`(see</span> <span class="pre">`AutodiffComposition_PyTorch_LearningScale</span></code> for
information about settings)</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>OPTIMIZATION_STEP, MINIBATCH, EPOCH, RUN or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.retain_torch_targets">
<span class="sig-name descname"><span class="pre">retain_torch_targets</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.retain_torch_targets" title="Permalink to this definition">¶</a></dt>
<dd><p>determines the scale at which the targets used for training the Pytorch model are tracked, all of which
are stored in the AutodiffComposition’s <code class="xref any docutils literal notranslate"><span class="pre">targets</span></code> attribute at the end of the run
if this is not specified in the call to <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learn" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learn"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">learn</span></code></a>
(see <code class="xref any docutils literal notranslate"><span class="pre">AutodiffComposition_PyTorch_LearningScale</span></code> for information about settings).</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>OPTIMIZATION_STEP, TRIAL, MINIBATCH, EPOCH, RUN or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.retain_torch_losses">
<span class="sig-name descname"><span class="pre">retain_torch_losses</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.retain_torch_losses" title="Permalink to this definition">¶</a></dt>
<dd><p>determines the scale at which the losses of the Pytorch model are tracked, all of which are stored in
the AutodiffComposition’s <code class="xref any docutils literal notranslate"><span class="pre">torch_losses</span></code> attribute at the end of the run
if this is nota specified in the call to <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learn" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learn"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">learn</span></code></a>
(see <code class="xref any docutils literal notranslate"><span class="pre">AutodiffComposition_PyTorch_LearningScale</span></code> for information about settings).</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>OPTIMIZATION_STEP, MINIBATCH, EPOCH, RUN or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.torch_trained_outputs">
<span class="sig-name descname"><span class="pre">torch_trained_outputs</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.torch_trained_outputs" title="Permalink to this definition">¶</a></dt>
<dd><p>stores the outputs (converted to np arrays) of the Pytorch model trained during learning, at the frequency
specified by <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.retain_torch_trained_outputs" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.retain_torch_trained_outputs"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">retain_torch_trained_outputs</span></code></a> if it is set
to <em>MINIBATCH</em>, <em>EPOCH</em>, or <em>RUN</em>; see <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.retain_torch_trained_outputs" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.retain_torch_trained_outputs"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">retain_torch_trained_outputs</span></code></a> for additional details.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>List[ndarray]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.torch_targets">
<span class="sig-name descname"><span class="pre">torch_targets</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.torch_targets" title="Permalink to this definition">¶</a></dt>
<dd><p>stores the targets used for training the Pytorch model during learning at the frequency specified by
<a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.retain_torch_targets" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.retain_torch_targets"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">retain_torch_targets</span></code></a> if it is set to <em>MINIBATCH</em>, <em>EPOCH</em>,
or <em>RUN</em>; see <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.retain_torch_targets" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.retain_torch_targets"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">retain_torch_targets</span></code></a> for additional details.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>List[ndarray]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.torch_losses">
<span class="sig-name descname"><span class="pre">torch_losses</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.torch_losses" title="Permalink to this definition">¶</a></dt>
<dd><p>stores the average loss after each weight update (i.e. each minibatch) during learning, at the frequency
specified by <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.retain_torch_trained_outputs" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.retain_torch_trained_outputs"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">retain_torch_trained_outputs</span></code></a> if it is set to <em>MINIBATCH</em>,
<em>EPOCH</em>, or <em>RUN</em>; see <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.retain_torch_losses" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.retain_torch_losses"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">retain_torch_losses</span></code></a> for additonal details.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>list of floats</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.last_saved_weights">
<span class="sig-name descname"><span class="pre">last_saved_weights</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.last_saved_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>path for file to which weights were last saved.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>path</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.last_loaded_weights">
<span class="sig-name descname"><span class="pre">last_loaded_weights</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.last_loaded_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>path for file from which weights were last loaded.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>path</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.device">
<span class="sig-name descname"><span class="pre">device</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.device" title="Permalink to this definition">¶</a></dt>
<dd><p>the device on which the model is run.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>torch.device</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper">
<em class="property"><span class="pre">class</span> </em><span class="sig-name descname"><span class="pre">PytorchCompositionWrapper</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">composition</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outer_creator</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper for a Composition as a Pytorch Module
Class that wraps a <a class="reference internal" href="Composition.html"><span class="doc">Composition</span></a> as a PyTorch module.</p>
<p>Two main responsibilities:</p>
<ol class="arabic">
<li><dl>
<dt>Set up parameters of PyTorch model &amp; information required for forward computation:</dt><dd><p>Handle nested compositions (flattened in infer_backpropagation_learning_pathways):
Deal with Projections into and/or out of a nested Composition as shown in figure below:</p>
<blockquote>
<div><blockquote>
<div><dl class="simple">
<dt>(note: Projections in outer Composition to/from a nested Composition’s CIMs are learnable,</dt><dd><p>and ones in a nested Composition from/to its CIMs are not)</p>
</dd>
</dl>
</div></blockquote>
<dl>
<dt>[      OUTER     ][                            NESTED                               ][     OUTER      ]</dt><dd><p>learnable//   not learnable//                     not learnable//    learnable//</p>
</dd>
<dt>—&gt; [Node] —-&gt; [input_CIM] ~~~&gt; [INPUT Node] —-&gt; [OUTPUT Node] ~~~&gt; [output_CIM] —-&gt; [Node] —&gt;</dt><dd><dl>
<dt>sndr            rcvr          nested_rcvr         nested_sndr         sndr             rcvr</dt><dd><p>^–projection–&gt;^                                                     ^—projection–&gt;^
^—-PytorchProjectionWrapper—-&gt;^                  ^—-PytorchProjectionWrapper—-&gt;^</p>
<blockquote>
<div><p>ENTRY                                                       EXIT</p>
</div></blockquote>
</dd>
</dl>
</dd>
</dl>
</div></blockquote>
</dd>
</dl>
</li>
<li><p>Handle coordination of passing data and outcomes back to PsyNeuLink objects, handled by two main methods:</p>
<ul>
<li><dl>
<dt>synch_with_psyneulink()</dt><dd><p>Copies matrix weights, node variables, node values, and/or autoutdiff results
at user-specified intervals (LearningScale:  OPTIMIZATION_STEP, TRIAL, MINIBATCH, EPOCH, RUN);
these are specified by the user in the following arguments to run() or learn():</p>
<blockquote>
<div><p>synch_projection_matrices_with_torch=RUN,
synch_node_variables_with_torch=None,
synch_node_values_with_torch=RUN,
synch_results_with_torch=RUN,</p>
</div></blockquote>
<p>and consolidated in the synch_with_pnl_options dict used by synch_with_psyneulink</p>
</dd>
</dl>
</li>
<li><dl>
<dt>retain_for_psyneulink()</dt><dd><p>Retains learning-specific data used and outcomes generated during execution of PyTorch model
(TRAINED_OUTPUT_VALUES, corresponding TARGETS and LOSSES), that are copied to PsyNeuLink
at the end of a call to learn(); these are specified by the user in the following arguments
to learn():</p>
<blockquote>
<div><p>retain_torch_trained_outputs=MINIBATCH,
retain_torch_targets=MINIBATCH,
retain_torch_losses=MINIBATCH,</p>
</div></blockquote>
<p>and consolidated in the retain_in_pnl_options dict used by retain_for_psyneulink</p>
</dd>
</dl>
</li>
</ul>
<blockquote>
<div><ul class="simple">
<li><dl class="simple">
<dt>Note: RESULTS is handled in an idiosyncratic way: it is specified along with the synchronization</dt><dd><p>parameters, since it is a value ordinarily generated in the execution of a Composition;
however it’s helper parallels the retain_for_psyneulink helper methods, and it is called
from _update_results if TRIAL is specified, in order to integrate with the standard execution
of a Composition.</p>
</dd>
</dl>
</li>
</ul>
</div></blockquote>
</li>
</ol>
<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper._composition">
<span class="sig-name descname"><span class="pre">_composition</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper._composition" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference internal" href="#"><span class="doc">AutodiffComposition</span></a> being wrapped.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.Composition" title="psyneulink.core.compositions.composition.Composition">Composition</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.wrapped_nodes">
<span class="sig-name descname"><span class="pre">wrapped_nodes</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.wrapped_nodes" title="Permalink to this definition">¶</a></dt>
<dd><p>list of nodes in the PytorchCompositionWrapper corresponding to PyTorch modules. Generally these are
<a class="reference internal" href="Mechanism.html"><span class="doc">Mechanisms</span></a> wrapped in a <code class="xref any docutils literal notranslate"><span class="pre">PytorchMechanismWrapper</span></code>, however, if the <a class="reference internal" href="#"><span class="doc">AutodiffComposition</span></a>
being wrapped is itself a nested Composition, then the wrapped nodes are <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper"><code class="xref any py py-class docutils literal notranslate"><span class="pre">PytorchCompositionWrapper</span></code></a> objects.
When the PyTorch model is executed these are “flattened” into a single PyTorch module, which can be visualized
using the AutodiffComposition’s <a class="reference internal" href="Visualization.html#psyneulink.core.compositions.showgraph.ShowGraph.show_graph" title="psyneulink.core.compositions.showgraph.ShowGraph.show_graph"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">show_graph</span></code></a> method and setting its <em>show_pytorch</em>
argument to True (see <code class="xref any docutils literal notranslate"><span class="pre">PytorchShowGraph</span></code> for additional information).</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>List[PytorchMechanismWrapper]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.nodes_map">
<span class="sig-name descname"><span class="pre">nodes_map</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.nodes_map" title="Permalink to this definition">¶</a></dt>
<dd><p>maps psyneulink <a class="reference internal" href="Composition.html#composition-nodes"><span class="std std-ref">Nodes</span></a> to PytorchCompositionWrapper nodes.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>Dict[Node: PytorchMechanismWrapper or <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper">PytorchCompositionWrapper</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">projection_wrappers</span> <span class="pre">=</span> <span class="pre">List[PytorchProjectionWrapper]</span></span></dt>
<dd><p>list of PytorchCompositionWrappers in the PytorchCompositionWrapper, each of which wraps a <a class="reference internal" href="Projection.html"><span class="doc">Projection</span></a>
in the AutodiffComposition being wrapped.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.projections_map">
<span class="sig-name descname"><span class="pre">projections_map</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.projections_map" title="Permalink to this definition">¶</a></dt>
<dd><p>maps <a class="reference internal" href="Projection.html"><span class="doc">Projections</span></a> in the AutodiffComposition being wrapped to <code class="xref any docutils literal notranslate"><span class="pre">PytorchProjectionWrappers</span></code> in
the PytorchCompositionWrapper.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>Dict[Projection: PytorchProjectionWrapper]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper._nodes_to_execute_after_gradient_calc">
<span class="sig-name descname"><span class="pre">_nodes_to_execute_after_gradient_calc</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper._nodes_to_execute_after_gradient_calc" title="Permalink to this definition">¶</a></dt>
<dd><p>contains nodes specified as <code class="xref any docutils literal notranslate"><span class="pre">exclude_from_gradient_calc</span></code> as keys, and their current variable as values</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>Dict[node : torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.optimizer">
<span class="sig-name descname"><span class="pre">optimizer</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>assigned by AutodffComposition after the wrapper is created, which passes the parameters to the optimizer</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>torch</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.device">
<span class="sig-name descname"><span class="pre">device</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.device" title="Permalink to this definition">¶</a></dt>
<dd><p>device used to process torch Tensors in PyTorch modules</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>torch.device</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.params">
<span class="sig-name descname"><span class="pre">params</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.params" title="Permalink to this definition">¶</a></dt>
<dd><p>list of PyTorch parameters (connection weight matrices) in the PyTorch model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>nn.ParameterList()</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.minibatch_loss">
<span class="sig-name descname"><span class="pre">minibatch_loss</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.minibatch_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>accumulated loss over all trials (stimuli) within a batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.minibatch_loss_count">
<span class="sig-name descname"><span class="pre">minibatch_loss_count</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.minibatch_loss_count" title="Permalink to this definition">¶</a></dt>
<dd><p>count of losses (trials) within batch, used to calculate average loss per batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.retained_results">
<span class="sig-name descname"><span class="pre">retained_results</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.retained_results" title="Permalink to this definition">¶</a></dt>
<dd><p>list of the <a class="reference internal" href="Composition.html#id9" title="psyneulink.core.compositions.composition.Composition.output_values"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">output_values</span></code></a> of the AutodiffComposition for ever trial executed
in a call to <code class="xref any docutils literal notranslate"><span class="pre">run</span></code> or <code class="xref any docutils literal notranslate"><span class="pre">learn</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>List[ndarray]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.retained_trained_outputs">
<span class="sig-name descname"><span class="pre">retained_trained_outputs</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.retained_trained_outputs" title="Permalink to this definition">¶</a></dt>
<dd><p>values of the trained <a class="reference internal" href="Composition.html#psyneulink.core.compositions.composition.NodeRole.OUTPUT" title="psyneulink.core.compositions.composition.NodeRole.OUTPUT"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">OUTPUT</span></code></a> Node (i.e., ones associated with <code class="xref any docutils literal notranslate"><span class="pre">TARGET</span> <span class="pre">&lt;NodeRole.TARGET</span></code>
Node) for each trial executed in a call to <code class="xref any docutils literal notranslate"><span class="pre">learn</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>List[ndarray]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.retained_targets">
<span class="sig-name descname"><span class="pre">retained_targets</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.retained_targets" title="Permalink to this definition">¶</a></dt>
<dd><p>values of the <code class="xref any docutils literal notranslate"><span class="pre">TARGET</span> <span class="pre">&lt;NodeRole.TARGET</span></code> Nodes for each trial executed in a call to <code class="xref any docutils literal notranslate"><span class="pre">learn</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>List[ndarray]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.retained_losses">
<span class="sig-name descname"><span class="pre">retained_losses</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.retained_losses" title="Permalink to this definition">¶</a></dt>
<dd><p>losses per batch, epoch or run accumulated over a call to learn()</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>List[ndarray]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper._regenerate_paramlist">
<span class="sig-name descname"><span class="pre">_regenerate_paramlist</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper._regenerate_paramlist" title="Permalink to this definition">¶</a></dt>
<dd><p>Add Projection matrices to Pytorch Module’s parameter list</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.copy_node_values_to_psyneulink">
<span class="sig-name descname"><span class="pre">copy_node_values_to_psyneulink</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nodes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'all'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.copy_node_values_to_psyneulink" title="Permalink to this definition">¶</a></dt>
<dd><p>Copy output of Pytorch nodes to value of AutodiffComposition nodes.
IMPLEMENTATION NOTE:  list included in nodes arg to allow for future specification of specific nodes to copy</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.copy_node_variables_to_psyneulink">
<span class="sig-name descname"><span class="pre">copy_node_variables_to_psyneulink</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nodes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'all'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.copy_node_variables_to_psyneulink" title="Permalink to this definition">¶</a></dt>
<dd><p>Copy input to Pytorch nodes to variable of AutodiffComposition nodes.
IMPLEMENTATION NOTE:  list included in nodes arg to allow for future specification of specific nodes to copy</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.copy_results_to_psyneulink">
<span class="sig-name descname"><span class="pre">copy_results_to_psyneulink</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">current_condition</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.copy_results_to_psyneulink" title="Permalink to this definition">¶</a></dt>
<dd><p>Copy outputs of Pytorch forward() to AutodiffComposition.results attribute.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.execute_node">
<span class="sig-name descname"><span class="pre">execute_node</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">variable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimization_num</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.execute_node" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute node and store the result in the node’s value attribute
Implemented as method (and includes optimization_rep and context as args)</p>
<blockquote>
<div><p>so that it can be overridden by subclasses of PytorchCompositionWrapper</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimization_rep</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward method of the model for PyTorch and LLVM modes
Returns a dictionary {output_node:value} of output values for the model</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.retain_for_psyneulink">
<span class="sig-name descname"><span class="pre">retain_for_psyneulink</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retain_in_pnl_options</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.retain_for_psyneulink" title="Permalink to this definition">¶</a></dt>
<dd><p>Store outputs, targets, and losses from Pytorch execution for copying to PsyNeuLink at end of learn().
:type data: <code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>
:param data: specifies local data available to retain (for copying to pnl at end of run;</p>
<blockquote>
<div><p>keys must be one or more of the keywords OUTPUTS, TARGETS, or LOSSES; value must be a torch.Tensor</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>retain_in_pnl_options</strong> (<em>dict</em>) – specifies which data the user has requested be retained (and copied to pnl at end of run)
keys must be OUTPUTS, TARGETS, or LOSSES; value must be a LearningScale.name or None (which suppresses copy)</p></li>
<li><p><strong>Note</strong> (<em>does not actually copy data to pnl; that is done by _getter methods for the relevant autodiff Parameters</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.retain_losses">
<span class="sig-name descname"><span class="pre">retain_losses</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.retain_losses" title="Permalink to this definition">¶</a></dt>
<dd><p>Track losses and copy to AutodiffComposition.pytorch_targets at end of learn().</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.retain_results">
<span class="sig-name descname"><span class="pre">retain_results</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">results</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.retain_results" title="Permalink to this definition">¶</a></dt>
<dd><p>Track outputs and copy to AutodiffComposition.pytorch_outputs at end of learn().</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.retain_targets">
<span class="sig-name descname"><span class="pre">retain_targets</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">targets</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.retain_targets" title="Permalink to this definition">¶</a></dt>
<dd><p>Track targets and copy to AutodiffComposition.pytorch_targets at end of learn().</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.retain_trained_outputs">
<span class="sig-name descname"><span class="pre">retain_trained_outputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trained_outputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.retain_trained_outputs" title="Permalink to this definition">¶</a></dt>
<dd><p>Track outputs and copy to AutodiffComposition.pytorch_outputs at end of learn().</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.synch_with_psyneulink">
<span class="sig-name descname"><span class="pre">synch_with_psyneulink</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">synch_with_pnl_options</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">current_condition</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper.synch_with_psyneulink" title="Permalink to this definition">¶</a></dt>
<dd><p>Copy weights, values, and/or results from Pytorch to PsyNeuLink at specified junctures
params can be used to restrict copy to a specific (set of) param(s). If params is not specified, all are copied;</p>
</dd></dl>

</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.pytorch_composition_wrapper_type">
<span class="sig-name descname"><span class="pre">pytorch_composition_wrapper_type</span></span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.pytorch_composition_wrapper_type" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper" title="psyneulink.library.compositions.pytorchwrappers.PytorchCompositionWrapper"><code class="xref py py-class docutils literal notranslate"><span class="pre">psyneulink.library.compositions.pytorchwrappers.PytorchCompositionWrapper</span></code></a></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.Parameters">
<em class="property"><span class="pre">class</span> </em><span class="sig-name descname"><span class="pre">Parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">owner</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parent</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.Parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.assign_ShowGraph">
<span class="sig-name descname"><span class="pre">assign_ShowGraph</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">show_graph_attributes</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.assign_ShowGraph" title="Permalink to this definition">¶</a></dt>
<dd><p>Override to replace assignment of ShowGraph class with PytorchShowGraph if torch is available</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.infer_backpropagation_learning_pathways">
<span class="sig-name descname"><span class="pre">infer_backpropagation_learning_pathways</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">execution_mode</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.infer_backpropagation_learning_pathways" title="Permalink to this definition">¶</a></dt>
<dd><p>Create backpropapagation learning pathways for every Input Node –&gt; Output Node pathway
Flattens nested compositions:</p>
<blockquote>
<div><ul class="simple">
<li><p>only includes the Projections in outer Composition to/from the CIMs of the nested Composition
(i.e., to input_CIMs and from output_CIMs) – the ones that should be learned;</p></li>
<li><p>excludes Projections from/to CIMs in the nested Composition
(from input_CIMs and to output_CIMs), as those should remain identity Projections;</p></li>
</ul>
<p>see <a class="reference internal" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper" title="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.PytorchCompositionWrapper"><code class="xref any py py-class docutils literal notranslate"><span class="pre">PytorchCompositionWrapper</span></code></a> for table of how Projections are handled and further details.</p>
</div></blockquote>
<p>Returns list of target nodes for each pathway</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition._build_pytorch_representation">
<span class="sig-name descname"><span class="pre">_build_pytorch_representation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">refresh</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition._build_pytorch_representation" title="Permalink to this definition">¶</a></dt>
<dd><p>Builds a Pytorch representation of the AutodiffComposition</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.autodiff_forward">
<span class="sig-name descname"><span class="pre">autodiff_forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">synch_with_pnl_options</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retain_in_pnl_options</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">execution_mode</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scheduler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.autodiff_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform forward pass of model and compute loss for a single trial (i.e., a single input) in Pytorch mode.
Losses are accumulated in pytorch_rep.track_losses, over calls to this method within a minibatch;</p>
<blockquote>
<div><p>at the end of a minibatch, they are averaged and backpropagated by compositionrunner.run_learning()
before the next time it calls run(), in a call to backward() by do_gradient_optimization()
in _batch_inputs() or _batch_function_inputs(),</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.do_gradient_optimization">
<span class="sig-name descname"><span class="pre">do_gradient_optimization</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">retain_in_pnl_options</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimization_num</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.do_gradient_optimization" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute loss and use in call to autodiff_backward() to compute gradients and update PyTorch parameters.
Update parameters (weights) based on trial(s) executed since last optimization,
Reinitizalize minibatch_loss and minibatch_loss_count</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.autodiff_backward">
<span class="sig-name descname"><span class="pre">autodiff_backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">minibatch_loss</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.autodiff_backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate gradients and apply to PyTorch model parameters (weights)</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition._get_autodiff_inputs_values">
<span class="sig-name descname"><span class="pre">_get_autodiff_inputs_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dict</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition._get_autodiff_inputs_values" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove TARGET Nodes, and return dict with values of INPUT Nodes for single trial
For nested Compositions, replace input to nested Composition with inputs to its INPUT Nodes
For InuptPorts, replace with owner</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>A dict mapping INPUT Nodes -&gt; input values for a single trial</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition._get_autodiff_targets_values">
<span class="sig-name descname"><span class="pre">_get_autodiff_targets_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dict</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition._get_autodiff_targets_values" title="Permalink to this definition">¶</a></dt>
<dd><p>Return dict with values for TARGET Nodes
Get Inputs to TARGET Nodes used for computation of loss in autodiff_forward().
Uses input_dict to get values for TARGET Nodes that are INPUT Nodes of the AutodiffComposition,
If a TARGET Node is not an INPUT Node, it is assumed to be the target of a projection from an INPUT Node
and the value is determined by searching recursively for the input Node that projects to the TARGET Node.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>A dict mapping TARGET Nodes -&gt; target values</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition._parse_learning_spec">
<span class="sig-name descname"><span class="pre">_parse_learning_spec</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">execution_mode</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition._parse_learning_spec" title="Permalink to this definition">¶</a></dt>
<dd><p>Converts learning inputs and targets to a standardized form</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><code class="xref any docutils literal notranslate"><span class="pre">dict</span></code> – Dict mapping mechanisms to values (with TargetMechanisms inferred from output nodes if needed)</p></li>
<li><p><code class="xref any docutils literal notranslate"><span class="pre">int</span></code> – Number of input sets in dict for each input node in the Composition</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition._identify_target_nodes">
<span class="sig-name descname"><span class="pre">_identify_target_nodes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition._identify_target_nodes" title="Permalink to this definition">¶</a></dt>
<dd><p>Recursively call all nested AutodiffCompositions to assign TARGET nodes for learning</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learn">
<span class="sig-name descname"><span class="pre">learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">synch_projection_matrices_with_torch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">NotImplemented</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">synch_node_variables_with_torch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">NotImplemented</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">synch_node_values_with_torch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">NotImplemented</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">synch_results_with_torch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">NotImplemented</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retain_torch_trained_outputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">NotImplemented</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retain_torch_targets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">NotImplemented</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retain_torch_losses</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">NotImplemented</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.learn" title="Permalink to this definition">¶</a></dt>
<dd><p>Override to handle synch and retain args
Note: defaults for synch and retain args are set to NotImplemented, so that the user can specify None if</p>
<blockquote>
<div><p>they want to locally override the default values for the AutodiffComposition (see docstrings for run()
and _parse_synch_and_retain_args() for additonal details).</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition._get_execution_mode">
<span class="sig-name descname"><span class="pre">_get_execution_mode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">execution_mode</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition._get_execution_mode" title="Permalink to this definition">¶</a></dt>
<dd><p>Parse execution_mode argument and return a valid execution mode for the learn() method
Can be overridden by subclasses to change the permitted and/or default execution mode for learning</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.execute">
<span class="sig-name descname"><span class="pre">execute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">inputs=None</span></em>, <em class="sig-param"><span class="pre">num_trials=None</span></em>, <em class="sig-param"><span class="pre">minibatch_size=1</span></em>, <em class="sig-param"><span class="pre">optimizations_per_minibatch=1</span></em>, <em class="sig-param"><span class="pre">do_logging=False</span></em>, <em class="sig-param"><span class="pre">scheduler=None</span></em>, <em class="sig-param"><span class="pre">termination_processing=None</span></em>, <em class="sig-param"><span class="pre">call_before_minibatch=None</span></em>, <em class="sig-param"><span class="pre">call_after_minibatch=None</span></em>, <em class="sig-param"><span class="pre">call_before_time_step=None</span></em>, <em class="sig-param"><span class="pre">call_before_pass=None</span></em>, <em class="sig-param"><span class="pre">call_after_time_step=None</span></em>, <em class="sig-param"><span class="pre">call_after_pass=None</span></em>, <em class="sig-param"><span class="pre">reset_stateful_functions_to=None</span></em>, <em class="sig-param"><span class="pre">context=None</span></em>, <em class="sig-param"><span class="pre">base_context=&lt;psyneulink.core.globals.context.Context</span> <span class="pre">object&gt;</span></em>, <em class="sig-param"><span class="pre">clamp_input='soft_clamp'</span></em>, <em class="sig-param"><span class="pre">targets=None</span></em>, <em class="sig-param"><span class="pre">runtime_params=None</span></em>, <em class="sig-param"><span class="pre">execution_mode=ExecutionMode.PyTorch</span></em>, <em class="sig-param"><span class="pre">skip_initialization=False</span></em>, <em class="sig-param"><span class="pre">synch_with_pnl_options=None</span></em>, <em class="sig-param"><span class="pre">retain_in_pnl_options=None</span></em>, <em class="sig-param"><span class="pre">report_output=ReportOutput.OFF</span></em>, <em class="sig-param"><span class="pre">report_params=ReportParams.OFF</span></em>, <em class="sig-param"><span class="pre">report_progress=ReportProgress.OFF</span></em>, <em class="sig-param"><span class="pre">report_simulations=ReportSimulations.OFF</span></em>, <em class="sig-param"><span class="pre">report_to_devices=None</span></em>, <em class="sig-param"><span class="pre">report=None</span></em>, <em class="sig-param"><span class="pre">report_num=None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.execute" title="Permalink to this definition">¶</a></dt>
<dd><p>Override to execute autodiff_forward() in learning mode if execute_mode is not Python</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">synch_projection_matrices_with_torch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">NotImplemented</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">synch_node_variables_with_torch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">NotImplemented</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">synch_node_values_with_torch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">NotImplemented</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">synch_results_with_torch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">NotImplemented</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retain_torch_trained_outputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">NotImplemented</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retain_torch_targets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">NotImplemented</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retain_torch_losses</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">NotImplemented</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.run" title="Permalink to this definition">¶</a></dt>
<dd><p>Override to handle synch and retain args if run called directly from run() rather than learn()
Note: defaults for synch and retain args are NotImplemented, so that the user can specify None if they want</p>
<blockquote>
<div><p>to locally override the default values for the AutodiffComposition (see _parse_synch_and_retain_args()
for details). This is distinct from the user assigning the Parameter default_values(s), which is done
in the AutodiffComposition constructor and handled by the Parameter._specify_none attribute.</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition._update_results">
<span class="sig-name descname"><span class="pre">_update_results</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">results</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trial_output</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">execution_mode</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">synch_with_pnl_options</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition._update_results" title="Permalink to this definition">¶</a></dt>
<dd><p>Update results by appending most recent trial_output
This is included as a helper so it can be overriden by subclasses (such as AutodiffComposition)
that may need to do this less frequently for scallable exeuction</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">directory</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filename</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Saves all weight matrices for all MappingProjections in the AutodiffComposition</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>Path</em><em>, </em><em>PosixPath</em><em> or </em><em>str : default None</em>) – path specification; must be a legal path specification in the filesystem.</p></li>
<li><p><strong>directory</strong> (str : default <code class="docutils literal notranslate"><span class="pre">current</span> <span class="pre">working</span> <span class="pre">directory</span></code>) – directory where <a class="reference internal" href="MappingProjection.html#psyneulink.core.components.projections.pathway.mappingprojection.MappingProjection.matrix" title="psyneulink.core.components.projections.pathway.mappingprojection.MappingProjection.matrix"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">matrices</span></code></a> for all MappingProjections
in the AutodiffComposition are saved.</p></li>
<li><p><strong>filename</strong> (str : default <code class="docutils literal notranslate"><span class="pre">&lt;name</span> <span class="pre">of</span> <span class="pre">AutodiffComposition&gt;_matrix_wts.pnl</span></code>) – filename in which <a class="reference internal" href="MappingProjection.html#psyneulink.core.components.projections.pathway.mappingprojection.MappingProjection.matrix" title="psyneulink.core.components.projections.pathway.mappingprojection.MappingProjection.matrix"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">matrices</span></code></a> for all MappingProjections
in the AutodiffComposition are saved.</p></li>
<li><p><strong>note::</strong> (<em>.</em>) – Matrices are saved in
<a class="reference external" href="https://pytorch.org/tutorials/beginner/saving_loading_models.html">PyTorch state_dict</a> format.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Path</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.load">
<span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">directory</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filename</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Loads all weight matrices for all MappingProjections in the AutodiffComposition from file
:type path: <code class="xref py py-class docutils literal notranslate"><span class="pre">PosixPath</span></code>
:param path: Path for file in which <a class="reference internal" href="MappingProjection.html"><span class="doc">MappingProjection</span></a> <a class="reference internal" href="MappingProjection.html#psyneulink.core.components.projections.pathway.mappingprojection.MappingProjection.matrix" title="psyneulink.core.components.projections.pathway.mappingprojection.MappingProjection.matrix"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">matrices</span></code></a> are stored.</p>
<blockquote>
<div><p>This must be a legal PosixPath object; if it is specified <strong>directory</strong> and <strong>filename</strong> are ignored.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>directory</strong> (str : default <code class="docutils literal notranslate"><span class="pre">current</span> <span class="pre">working</span> <span class="pre">directory</span></code>) – directory where <a class="reference internal" href="MappingProjection.html"><span class="doc">MappingProjection</span></a> <a class="reference internal" href="MappingProjection.html#psyneulink.core.components.projections.pathway.mappingprojection.MappingProjection.matrix" title="psyneulink.core.components.projections.pathway.mappingprojection.MappingProjection.matrix"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">matrices</span></code></a> are stored.</p></li>
<li><p><strong>filename</strong> (str : default <code class="docutils literal notranslate"><span class="pre">&lt;name</span> <span class="pre">of</span> <span class="pre">AutodiffComposition&gt;_matrix_wts.pnl</span></code>) – name of file in which <a class="reference internal" href="MappingProjection.html"><span class="doc">MappingProjection</span></a> <a class="reference internal" href="MappingProjection.html#psyneulink.core.components.projections.pathway.mappingprojection.MappingProjection.matrix" title="psyneulink.core.components.projections.pathway.mappingprojection.MappingProjection.matrix"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">matrices</span></code></a> are stored.</p></li>
<li><p><strong>note::</strong> (<em>.</em>) – <p>Matrices must be stored in
<a class="reference external" href="https://pytorch.org/tutorials/beginner/saving_loading_models.html">PyTorch state_dict</a> format.</p>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.parameters">
<span class="sig-name descname"><span class="pre">parameters</span></span><em class="property"> <span class="pre">=</span> <span class="pre">&lt;psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.Parameters</span> <span class="pre">object&gt;</span> <span class="pre">:</span> <span class="pre">(</span> <span class="pre">	device</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value=None</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		function_arg=True</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=True</span> <span class="pre">		mdf_name=None</span> <span class="pre">		name='device'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=False</span> <span class="pre">		port=None</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=True</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	execute_until_finished</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value=True</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		function_arg=True</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=True</span> <span class="pre">		mdf_name=None</span> <span class="pre">		name='execute_until_finished'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=True</span> <span class="pre">		port=None</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=True</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	execution_count</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value=array(0)</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		fallback_default=True</span> <span class="pre">		function_arg=True</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=False</span> <span class="pre">		mdf_name=None</span> <span class="pre">		name='execution_count'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=True</span> <span class="pre">		port=None</span> <span class="pre">		read_only=True</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=False</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	has_initializers</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value=False</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		function_arg=True</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=True</span> <span class="pre">		mdf_name=None</span> <span class="pre">		name='has_initializers'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=True</span> <span class="pre">		port=None</span> <span class="pre">		reference=False</span> <span class="pre">		setter=&lt;function</span> <span class="pre">_has_initializers_setter&gt;</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=True</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	input_specification</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value=None</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		function_arg=True</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=False</span> <span class="pre">		mdf_name=None</span> <span class="pre">		name='input_specification'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=True</span> <span class="pre">		port=None</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=False</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	is_finished_flag</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value=True</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		function_arg=True</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=False</span> <span class="pre">		mdf_name=None</span> <span class="pre">		name='is_finished_flag'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=False</span> <span class="pre">		port=None</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=True</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	learning_rate</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value=array(0.001)</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		fallback_default=True</span> <span class="pre">		function_arg=True</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=True</span> <span class="pre">		mdf_name=None</span> <span class="pre">		name='learning_rate'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=False</span> <span class="pre">		port=None</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=True</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	learning_results</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value=[]</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		function_arg=True</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=False</span> <span class="pre">		mdf_name=None</span> <span class="pre">		name='learning_results'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=True</span> <span class="pre">		port=None</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=True</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	max_executions_before_finished</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value=array(1000)</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		function_arg=True</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=True</span> <span class="pre">		mdf_name=None</span> <span class="pre">		name='max_executions_before_finished'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=True</span> <span class="pre">		port=None</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=True</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	minibatch_size</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value=array(1)</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		function_arg=True</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=True</span> <span class="pre">		mdf_name=None</span> <span class="pre">		modulable=True</span> <span class="pre">		modulation_combination_function=None</span> <span class="pre">		name='minibatch_size'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=True</span> <span class="pre">		port=None</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=True</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	num_executions</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value=Time(run:</span> <span class="pre">0,</span> <span class="pre">trial:</span> <span class="pre">0,</span> <span class="pre">pass:</span> <span class="pre">0,</span> <span class="pre">time_step:</span> <span class="pre">0)</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		function_arg=True</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=False</span> <span class="pre">		mdf_name=None</span> <span class="pre">		name='num_executions'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=True</span> <span class="pre">		port=None</span> <span class="pre">		read_only=True</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=True</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	num_executions_before_finished</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value=array(0)</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		function_arg=True</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=True</span> <span class="pre">		mdf_name=None</span> <span class="pre">		name='num_executions_before_finished'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=True</span> <span class="pre">		port=None</span> <span class="pre">		read_only=True</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=True</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	optimizations_per_minibatch</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value=array(1)</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		function_arg=True</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=True</span> <span class="pre">		mdf_name=None</span> <span class="pre">		modulable=True</span> <span class="pre">		modulation_combination_function=None</span> <span class="pre">		name='optimizations_per_minibatch'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=True</span> <span class="pre">		port=None</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=True</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	optimizer</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value=None</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		function_arg=True</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=True</span> <span class="pre">		mdf_name=None</span> <span class="pre">		name='optimizer'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=False</span> <span class="pre">		port=None</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=True</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	pytorch_representation</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value=None</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		function_arg=True</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=True</span> <span class="pre">		mdf_name=None</span> <span class="pre">		name='pytorch_representation'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=False</span> <span class="pre">		port=None</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=True</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	results</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value=[]</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		function_arg=True</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=False</span> <span class="pre">		mdf_name=None</span> <span class="pre">		name='results'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=True</span> <span class="pre">		port=None</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=True</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	retain_old_simulation_data</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value=False</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		function_arg=True</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=False</span> <span class="pre">		mdf_name=None</span> <span class="pre">		name='retain_old_simulation_data'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=True</span> <span class="pre">		port=None</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=False</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	retain_torch_losses</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value='minibatch'</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		fallback_default=True</span> <span class="pre">		function_arg=True</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=True</span> <span class="pre">		mdf_name=None</span> <span class="pre">		name='retain_torch_losses'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=False</span> <span class="pre">		port=None</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=True</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	retain_torch_targets</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value='minibatch'</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		fallback_default=True</span> <span class="pre">		function_arg=True</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=True</span> <span class="pre">		mdf_name=None</span> <span class="pre">		name='retain_torch_targets'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=False</span> <span class="pre">		port=None</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=True</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	retain_torch_trained_outputs</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value='minibatch'</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		fallback_default=True</span> <span class="pre">		function_arg=True</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=True</span> <span class="pre">		mdf_name=None</span> <span class="pre">		name='retain_torch_trained_outputs'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=False</span> <span class="pre">		port=None</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=True</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	simulation_results</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value=[]</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		function_arg=True</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=False</span> <span class="pre">		mdf_name=None</span> <span class="pre">		name='simulation_results'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=True</span> <span class="pre">		port=None</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=True</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	synch_node_values_with_torch</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value='run'</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		fallback_default=True</span> <span class="pre">		function_arg=True</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=True</span> <span class="pre">		mdf_name=None</span> <span class="pre">		name='synch_node_values_with_torch'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=False</span> <span class="pre">		port=None</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=True</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	synch_node_variables_with_torch</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value=None</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		fallback_default=True</span> <span class="pre">		function_arg=True</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=True</span> <span class="pre">		mdf_name=None</span> <span class="pre">		name='synch_node_variables_with_torch'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=False</span> <span class="pre">		port=None</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=True</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	synch_projection_matrices_with_torch</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value='run'</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		fallback_default=True</span> <span class="pre">		function_arg=True</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=True</span> <span class="pre">		mdf_name=None</span> <span class="pre">		name='synch_projection_matrices_with_torch'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=False</span> <span class="pre">		port=None</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=True</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	synch_results_with_torch</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value='run'</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		fallback_default=True</span> <span class="pre">		function_arg=True</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=True</span> <span class="pre">		mdf_name=None</span> <span class="pre">		name='synch_results_with_torch'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=False</span> <span class="pre">		port=None</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=True</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	torch_losses</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value=[]</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		function_arg=True</span> <span class="pre">		getter=&lt;function</span> <span class="pre">_get_torch_losses&gt;</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=True</span> <span class="pre">		mdf_name=None</span> <span class="pre">		name='torch_losses'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=False</span> <span class="pre">		port=None</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=True</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	torch_targets</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value=[]</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		function_arg=True</span> <span class="pre">		getter=&lt;function</span> <span class="pre">_get_torch_targets&gt;</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=True</span> <span class="pre">		mdf_name=None</span> <span class="pre">		name='torch_targets'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=False</span> <span class="pre">		port=None</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=True</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	torch_trained_outputs</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value=[]</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		function_arg=True</span> <span class="pre">		getter=&lt;function</span> <span class="pre">_get_torch_trained_outputs&gt;</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=True</span> <span class="pre">		mdf_name=None</span> <span class="pre">		name='torch_trained_outputs'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=False</span> <span class="pre">		port=None</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=True</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	trial_losses</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value=[]</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		function_arg=True</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=True</span> <span class="pre">		mdf_name=None</span> <span class="pre">		name='trial_losses'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=False</span> <span class="pre">		port=None</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=True</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	value</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		default_value=NotImplemented</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		function_arg=True</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=True</span> <span class="pre">		mdf_name=None</span> <span class="pre">		name='value'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=False</span> <span class="pre">		port=None</span> <span class="pre">		read_only=True</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=True</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">	variable</span> <span class="pre">=</span> <span class="pre">Parameter(</span> <span class="pre">		constructor_argument='default_variable'</span> <span class="pre">		default_value=array([0])</span> <span class="pre">		delivery_condition=&lt;LogCondition.OFF:</span> <span class="pre">0&gt;</span> <span class="pre">		dependencies=None</span> <span class="pre">		function_arg=True</span> <span class="pre">		history={}</span> <span class="pre">		history_max_length=1</span> <span class="pre">		history_min_length=0</span> <span class="pre">		loggable=True</span> <span class="pre">		mdf_name=None</span> <span class="pre">		name='variable'</span> <span class="pre">		parse_spec=False</span> <span class="pre">		pnl_internal=True</span> <span class="pre">		port=None</span> <span class="pre">		read_only=True</span> <span class="pre">		reference=False</span> <span class="pre">		specify_none=False</span> <span class="pre">		stateful=True</span> <span class="pre">		structural=False</span> <span class="pre">		user=True</span> <span class="pre">		values={}</span> <span class="pre">	),</span> <span class="pre">)</span></em><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.show_graph">
<span class="sig-name descname"><span class="pre">show_graph</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#psyneulink.library.compositions.autodiffcomposition.AutodiffComposition.show_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Override to use PytorchShowGraph if show_pytorch is True</p>
</dd></dl>

</dd></dl>

</section>
</section>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="CompositionFunctionApproximator.html" class="btn btn-neutral float-right" title="CompositionFunctionApproximator" accesskey="n" rel="next">Next <img src="_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="Compositions.html" class="btn btn-neutral" title="Compositions" accesskey="p" rel="prev"><img src="_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, Jonathan D. Cohen.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="psyneulink-content-right" id="psyneulink-content-right">
          <div class="psyneulink-right-menu" id="psyneulink-right-menu">
            <div class="psyneulink-side-scroll" id="psyneulink-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">AutodiffComposition</a><ul>
<li><a class="reference internal" href="#contents">Contents</a></li>
<li><a class="reference internal" href="#overview">Overview</a></li>
<li><a class="reference internal" href="#creating-an-autodiffcomposition">Creating an AutodiffComposition</a><ul>
<li><a class="reference internal" href="#only-one-outputport-per-node"><em>Only one OutputPort per Node</em></a></li>
<li><a class="reference internal" href="#no-modulatory-components"><em>No Modulatory Components</em></a></li>
<li><a class="reference internal" href="#no-bias-parameters"><em>No Bias Parameters</em></a></li>
<li><a class="reference internal" href="#nesting"><em>Nesting</em></a></li>
<li><a class="reference internal" href="#no-post-construction-modification"><em>No Post-construction Modification</em></a></li>
</ul>
</li>
<li><a class="reference internal" href="#execution">Execution</a><ul>
<li><a class="reference internal" href="#pytorch-mode"><em>PyTorch mode</em></a></li>
<li><a class="reference internal" href="#llvm-mode"><em>LLVM mode</em></a></li>
<li><a class="reference internal" href="#python-mode"><em>Python mode</em></a></li>
<li><a class="reference internal" href="#nested-execution-and-modulation"><em>Nested Execution and Modulation</em></a></li>
<li><a class="reference internal" href="#logging"><em>Logging</em></a></li>
</ul>
</li>
<li><a class="reference internal" href="#class-reference">Class Reference</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
         <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
         <script src="_static/jquery.js"></script>
         <script src="_static/underscore.js"></script>
         <script src="_static/doctools.js"></script>
     

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <footer class="site-footer" id="docs-tutorials-resources">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://princetonuniversity.github.io/PsyNeuLink/" class="footer-logo"></a>
      </div>

  </footer>

  

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container mobile-logo-container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://princetonuniversity.github.io/PsyNeuLink/" aria-label="PsyNeuLink"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/PrincetonUniversity/PsyNeuLink">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      psyneulinkAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.psyneulink-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>