

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Basics and Sampler &mdash; PsyNeuLink 0.3.2 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="genindex.html"/>
        <link rel="search" title="Search" href="search.html"/>
    <link rel="top" title="PsyNeuLink 0.3.2 documentation" href="index.html"/>
        <link rel="next" title="Quick Reference" href="QuickReference.html"/>
        <link rel="prev" title="Intro" href="index.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> PsyNeuLink
          

          
          </a>

          
            
            
              <div class="version">
                0.3
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="index.html">Intro</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Basics and Sampler</a></li>
<li class="toctree-l1"><a class="reference internal" href="QuickReference.html">Quick Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="Component.html">Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="Composition.html">Compositions</a></li>
<li class="toctree-l1"><a class="reference internal" href="Scheduling.html">Scheduling</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="index.html">PsyNeuLink</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
      
    <li>Basics and Sampler</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/BasicsAndSampler.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="basics-and-sampler">
<h1>Basics and Sampler<a class="headerlink" href="#basics-and-sampler" title="Permalink to this headline">¶</a></h1>
<ul>
<li><p class="first"><a class="reference internal" href="#basics"><span class="std std-ref">Basics</span></a></p>
</li>
<li><dl class="first docutils">
<dt><a class="reference internal" href="#sampler"><span class="std std-ref">Sampler</span></a></dt>
<dd><ul class="first last simple">
<li><a class="reference internal" href="#simple-configurations"><span class="std std-ref">Simple Configurations</span></a></li>
<li><a class="reference internal" href="#elaborate-configurations"><span class="std std-ref">More Elaborate Configurations</span></a></li>
<li><a class="reference internal" href="#dynamics-of-execution"><span class="std std-ref">Dynamics of Execution</span></a></li>
</ul>
</dd>
</dl>
</li>
</ul>
<div class="section" id="basics">
<span id="id1"></span><h2>Basics<a class="headerlink" href="#basics" title="Permalink to this headline">¶</a></h2>
<p>PsyNeuLink models are made of <a class="reference internal" href="Component.html"><span class="doc">Components</span></a> and <a class="reference internal" href="Composition.html"><span class="doc">Compositions</span></a>:
Components are objects that perform a specific function, and Compositions are used to combine Components into an
executable model.  There are two primary kinds of Components:  <a class="reference internal" href="Mechanism.html"><span class="doc">Mechanisms</span></a> and <a class="reference internal" href="Projection.html"><span class="doc">Projections</span></a>.
For those familiar with block modeling systems, Mechanisms are the &#8220;blocks&#8221; in PsyNeuLink, and Projections are the
&#8220;links&#8221;.  Mechanisms take inputs, use a function to process them in some way, and generate outputs that can be sent to
other Mechanisms. Projections are used to send information from one Mechanism to another.  A <a class="reference internal" href="Composition.html"><span class="doc">Composition</span></a> uses Projections to link Mechanisms together into pathways that can execute a Process, and Processes
can be combined into Systems to form networks or circuits that make up a systems-level model.  A <a class="reference internal" href="Scheduler.html"><span class="doc">Scheduler</span></a>
coordinates the execution of Mechanisms in a Composition, each of which can be assigned one or more pre-specified or
customized <a class="reference internal" href="Condition.html"><span class="doc">Conditions</span></a>.</p>
<p>Mechanisms and Projections fall into two broad categories:  ones that <em>directly transmit and transform</em> information,
taking the inputs to a model and generating its outputs;  and ones that <em>modulate</em> the transmission and transformation
of information.  PsyNeuLink provides a library of Components of each type.  For example, there is a variety of
ProcessingMechanisms that can be used to transform, integrate, and evaluate information in various ways (e.g., to
implement layers of a feedforward or recurrent neural network, or a drift diffusion decision process); and there
are LearningMechanisms, ControlMechanisms, and GatingMechanisms that can be used to modulate those Mechanisms.</p>
<p>Since Mechanisms can implement any function, Projections ensure that they can &#8220;communicate&#8221; with each other
seamlessly.  A Scheduler, together with Conditions, can be used to specify any pattern of execution among the
Mechanisms in a Composition.  Together, these allow PsyNeuLink to integrate Mechanisms of different types, levels of
analysis, and/or time scales of operation, composing heterogeneous Components into a single integrated System.  This
affords modelers the flexibility to commit each Component of their model to a form of processing and/or level of
analysis that is appropriate for that Component, while providing the opportunity to test and explore how they
interact with one another in a single System.</p>
<p>The figure below provides an example of the kinds of elements available in PsyNeuLink, and some that are planned for
future inclusion.  The <a class="reference internal" href="QuickReference.html"><span class="doc">Quick Reference</span></a> provides a more detailed overview of PsyNeuLink objects and its other
facilities.  In the sections that follow, the Sampler provides some examples of how these are used to construct
models in PsyNeuLink.</p>
<div class="figure" id="id5">
<span id="basicssampler-grandview-figure"></span><img alt="_images/Grandview_With_System_fig.svg" src="_images/Grandview_With_System_fig.svg" /><p class="caption"><span class="caption-text"><strong>PsyNeuLink Environment</strong>.  Full-colored items are examples of currently implemented elements; dimmed
items are examples of elements planned for future implementation.</span></p>
</div>
</div>
<div class="section" id="sampler">
<span id="id2"></span><h2>Sampler<a class="headerlink" href="#sampler" title="Permalink to this headline">¶</a></h2>
<div class="section" id="simple-configurations">
<span id="id3"></span><h3>Simple Configurations<a class="headerlink" href="#simple-configurations" title="Permalink to this headline">¶</a></h3>
<p>Mechanisms can be executed on their own (to gain familiarity with their functions), linked in simple configurations
(for testing isolated interactions), or in Compositions to implement a full model.
Linking Mechanisms for execution can be as simple as placing them in a list &#8211; PsyNeuLink provides the necessary
Projections that connects each to the next one in the list.  For example, the following script uses a simple form of
Composition &#8211; a <a class="reference internal" href="Process.html"><span class="doc">Process</span></a> &#8211; to create a 3-layered 5-2-5 encoder network, the first layer of which
uses a Linear
function (the default for a TransferMechanism), and the other two of which use a LogisticFunction:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="c1"># Construct the Mechanisms:</span>
<span class="n">input_layer</span> <span class="o">=</span> <span class="n">TransferMechanism</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">hidden_layer</span> <span class="o">=</span> <span class="n">TransferMechanism</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">function</span><span class="o">=</span><span class="n">Logistic</span><span class="p">)</span>
<span class="n">output_layer</span> <span class="o">=</span> <span class="n">TransferMechanism</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">function</span><span class="o">=</span><span class="n">Logistic</span><span class="p">)</span>

<span class="c1"># Construct the Process:</span>
<span class="n">my_encoder</span> <span class="o">=</span> <span class="n">process</span><span class="p">(</span><span class="n">pathway</span><span class="o">=</span><span class="p">[</span><span class="n">input_layer</span><span class="p">,</span> <span class="n">hidden_layer</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">])</span>
</pre></div>
</div>
<p>Each of the Mechanisms can be executed individually, by simply calling its <a class="reference internal" href="Mechanism.html#Mechanism.Mechanism_Base.execute" title="Mechanism.Mechanism_Base.execute"><code class="xref any py py-meth docutils literal"><span class="pre">execute</span></code></a> method
with an input array:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">output_layer</span><span class="o">.</span><span class="n">execute</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">10.9</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">7.6</span><span class="p">])</span>
</pre></div>
</div>
<p>The full Process can be run simply by calling its <a class="reference internal" href="Process.html#Process.Process_Base.execute" title="Process.Process_Base.execute"><code class="xref any py py-meth docutils literal"><span class="pre">execute</span></code></a> method:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">my_encoder</span><span class="o">.</span><span class="n">execute</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">10.9</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">7.6</span><span class="p">])</span>
</pre></div>
</div>
<p>The order of that the Mechanisms appear in the list determines the order of their Projections, and PsyNeuLink
picks sensible defaults when necessary Components are not specified.  In the example above, since no Projections were
specified, PsyNeuLink automatically created ones that were properly sized to connect each pair of Mechanisms,
using random initial weights.  However, it is easy to specify them explicitly, simply by inserting them in between
the Mechanisms in the pathway for the Process:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">my_projection_1</span> <span class="o">=</span> <span class="n">MappingProjection</span><span class="p">(</span><span class="n">matrix</span><span class="o">=</span><span class="p">(</span><span class="o">.</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span> <span class="o">-</span> <span class="o">.</span><span class="mi">1</span><span class="p">))</span>
<span class="n">my_encoder</span> <span class="o">=</span> <span class="n">process</span><span class="p">(</span><span class="n">pathway</span><span class="o">=</span><span class="p">[</span><span class="n">input_layer</span><span class="p">,</span> <span class="n">my_projection_1</span><span class="p">,</span> <span class="n">hidden_layer</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">])</span>
</pre></div>
</div>
<p>The first line above creates a Projection with a 2x5 matrix of random weights constrained to be between -.1 and +.1,
which is then inserted in the pathway between the <code class="docutils literal"><span class="pre">input_layer</span></code> and <code class="docutils literal"><span class="pre">output_layer</span></code>.  The matrix itself could also
have been inserted directly, as follows:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">my_encoder</span> <span class="o">=</span> <span class="n">process</span><span class="p">(</span><span class="n">pathway</span><span class="o">=</span><span class="p">[</span><span class="n">input_layer</span><span class="p">,</span> <span class="p">(</span><span class="o">.</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span> <span class="o">-</span> <span class="o">.</span><span class="mi">1</span><span class="p">)),</span> <span class="n">hidden_layer</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">])</span>
</pre></div>
</div>
<p>PsyNeuLink knows to create a MappingProjection using the matrix.  PsyNeuLink is also flexible.  For example,
a recurrent Projection from the <code class="docutils literal"><span class="pre">output_layer</span></code> back to the <code class="docutils literal"><span class="pre">hidden_layer</span></code> can be added simply by adding another
entry to the pathway:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">my_encoder</span> <span class="o">=</span> <span class="n">process</span><span class="p">(</span><span class="n">pathway</span><span class="o">=</span><span class="p">[</span><span class="n">input_layer</span><span class="p">,</span> <span class="n">hidden_layer</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">,</span> <span class="n">hidden_layer</span><span class="p">])</span>
</pre></div>
</div>
<p>This tells PsyNeuLink to create a Projection from the output_layer back to the hidden_layer.  The same could have also
been accomplished by explicitly creating the recurrent connection:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">my_encoder</span> <span class="o">=</span> <span class="n">process</span><span class="p">(</span><span class="n">pathway</span><span class="o">=</span><span class="p">[</span><span class="n">input_layer</span><span class="p">,</span> <span class="n">hidden_layer</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">])</span>
<span class="n">MappingProjection</span><span class="p">(</span><span class="n">sender</span><span class="o">=</span><span class="n">output_layer</span><span class="p">,</span>
                  <span class="n">receiver</span><span class="o">=</span><span class="n">hidden_layer</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="more-elaborate-configurations">
<span id="elaborate-configurations"></span><h3>More Elaborate Configurations<a class="headerlink" href="#more-elaborate-configurations" title="Permalink to this headline">¶</a></h3>
<p>Configuring more complex features is just as simple and flexible.  For example, the feedforward network above can be
trained using backpropagation simply by adding the <strong>learning</strong> argument to the constructor for the Process:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">my_encoder</span> <span class="o">=</span> <span class="n">process</span><span class="p">(</span><span class="n">pathway</span><span class="o">=</span><span class="p">[</span><span class="n">input_layer</span><span class="p">,</span> <span class="n">hidden_layer</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">],</span> <span class="n">learning</span><span class="o">=</span><span class="n">ENABLED</span><span class="p">)</span>
</pre></div>
</div>
<p>and then specifying the target for each trial when it is executed (here, the Process&#8217; <a class="reference internal" href="Process.html#Process.Process_Base.run" title="Process.Process_Base.run"><code class="xref any py py-meth docutils literal"><span class="pre">run</span></code></a> command
is used to execute a series of five training trials, one that trains it on each element of the input):</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">my_encoder</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]],</span>
               <span class="n">target</span><span class="o">=</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]])</span>
</pre></div>
</div>
<p><a class="reference internal" href="Function.html#Function.BackPropagation" title="Function.BackPropagation"><code class="xref any py py-class docutils literal"><span class="pre">Backpropagation</span></code></a> is the default learning method, but PsyNeuLink also currently supports
<a class="reference internal" href="Function.html#Function.Reinforcement" title="Function.Reinforcement"><code class="xref any py py-class docutils literal"><span class="pre">Reinforcement</span> <span class="pre">Learning</span></code></a>, and others are currently being implemented (including Hebbian, Temporal
Differences, and supervised learning for recurrent networks).</p>
<p>PsyNeuLink can also be used to construct models with different kinds of Mechanisms.  For example, the script below
uses a <a class="reference internal" href="System.html"><span class="doc">System</span></a> &#8211; a more powerful form of Composition &#8211; to create two feedforward networks that converge on a single
output layer, which combines the inputs and projects to a drift diffusion mechanism (DDM) that decides the response:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="c1"># Construct the Mechanisms:</span>
<span class="n">colors_input_layer</span> <span class="o">=</span> <span class="n">TransferMechanism</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">function</span><span class="o">=</span><span class="n">Logistic</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;COLORS INPUT&#39;</span><span class="p">)</span>
<span class="n">words_input_layer</span> <span class="o">=</span> <span class="n">TransferMechanism</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">function</span><span class="o">=</span><span class="n">Logistic</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;WORDS INPUT&#39;</span><span class="p">)</span>
<span class="n">output_layer</span> <span class="o">=</span> <span class="n">TransferMechanism</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;OUTPUT&#39;</span><span class="p">)</span>
<span class="n">decision_mech</span> <span class="o">=</span> <span class="n">DDM</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;DECISION&#39;</span><span class="p">)</span>

<span class="c1"># Define a weight matrix used to specify the MappingProjection</span>
<span class="c1"># from each of the input layers to the output_layer</span>
<span class="n">differencing_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span>

<span class="c1"># Construct the Processes:</span>
<span class="n">colors_process</span> <span class="o">=</span> <span class="n">process</span><span class="p">(</span><span class="n">pathway</span><span class="o">=</span><span class="p">[</span><span class="n">colors_input_layer</span><span class="p">,</span> <span class="n">differencing_weights</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">])</span>
<span class="n">words_process</span> <span class="o">=</span> <span class="n">process</span><span class="p">(</span><span class="n">pathway</span><span class="o">=</span><span class="p">[</span><span class="n">words_input_layer</span><span class="p">,</span> <span class="n">differencing_weights</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">])</span>
<span class="n">decision_process</span> <span class="o">=</span> <span class="n">process</span><span class="p">(</span><span class="n">pathway</span><span class="o">=</span><span class="p">[</span><span class="n">output_layer</span><span class="p">,</span> <span class="n">decision_mech</span><span class="p">])</span>

<span class="c1"># Construct the System:</span>
<span class="n">my_simple_Stroop</span> <span class="o">=</span> <span class="n">system</span><span class="p">(</span><span class="n">processes</span><span class="o">=</span><span class="p">[</span><span class="n">colors_process</span><span class="p">,</span> <span class="n">words_process</span><span class="p">,</span> <span class="n">decision_process</span><span class="p">])</span>
</pre></div>
</div>
<p>In this example, <code class="docutils literal"><span class="pre">differencing_weights</span></code> is used to specify a <a class="reference internal" href="MappingProjection.html"><span class="doc">MappingProjection</span></a> between the input layer of the
<a class="reference internal" href="Process.html#Process.Process_Base.pathway" title="Process.Process_Base.pathway"><code class="xref any py py-attr docutils literal"><span class="pre">pathway</span></code></a> for each Process and the Mechanism (<code class="docutils literal"><span class="pre">output_layer</span></code>) on which they converge.</p>
<p>As a Composition gets more complex, it helps to visualize it.  PsyNeuLink has built-in methods for doing so.
For example, calling <code class="docutils literal"><span class="pre">my_simple_Stroop.show_graph()</span></code> produces the following display:</p>
<p id="simple-stroop-example-figure"><strong>Composition Graph</strong></p>
<div class="figure" id="id6">
<img alt="_images/Simple_Stroop_Example_fig.svg" src="_images/Simple_Stroop_Example_fig.svg" /><p class="caption"><span class="caption-text">Graph representation of the System Composition in the example above.</span></p>
</div>
<p>As the name of the <code class="docutils literal"><span class="pre">show_graph()</span></code> method suggests, Compositions are represented in PsyNeuLink as graphs, using a
standard dependency dictionary format, so that they can also be submitted to other graph theoretic packages for
display and/or analysis (such as <a class="reference external" href="https://networkx.github.io">NetworkX</a> and <a class="reference external" href="http://igraph.org/redirect.html">igraph</a>).</p>
</div>
<div class="section" id="dynamics-of-execution">
<span id="id4"></span><h3>Dynamics of Execution<a class="headerlink" href="#dynamics-of-execution" title="Permalink to this headline">¶</a></h3>
<p>Finally, perhaps the most powerful feature of PsyNeuLink is its ability to simulate models with Components
that execute at arbitrary and disparate &#8220;time scales&#8221;. For example, a Composition can include some Mechanisms
that require fine-grained updates (e.g., Euler integration of a drift diffusion process) with ones that carry out
&#8220;single shot&#8221; computations (e.g., a single pass through a feedforward neural network). By default, when a Composition
is run, each Component in it is executed at least once.  However, PsyNeuLink has a <a class="reference internal" href="Scheduler.html"><span class="doc">Scheduler</span></a> that can be used to
design more complex dynamics of execution by assigning one or more <a class="reference internal" href="Condition.html"><span class="doc">Conditions</span></a> to any Mechanism. Conditions
can specify the isolated behavior of a Mechanism (e.g., how many times it should be executed in each <a class="reference internal" href="TimeScale.html#Scheduling.TimeScale.TimeScale.TRIAL" title="Scheduling.TimeScale.TimeScale.TRIAL"><code class="xref any py py-attr docutils literal"><span class="pre">TRIAL</span></code></a>), or its
behavior relative to that of one or more other Components (e.g., how many times it should execute or when it should
stop executing relative to other Mechanisms).</p>
<p>For example, the following script implements a Composition that integrates a 3-layered feedforward network for
performing a simple stimulus-response mapping task, with a recurrent network that receives input from and feeds back
to the feed-forward network, to provide a simple form of maintained context.  To allow the recurrent layer to settle
following the presentation of each stimulus (which is not required for the feedforward network), the Scheduler can
be used to execute the recurrent layer multiple times but the feedforward network only once in each <a class="reference internal" href="TimeScale.html#Scheduling.TimeScale.TimeScale.TRIAL" title="Scheduling.TimeScale.TimeScale.TRIAL"><code class="xref any py py-attr docutils literal"><span class="pre">TRIAL</span></code></a>, as
follows:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="c1"># Construct the Mechanisms:</span>
<span class="n">input_layer</span> <span class="o">=</span> <span class="n">TransferMechanism</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">hidden_layer</span> <span class="o">=</span> <span class="n">TransferMechanism</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">output_layer</span> <span class="o">=</span> <span class="n">TransferMechanism</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">recurrent_layer</span> <span class="o">=</span> <span class="n">RecurrentTransferMechanism</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>

<span class="c1"># Construct the Processes:</span>
<span class="n">feed_forward_network</span> <span class="o">=</span> <span class="n">process</span><span class="p">(</span><span class="n">pathway</span><span class="o">=</span><span class="p">[</span><span class="n">input_layer</span><span class="p">,</span> <span class="n">hidden_layer</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">])</span>
<span class="n">recurrent_network</span> <span class="o">=</span> <span class="n">process</span><span class="p">(</span><span class="n">pathway</span><span class="o">=</span><span class="p">[</span><span class="n">hidden_layer</span><span class="p">,</span> <span class="n">recurrent_layer</span><span class="p">,</span> <span class="n">hidden_layer</span><span class="p">])</span>

<span class="c1"># Construct the System:</span>
<span class="n">full_model</span> <span class="o">=</span> <span class="n">system</span><span class="p">(</span><span class="n">processes</span><span class="o">=</span><span class="p">[</span><span class="n">feed_forward_network</span><span class="p">,</span> <span class="n">recurrent_network</span><span class="p">])</span>

<span class="c1"># Construct the Scheduler:</span>
<span class="n">my_scheduler</span> <span class="o">=</span> <span class="n">Scheduler</span><span class="p">(</span><span class="n">system</span><span class="o">=</span><span class="n">full_model</span><span class="p">)</span>

<span class="c1"># Add Conditions to the Scheduler:</span>
<span class="n">my_scheduler</span><span class="o">.</span><span class="n">add_condition</span><span class="p">(</span><span class="n">my_hidden_layer</span><span class="p">,</span>
                           <span class="n">Any</span><span class="p">(</span><span class="n">EveryNCalls</span><span class="p">(</span><span class="n">my_input_layer</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                           <span class="n">EveryNCalls</span><span class="p">(</span><span class="n">my_recurrent_layer</span><span class="p">,</span> <span class="mi">10</span><span class="p">)))</span>
<span class="n">my_scheduler</span><span class="o">.</span><span class="n">add_condition</span><span class="p">(</span><span class="n">my_output_layer</span><span class="p">,</span>
                           <span class="n">EveryNCalls</span><span class="p">(</span><span class="n">my_hidden_layer</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
<p>The two Conditions added to the Scheduler specify that:</p>
<blockquote>
<div><ol class="arabic simple">
<li><code class="docutils literal"><span class="pre">my_hidden_layer</span></code> should execute whenever either <code class="docutils literal"><span class="pre">input_hidden_layer</span></code> has executed once (to encode the stimulus and make available to the <code class="docutils literal"><span class="pre">recurrent_layer</span></code>), or when the <code class="docutils literal"><span class="pre">recurrent_layer</span></code> has executed 10 times (to allow it to settle on a context representation and provide that back to the <code class="docutils literal"><span class="pre">hidden_layer</span></code>)</li>
<li>the <code class="docutils literal"><span class="pre">output_layer</span></code> should execute only after the <code class="docutils literal"><span class="pre">hidden_layer</span></code> has executed twice (to integrate its inputs from both <code class="docutils literal"><span class="pre">input_layer</span></code> and <code class="docutils literal"><span class="pre">recurrent_layer</span></code>).</li>
</ol>
</div></blockquote>
<p>More sophisticated Conditions can also be created.  For example, the <code class="docutils literal"><span class="pre">recurrent_layer</span></code> can be scheduled to
execute until the change in its value falls below a specified threshold as follows:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="c1"># Define a function ``converge`` that detects when a Mechanism has converged such that</span>
<span class="c1"># none of elements has changed more than ``epsilon`` since the last execution</span>
<span class="k">def</span> <span class="nf">converge</span><span class="p">(</span><span class="n">mech</span><span class="p">,</span> <span class="n">thresh</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">mech</span><span class="o">.</span><span class="n">delta</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">thresh</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="kc">True</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="mf">0.01</span>

<span class="c1"># Add a Condition to the Scheduler that uses the ``converge`` function to continue</span>
<span class="c1"># executing the ``recurrent_layer`` while it has not (i.e., until it has) converged</span>
<span class="n">my_scheduler</span><span class="o">.</span><span class="n">add_condition</span><span class="p">(</span><span class="n">my_hidden_layer</span><span class="p">,</span>
                           <span class="n">Any</span><span class="p">(</span><span class="n">EveryNCalls</span><span class="p">(</span><span class="n">my_input_layer</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                           <span class="n">EveryNCalls</span><span class="p">(</span><span class="n">my_recurrent_layer</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
<span class="n">my_scheduler</span><span class="o">.</span><span class="n">add_condition</span><span class="p">(</span><span class="n">my_recurrent_layer</span><span class="p">,</span>
                           <span class="n">All</span><span class="p">(</span><span class="n">EveryNCalls</span><span class="p">(</span><span class="n">my_hidden_layer</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                               <span class="n">WhileNot</span><span class="p">(</span><span class="n">converge</span><span class="p">,</span> <span class="n">my_recurrent_mech</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">)))</span>
</pre></div>
</div>
<p>Here, the criterion for stopping execution is defined as a function (<code class="docutils literal"><span class="pre">converge</span></code>), that is used in a <a class="reference internal" href="Condition.html#Scheduling.Condition.WhileNot" title="Scheduling.Condition.WhileNot"><code class="xref any py py-class docutils literal"><span class="pre">WhileNot</span></code></a>
Condition.  Any arbitrary Conditions can be created and flexibly combined to construct virtually any schedule of
execution that is logically sensible.</p>
<p>The <a class="reference internal" href="UserGuide.html"><span class="doc">User&#8217;s Guide</span></a> provides a more detailed review of PsyNeuLink&#8217;s organization and capabilities,
and the <a class="reference internal" href="index.html#tutorial"><span class="std std-ref">Tutorial</span></a> provides an interactive introduction to its use.</p>
</div>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="QuickReference.html" class="btn btn-neutral float-right" title="Quick Reference" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral" title="Intro" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, Jonathan D. Cohen.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.3.2',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>